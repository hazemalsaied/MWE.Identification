INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_6866Ys.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 10619/11178 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmp3EJ51C and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmpEg7A4O). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmp3EJ51C and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmpEg7A4O). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmp3EJ51C and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmpEg7A4O). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmp3EJ51C and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmpEg7A4O). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmp3EJ51C and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmpEg7A4O). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmp3EJ51C and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmpEg7A4O). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmp3EJ51C and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmpEg7A4O). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmpXYMTUG and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmppGvunp). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5733')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '4957' (I am process '5733')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5733')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '4968' (I am process '5733')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '4957' (I am process '5733')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '5167' (I am process '5733')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '4957' (I am process '5733')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5733')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5733')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,8              ,61             ,187            ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
39             ,59             ,True           ,63             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.021          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.077          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.025          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 8, 61, 187, 7, 39, 59, True, 63, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.021, True, 20, 0.077, 128, 2, 20, categorical_crossentropy, 0.006, val_loss, adagrad, 4, False, 256, 0.025, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (17h:20)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.077
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1683 - acc: 0.9572
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0714 - acc: 0.9799
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0546 - acc: 0.9844
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0853 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0555 - acc: 0.9842
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0395 - acc: 0.9887
MWE identification: 3
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0329 - acc: 0.9906
MWE identification: 4
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0283 - acc: 0.9921
MWE identification: 5
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 54.9
	TRAINING TIME: 3.98 minutes 
==================================================================================================
	PARSING TIME: 1.8 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (17 h:26)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (17h:26)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.077
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2798 - acc: 0.9161
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1541 - acc: 0.9498
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1264 - acc: 0.9582
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0813 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1440 - acc: 0.9546
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1052 - acc: 0.9658
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0916 - acc: 0.9707
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0817 - acc: 0.9740
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0738 - acc: 0.9772
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 58.0
	TRAINING TIME: 1.82 minutes 
==================================================================================================
	PARSING TIME: 2.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (17 h:31)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (17h:31)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.077
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2284 - acc: 0.9347
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0881 - acc: 0.9726
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0608 - acc: 0.9816
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0852 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0755 - acc: 0.9784
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0414 - acc: 0.9880
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0307 - acc: 0.9918
MWE identification: 4
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0240 - acc: 0.9940
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 41.4
	TRAINING TIME: 2.7 minutes 
==================================================================================================
	PARSING TIME: 1.23 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (17 h:35)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,31             ,182            ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
45             ,55             ,True           ,50             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.008          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.014          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.026          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.047          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 31, 182, 5, 45, 55, True, 50, False, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.008, True, 20, 0.014, 96, 1, 20, categorical_crossentropy, 0.026, val_loss, adagrad, 4, False, 64, 0.047, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (17h:35)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.047
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1423 - acc: 0.9626
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0561 - acc: 0.9834
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0456 - acc: 0.9860
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0784 - acc: 0.9811
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0279 - acc: 0.9914
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0570 - acc: 0.9858
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0180 - acc: 0.9944
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0520 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0134 - acc: 0.9958
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0494 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0108 - acc: 0.9966
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0479 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.72 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.563
	P, R  : 0.724, 0.461

==================================================================================================
	XP Ends: 20/9 (17 h:39)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (17h:39)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.047
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2488 - acc: 0.9232
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1286 - acc: 0.9568
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1100 - acc: 0.9624
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0890 - acc: 0.9781
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0733 - acc: 0.9762
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0615 - acc: 0.9848
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0523 - acc: 0.9835
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0554 - acc: 0.9864
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0408 - acc: 0.9875
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0521 - acc: 0.9874
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0331 - acc: 0.9900
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0502 - acc: 0.9880
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.2 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.574
	P, R  : 0.624, 0.532

==================================================================================================
	XP Ends: 20/9 (17 h:44)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (17h:44)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.047
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1923 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0670 - acc: 0.9781
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0491 - acc: 0.9836
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0719 - acc: 0.9818
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0242 - acc: 0.9924
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0551 - acc: 0.9858
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0119 - acc: 0.9968
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0508 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0069 - acc: 0.9985
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0485 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0044 - acc: 0.9992
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0471 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.33 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.446
	P, R  : 0.554, 0.373

==================================================================================================
	XP Ends: 20/9 (17 h:48)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,8              ,150            ,169            ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,95             ,True           ,74             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.018          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.026          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.019          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.017          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 8, 150, 169, 10, 5, 95, True, 74, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.018, True, 20, 0.026, 128, 1, 20, categorical_crossentropy, 0.019, val_acc, adagrad, 4, False, 128, 0.017, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (17h:48)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2036 - acc: 0.9496
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0842 - acc: 0.9772
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0680 - acc: 0.9808
MWE identification: 1
Epoch 1/1
 - 8s - loss: 8.0586 - acc: 0.4998
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0610 - acc: 0.9831
MWE identification: 2
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0466 - acc: 0.9869
MWE identification: 3
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0399 - acc: 0.9889
MWE identification: 4
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0351 - acc: 0.9902
MWE identification: 5
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.33 minutes 
==================================================================================================
	PARSING TIME: 2.42 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 20/9 (17 h:53)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (17h:53)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3185 - acc: 0.9073
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1743 - acc: 0.9439
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1484 - acc: 0.9513
MWE identification: 1
Epoch 1/1
 - 5s - loss: 2.0053 - acc: 0.8618
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1525 - acc: 0.9521
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0628 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1279 - acc: 0.9595
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0526 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1116 - acc: 0.9641
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0499 - acc: 0.9883
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1009 - acc: 0.9676
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0485 - acc: 0.9886
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0924 - acc: 0.9705
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0480 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 2.03 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.589
	P, R  : 0.683, 0.517

==================================================================================================
	XP Ends: 20/9 (17 h:57)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (17h:57)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2697 - acc: 0.9250
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1061 - acc: 0.9677
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0793 - acc: 0.9756
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0769 - acc: 0.9818
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0848 - acc: 0.9755
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0531 - acc: 0.9871
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0585 - acc: 0.9834
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0486 - acc: 0.9884
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0456 - acc: 0.9872
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0466 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0365 - acc: 0.9901
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0458 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.87 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.445
	P, R  : 0.621, 0.347

==================================================================================================
	XP Ends: 20/9 (18 h:1)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,9              ,219            ,98             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,49             ,True           ,117            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.029          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.015          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.048          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.007          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 9, 219, 98, 8, 6, 49, True, 117, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.029, True, 20, 0.015, 256, 2, 20, categorical_crossentropy, 0.048, val_loss, adagrad, 4, False, 96, 0.007, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:1)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4404 - acc: 0.8938
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1397 - acc: 0.9666
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1062 - acc: 0.9730
MWE identification: 1
Epoch 1/1
 - 5s - loss: 8.0568 - acc: 0.4992
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0924 - acc: 0.9760
MWE identification: 2
Epoch 1/1
 - 4s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0785 - acc: 0.9785
MWE identification: 3
Epoch 1/1
 - 4s - loss: 8.0591 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0719 - acc: 0.9800
MWE identification: 4
Epoch 1/1
 - 5s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0670 - acc: 0.9810
MWE identification: 5
Epoch 1/1
 - 4s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.07 minutes 
==================================================================================================
	PARSING TIME: 2.42 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 20/9 (18 h:6)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:6)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5602 - acc: 0.8489
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2567 - acc: 0.9246
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.2103 - acc: 0.9349
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0653 - acc: 0.2507
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1855 - acc: 0.9417
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1687 - acc: 0.9462
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1584 - acc: 0.9495
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1504 - acc: 0.9517
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.1438 - acc: 0.9539
MWE identification: 6
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.88 minutes 
==================================================================================================
	PARSING TIME: 3.85 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.074

==================================================================================================
	XP Ends: 20/9 (18 h:12)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:12)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5174 - acc: 0.8655
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1913 - acc: 0.9468
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1398 - acc: 0.9591
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0882 - acc: 0.9799
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1307 - acc: 0.9633
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0554 - acc: 0.9863
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1046 - acc: 0.9698
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0499 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0911 - acc: 0.9736
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0480 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0821 - acc: 0.9763
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0469 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 0.8 minutes 
==================================================================================================
	Identification : 0.445
	P, R  : 0.634, 0.343

==================================================================================================
	XP Ends: 20/9 (18 h:15)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
22             ,6              ,48             ,25             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
34             ,58             ,True           ,25             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.009          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.025          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.094          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 22, 6, 48, 25, 5, 34, 58, True, 25, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.009, False, 20, 0.025, 256, 1, 20, categorical_crossentropy, 0.094, val_acc, adagrad, 4, False, 64, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:15)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1144 - acc: 0.9712
MWE identification: 1
Epoch 1/1
 - 5s - loss: 8.0580 - acc: 0.4992
POS tagging: 4
Epoch 1/1
 - 8s - loss: 0.1075 - acc: 0.9738
MWE identification: 2
Epoch 1/1
 - 5s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0853 - acc: 0.9771
MWE identification: 3
Epoch 1/1
 - 5s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0780 - acc: 0.9787
MWE identification: 4
Epoch 1/1
 - 5s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0728 - acc: 0.9797
MWE identification: 5
Epoch 1/1
 - 5s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.27 minutes 
==================================================================================================
	PARSING TIME: 2.37 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 20/9 (18 h:20)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:20)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.2225 - acc: 0.9322
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.3447 - acc: 0.9603
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.2480 - acc: 0.9296
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.1013 - acc: 0.9830
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.2061 - acc: 0.9381
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0540 - acc: 0.9876
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1862 - acc: 0.9426
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0505 - acc: 0.9883
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1740 - acc: 0.9452
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0491 - acc: 0.9886
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.1654 - acc: 0.9476
MWE identification: 6
Epoch 1/1
 - 3s - loss: 0.0483 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.03 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.636
	P, R  : 0.812, 0.523

==================================================================================================
	XP Ends: 20/9 (18 h:24)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:24)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1522 - acc: 0.9554
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0799 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1281 - acc: 0.9635
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1045 - acc: 0.9697
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0929 - acc: 0.9731
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0845 - acc: 0.9758
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.63 minutes 
==================================================================================================
	PARSING TIME: 1.82 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.063

==================================================================================================
	XP Ends: 20/9 (18 h:29)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,1              ,52             ,77             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
43             ,144            ,True           ,45             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.019          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.015          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.08           ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.015          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 1, 52, 77, 8, 43, 144, True, 45, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.019, True, 20, 0.015, 256, 1, 20, categorical_crossentropy, 0.08, val_acc, adagrad, 4, False, 128, 0.015, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:29)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2516 - acc: 0.9362
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1188 - acc: 0.9681
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0964 - acc: 0.9739
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1085 - acc: 0.9764
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0858 - acc: 0.9772
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0615 - acc: 0.9856
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0706 - acc: 0.9812
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0519 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0609 - acc: 0.9839
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0490 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0540 - acc: 0.9857
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0475 - acc: 0.9890
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0487 - acc: 0.9870
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0466 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.18 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.504
	P, R  : 0.544, 0.47

==================================================================================================
	XP Ends: 20/9 (18 h:33)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:33)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3460 - acc: 0.9005
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1913 - acc: 0.9393
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1631 - acc: 0.9476
MWE identification: 1
Epoch 1/1
 - 3s - loss: 8.0552 - acc: 0.4985
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1433 - acc: 0.9544
MWE identification: 2
Epoch 1/1
 - 3s - loss: 8.0594 - acc: 0.4998
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1225 - acc: 0.9615
MWE identification: 3
Epoch 1/1
 - 3s - loss: 8.0594 - acc: 0.4998
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1101 - acc: 0.9658
MWE identification: 4
Epoch 1/1
 - 3s - loss: 8.0594 - acc: 0.4998
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1005 - acc: 0.9690
MWE identification: 5
Epoch 1/1
 - 3s - loss: 8.0594 - acc: 0.4998
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.68 minutes 
==================================================================================================
	PARSING TIME: 3.65 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.145

==================================================================================================
	XP Ends: 20/9 (18 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3097 - acc: 0.9137
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1295 - acc: 0.9621
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0921 - acc: 0.9739
MWE identification: 1
Epoch 1/1
 - 6s - loss: 8.0566 - acc: 0.4996
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0658 - acc: 0.9825
MWE identification: 2
Epoch 1/1
 - 6s - loss: 8.0590 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0475 - acc: 0.9876
MWE identification: 3
Epoch 1/1
 - 6s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0377 - acc: 0.9907
MWE identification: 4
Epoch 1/1
 - 6s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0312 - acc: 0.9926
MWE identification: 5
Epoch 1/1
 - 6s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 1.58 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.133

==================================================================================================
	XP Ends: 20/9 (18 h:43)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,7              ,54             ,87             ,14             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
18             ,103            ,True           ,120            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.03           ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.068          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.047          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 7, 54, 87, 14, 18, 103, True, 120, False, False, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.03, True, 20, 0.006, 96, 2, 20, categorical_crossentropy, 0.068, val_loss, adagrad, 4, False, 96, 0.047, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:43)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.047
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1423 - acc: 0.9626
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0561 - acc: 0.9834
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0431 - acc: 0.9866
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0829 - acc: 0.9790
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0262 - acc: 0.9920
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0653 - acc: 0.9836
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0176 - acc: 0.9946
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0605 - acc: 0.9851
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0132 - acc: 0.9957
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0576 - acc: 0.9858
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0108 - acc: 0.9966
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0556 - acc: 0.9864
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.13 minutes 
==================================================================================================
	Identification : 0.548
	P, R  : 0.676, 0.461

==================================================================================================
	XP Ends: 20/9 (18 h:47)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:47)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.047
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2488 - acc: 0.9232
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1286 - acc: 0.9568
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1058 - acc: 0.9639
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0950 - acc: 0.9751
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0708 - acc: 0.9769
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0722 - acc: 0.9816
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0520 - acc: 0.9836
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0660 - acc: 0.9833
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0409 - acc: 0.9874
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0627 - acc: 0.9843
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0334 - acc: 0.9900
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0602 - acc: 0.9849
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.13 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.579
	P, R  : 0.686, 0.501

==================================================================================================
	XP Ends: 20/9 (18 h:51)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:51)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.047
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1923 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0670 - acc: 0.9781
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0458 - acc: 0.9851
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0767 - acc: 0.9805
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0220 - acc: 0.9933
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0619 - acc: 0.9840
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0118 - acc: 0.9968
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0576 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0069 - acc: 0.9985
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0552 - acc: 0.9860
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0045 - acc: 0.9992
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0533 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.474
	P, R  : 0.585, 0.398

==================================================================================================
	XP Ends: 20/9 (18 h:55)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,2              ,67             ,79             ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
47             ,41             ,True           ,26             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.016          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.056          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.012          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 2, 67, 79, 10, 47, 41, True, 26, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.006, True, 20, 0.016, 64, 1, 20, categorical_crossentropy, 0.056, val_loss, adagrad, 4, False, 256, 0.012, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (18h:55)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2643 - acc: 0.9359
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1003 - acc: 0.9742
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0815 - acc: 0.9782
MWE identification: 1
Epoch 1/1
 - 17s - loss: 8.0580 - acc: 0.4999
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0757 - acc: 0.9796
MWE identification: 2
Epoch 1/1
 - 15s - loss: 8.0590 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0644 - acc: 0.9818
MWE identification: 3
Epoch 1/1
 - 15s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0582 - acc: 0.9837
MWE identification: 4
Epoch 1/1
 - 15s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0533 - acc: 0.9850
MWE identification: 5
Epoch 1/1
 - 15s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.82 minutes 
==================================================================================================
	PARSING TIME: 2.32 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 20/9 (19 h:0)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:0)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3791 - acc: 0.8933
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1986 - acc: 0.9376
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1707 - acc: 0.9455
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.1131 - acc: 0.9772
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1785 - acc: 0.9444
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0585 - acc: 0.9857
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1568 - acc: 0.9504
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0528 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1432 - acc: 0.9544
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0504 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1334 - acc: 0.9573
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0490 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.12 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.601
	P, R  : 0.745, 0.503

==================================================================================================
	XP Ends: 20/9 (19 h:5)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:5)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3356 - acc: 0.9096
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1296 - acc: 0.9618
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0994 - acc: 0.9707
MWE identification: 1
Epoch 1/1
 - 20s - loss: 0.0739 - acc: 0.9823
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1056 - acc: 0.9692
MWE identification: 2
Epoch 1/1
 - 20s - loss: 0.0526 - acc: 0.9869
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0831 - acc: 0.9760
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0489 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0707 - acc: 0.9799
MWE identification: 4
Epoch 1/1
 - 20s - loss: 0.0472 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0618 - acc: 0.9826
MWE identification: 5
Epoch 1/1
 - 20s - loss: 0.0462 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.52 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.433
	P, R  : 0.64, 0.327

==================================================================================================
	XP Ends: 20/9 (19 h:9)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
22             ,5              ,143            ,50             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
30             ,36             ,True           ,52             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.021          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.011          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.016          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.013          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 22, 5, 143, 50, 5, 30, 36, True, 52, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.021, False, 20, 0.011, 96, 2, 20, categorical_crossentropy, 0.016, val_loss, adagrad, 4, False, 64, 0.013, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:9)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2471 - acc: 0.9401
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0961 - acc: 0.9749
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0775 - acc: 0.9786
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0852 - acc: 0.9802
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0659 - acc: 0.9814
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0576 - acc: 0.9858
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0548 - acc: 0.9844
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0533 - acc: 0.9871
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0480 - acc: 0.9866
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0508 - acc: 0.9879
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0430 - acc: 0.9881
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0492 - acc: 0.9883
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.72 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.588
	P, R  : 0.813, 0.46

==================================================================================================
	XP Ends: 20/9 (19 h:13)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:13)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3616 - acc: 0.8974
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1924 - acc: 0.9390
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1645 - acc: 0.9466
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1086 - acc: 0.9755
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1457 - acc: 0.9529
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0635 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 5s - loss: 0.1271 - acc: 0.9588
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0570 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1155 - acc: 0.9626
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0537 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1068 - acc: 0.9653
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0515 - acc: 0.9877
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.22 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.7, 0.515

==================================================================================================
	XP Ends: 20/9 (19 h:18)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:18)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3187 - acc: 0.9134
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1232 - acc: 0.9636
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0932 - acc: 0.9711
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0792 - acc: 0.9814
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0756 - acc: 0.9776
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0556 - acc: 0.9860
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0571 - acc: 0.9834
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0514 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0464 - acc: 0.9868
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0492 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0391 - acc: 0.9893
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0477 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.3 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.434
	P, R  : 0.617, 0.335

==================================================================================================
	XP Ends: 20/9 (19 h:22)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
11             ,6              ,30             ,58             ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,38             ,True           ,35             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.015          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.065          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.04           ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.054          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 11, 6, 30, 58, 13, 7, 38, True, 35, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.015, False, 20, 0.065, 256, 1, 20, categorical_crossentropy, 0.04, val_acc, adagrad, 4, False, 96, 0.054, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:22)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.065
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1399 - acc: 0.9629
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0538 - acc: 0.9838
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0412 - acc: 0.9871
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0815 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0272 - acc: 0.9915
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0162 - acc: 0.9949
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0120 - acc: 0.9962
MWE identification: 4
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0096 - acc: 0.9969
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.2 minutes 
==================================================================================================
	PARSING TIME: 1.83 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (19 h:26)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:26)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.065
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2481 - acc: 0.9235
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1245 - acc: 0.9584
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1018 - acc: 0.9654
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0745 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0758 - acc: 0.9749
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0492 - acc: 0.9845
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0373 - acc: 0.9888
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0295 - acc: 0.9912
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.82 minutes 
==================================================================================================
	PARSING TIME: 2.67 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (19 h:31)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:31)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.065
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1905 - acc: 0.9440
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0638 - acc: 0.9791
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0426 - acc: 0.9858
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0830 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0237 - acc: 0.9927
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0102 - acc: 0.9971
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0055 - acc: 0.9988
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0035 - acc: 0.9994
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.45 minutes 
==================================================================================================
	Identification : 0.015
	P, R  : 0.008, 0.163

==================================================================================================
	XP Ends: 20/9 (19 h:36)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,4              ,28             ,97             ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
25             ,71             ,True           ,116            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.071          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.033          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.084          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 4, 28, 97, 11, 25, 71, True, 116, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.006, True, 20, 0.071, 256, 1, 20, categorical_crossentropy, 0.033, val_loss, adagrad, 4, False, 128, 0.084, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:36)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.084
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1610 - acc: 0.9590
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0533 - acc: 0.9842
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0385 - acc: 0.9881
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0798 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0290 - acc: 0.9910
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0163 - acc: 0.9950
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0119 - acc: 0.9963
MWE identification: 4
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0095 - acc: 0.9971
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0081 - acc: 0.9975
MWE identification: 6
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.15 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (19 h:40)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:40)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.084
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2661 - acc: 0.9216
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1192 - acc: 0.9594
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0925 - acc: 0.9681
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0752 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0704 - acc: 0.9767
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0421 - acc: 0.9867
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0301 - acc: 0.9911
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0229 - acc: 0.9934
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0179 - acc: 0.9952
MWE identification: 6
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.78 minutes 
==================================================================================================
	PARSING TIME: 2.77 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (19 h:45)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:45)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.084
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1990 - acc: 0.9430
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0596 - acc: 0.9802
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0363 - acc: 0.9881
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0824 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0237 - acc: 0.9926
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0090 - acc: 0.9976
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0045 - acc: 0.9991
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0028 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0020 - acc: 0.9997
MWE identification: 6
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.6 minutes 
==================================================================================================
	PARSING TIME: 1.28 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (19 h:49)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
18             ,3              ,29             ,199            ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
28             ,106            ,True           ,85             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.024          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.082          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.012          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 18, 3, 29, 199, 5, 28, 106, True, 85, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.024, False, 20, 0.082, 128, 1, 20, categorical_crossentropy, 0.006, val_acc, adagrad, 4, False, 64, 0.012, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:49)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.082
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2641 - acc: 0.9359
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1000 - acc: 0.9743
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0802 - acc: 0.9781
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0848 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0930 - acc: 0.9774
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0608 - acc: 0.9828
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0527 - acc: 0.9852
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0472 - acc: 0.9868
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 1.8 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (19 h:54)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:54)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.082
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3791 - acc: 0.8933
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1986 - acc: 0.9376
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1691 - acc: 0.9453
MWE identification: 1
Epoch 1/1
 - 5s - loss: 7.4761 - acc: 0.5250
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.5245 - acc: 0.8503
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.2399 - acc: 0.9701
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.3323 - acc: 0.9055
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.1255 - acc: 0.9815
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.2639 - acc: 0.9233
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0582 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.2300 - acc: 0.9315
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0525 - acc: 0.9880
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.2088 - acc: 0.9368
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0511 - acc: 0.9883
Should stop early?
POS tagging: 9
Epoch 1/1
 - 6s - loss: 0.1940 - acc: 0.9404
MWE identification: 7
Epoch 1/1
 - 5s - loss: 0.0504 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 91.9
POS tagging accuracy (MWEs) = 91.9
	TRAINING TIME: 2.47 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.636, 0.528

==================================================================================================
	XP Ends: 20/9 (19 h:58)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (19h:58)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.082
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3356 - acc: 0.9096
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1296 - acc: 0.9618
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0976 - acc: 0.9701
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0850 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1172 - acc: 0.9667
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0710 - acc: 0.9793
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0577 - acc: 0.9834
MWE identification: 4
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0490 - acc: 0.9860
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.05 minutes 
==================================================================================================
	PARSING TIME: 1.23 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (20 h:3)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
14             ,3              ,30             ,47             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
21             ,187            ,True           ,25             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.008          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.009          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.005          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 14, 3, 30, 47, 12, 21, 187, True, 25, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.008, True, 20, 0.009, 128, 2, 20, categorical_crossentropy, 0.005, val_loss, adagrad, 4, False, 128, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:3)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1190 - acc: 0.9706
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0920 - acc: 0.9779
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1047 - acc: 0.9736
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0601 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0908 - acc: 0.9762
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0549 - acc: 0.9867
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0830 - acc: 0.9778
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0523 - acc: 0.9874
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0775 - acc: 0.9788
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0507 - acc: 0.9879
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.32 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.587
	P, R  : 0.792, 0.466

==================================================================================================
	XP Ends: 20/9 (20 h:7)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:7)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.2284 - acc: 0.9313
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1172 - acc: 0.9717
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.2106 - acc: 0.9357
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0668 - acc: 0.9836
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1887 - acc: 0.9411
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0601 - acc: 0.9853
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1764 - acc: 0.9446
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0565 - acc: 0.9863
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1677 - acc: 0.9469
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0540 - acc: 0.9870
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 1.9 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.62
	P, R  : 0.864, 0.483

==================================================================================================
	XP Ends: 20/9 (20 h:10)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:10)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1584 - acc: 0.9541
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0829 - acc: 0.9798
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1388 - acc: 0.9608
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0569 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1144 - acc: 0.9673
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0525 - acc: 0.9870
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1019 - acc: 0.9705
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0502 - acc: 0.9878
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0931 - acc: 0.9728
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0486 - acc: 0.9883
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.82 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.446
	P, R  : 0.618, 0.349

==================================================================================================
	XP Ends: 20/9 (20 h:14)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,3              ,54             ,29             ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
13             ,76             ,True           ,120            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.009          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.074          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.034          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.013          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 3, 54, 29, 13, 13, 76, True, 120, True, False, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.009, True, 20, 0.074, 256, 1, 20, categorical_crossentropy, 0.034, val_acc, adagrad, 4, False, 96, 0.013, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:14)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2471 - acc: 0.9401
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0961 - acc: 0.9749
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0775 - acc: 0.9787
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0813 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0939 - acc: 0.9772
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0602 - acc: 0.9830
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0519 - acc: 0.9853
MWE identification: 4
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0462 - acc: 0.9870
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 1.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (20 h:19)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:19)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3616 - acc: 0.8974
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1924 - acc: 0.9390
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.1645 - acc: 0.9467
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0734 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1809 - acc: 0.9449
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1365 - acc: 0.9557
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1230 - acc: 0.9601
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1133 - acc: 0.9633
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.78 minutes 
==================================================================================================
	PARSING TIME: 2.93 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (20 h:24)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:24)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3187 - acc: 0.9134
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1232 - acc: 0.9636
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0933 - acc: 0.9713
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0811 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1069 - acc: 0.9691
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0663 - acc: 0.9805
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0537 - acc: 0.9847
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0453 - acc: 0.9871
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 1.27 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (20 h:28)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
24             ,3              ,267            ,52             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,37             ,True           ,51             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.012          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.043          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.011          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 24, 3, 267, 52, 6, 9, 37, True, 51, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.012, True, 20, 0.043, 96, 1, 20, categorical_crossentropy, 0.011, val_acc, adagrad, 4, False, 128, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:28)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1190 - acc: 0.9706
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0850 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1117 - acc: 0.9726
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0911 - acc: 0.9764
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0831 - acc: 0.9779
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0775 - acc: 0.9791
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 2.05 minutes 
==================================================================================================
	Identification : 0.011
	P, R  : 0.006, 0.073

==================================================================================================
	XP Ends: 20/9 (20 h:33)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:33)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.2284 - acc: 0.9313
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.2661 - acc: 0.9670
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.5266 - acc: 0.8644
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.2623 - acc: 0.9741
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.2857 - acc: 0.9230
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0500 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.2337 - acc: 0.9314
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0481 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.2105 - acc: 0.9356
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0473 - acc: 0.9887
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.1968 - acc: 0.9389
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0470 - acc: 0.9887
Should stop early?
POS tagging: 9
Epoch 1/1
 - 3s - loss: 0.1872 - acc: 0.9412
MWE identification: 7
Epoch 1/1
 - 7s - loss: 0.0469 - acc: 0.9888
Should stop early?
Early stopping applied
POS tagging accuracy = 93.3
POS tagging accuracy (MWEs) = 93.3
	TRAINING TIME: 2.32 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.598
	P, R  : 0.681, 0.533

==================================================================================================
	XP Ends: 20/9 (20 h:37)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:37)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1584 - acc: 0.9541
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0767 - acc: 0.9813
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.3621 - acc: 0.9111
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0536 - acc: 0.9872
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.2166 - acc: 0.9440
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0482 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1683 - acc: 0.9541
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0468 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1456 - acc: 0.9599
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0460 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 92.0
POS tagging accuracy (MWEs) = 92.0
	TRAINING TIME: 3.08 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.506
	P, R  : 0.537, 0.478

==================================================================================================
	XP Ends: 20/9 (20 h:41)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
13             ,1              ,81             ,30             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
19             ,43             ,True           ,70             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.01           ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.008          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 13, 1, 81, 30, 5, 19, 43, True, 70, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.01, False, 20, 0.006, 96, 1, 20, categorical_crossentropy, 0.008, val_acc, adagrad, 4, False, 64, 0.008, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:41)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3836 - acc: 0.9070
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1269 - acc: 0.9692
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0972 - acc: 0.9746
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0903 - acc: 0.9769
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0812 - acc: 0.9779
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0637 - acc: 0.9842
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0711 - acc: 0.9799
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0586 - acc: 0.9855
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0649 - acc: 0.9816
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0557 - acc: 0.9863
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0603 - acc: 0.9828
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0539 - acc: 0.9868
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0565 - acc: 0.9840
MWE identification: 6
Epoch 1/1
 - 10s - loss: 0.0526 - acc: 0.9873
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.95 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.588
	P, R  : 0.842, 0.452

==================================================================================================
	XP Ends: 20/9 (20 h:45)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:45)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5031 - acc: 0.8631
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2385 - acc: 0.9287
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1967 - acc: 0.9380
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1142 - acc: 0.9712
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1730 - acc: 0.9450
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0719 - acc: 0.9821
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1564 - acc: 0.9500
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0650 - acc: 0.9838
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1462 - acc: 0.9531
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0614 - acc: 0.9848
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1385 - acc: 0.9553
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0588 - acc: 0.9854
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.1321 - acc: 0.9577
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0570 - acc: 0.9861
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.42 minutes 
==================================================================================================
	PARSING TIME: 1.77 minutes 
==================================================================================================
	Identification : 0.612
	P, R  : 0.887, 0.467

==================================================================================================
	XP Ends: 20/9 (20 h:50)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:50)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4625 - acc: 0.8796
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1727 - acc: 0.9504
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1254 - acc: 0.9629
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0810 - acc: 0.9797
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1005 - acc: 0.9706
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0600 - acc: 0.9846
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0829 - acc: 0.9757
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0557 - acc: 0.9859
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0724 - acc: 0.9791
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0532 - acc: 0.9867
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0646 - acc: 0.9817
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0515 - acc: 0.9873
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.33 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.44
	P, R  : 0.612, 0.343

==================================================================================================
	XP Ends: 20/9 (20 h:54)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,9              ,49             ,29             ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,54             ,True           ,35             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.046          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.05           ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.024          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.035          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 9, 49, 29, 10, 7, 54, True, 35, True, False, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.046, True, 20, 0.05, 64, 1, 20, categorical_crossentropy, 0.024, val_acc, adagrad, 4, False, 128, 0.035, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:54)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.05
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1819 - acc: 0.9517
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0852 - acc: 0.9764
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0638 - acc: 0.9822
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0860 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0480 - acc: 0.9866
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0336 - acc: 0.9906
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0273 - acc: 0.9925
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0231 - acc: 0.9935
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.9 minutes 
==================================================================================================
	PARSING TIME: 1.97 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (20 h:59)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (20h:59)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.05
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2652 - acc: 0.9184
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1439 - acc: 0.9529
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1153 - acc: 0.9623
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0870 - acc: 0.2499
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0923 - acc: 0.9711
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0669 - acc: 0.9795
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0543 - acc: 0.9837
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0458 - acc: 0.9865
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.28 minutes 
==================================================================================================
	PARSING TIME: 2.75 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (21 h:5)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:5)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.05
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2189 - acc: 0.9358
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0798 - acc: 0.9763
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0470 - acc: 0.9864
MWE identification: 1
Epoch 1/1
 - 21s - loss: 8.0592 - acc: 0.4998
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0384 - acc: 0.9899
MWE identification: 2
Epoch 1/1
 - 21s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0173 - acc: 0.9955
MWE identification: 3
Epoch 1/1
 - 21s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0115 - acc: 0.9974
MWE identification: 4
Epoch 1/1
 - 21s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0085 - acc: 0.9982
MWE identification: 5
Epoch 1/1
 - 21s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 3.7 minutes 
==================================================================================================
	PARSING TIME: 1.57 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.133

==================================================================================================
	XP Ends: 20/9 (21 h:10)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,1              ,141            ,110            ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
19             ,75             ,True           ,32             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.018          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.032          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.073          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 1, 141, 110, 5, 19, 75, True, 32, True, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.018, True, 20, 0.032, 256, 1, 20, categorical_crossentropy, 0.008, val_loss, adagrad, 4, False, 256, 0.073, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:10)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.073
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1752 - acc: 0.9537
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0710 - acc: 0.9798
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0448 - acc: 0.9871
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0803 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0340 - acc: 0.9905
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0241 - acc: 0.9933
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0193 - acc: 0.9945
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0162 - acc: 0.9954
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0142 - acc: 0.9961
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.5
POS tagging accuracy (MWEs) = 95.5
	TRAINING TIME: 2.05 minutes 
==================================================================================================
	PARSING TIME: 2.55 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.11

==================================================================================================
	XP Ends: 20/9 (21 h:15)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:15)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.073
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2604 - acc: 0.9203
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1230 - acc: 0.9593
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0824 - acc: 0.9735
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1451 - acc: 0.9733
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0748 - acc: 0.9761
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0581 - acc: 0.9860
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0496 - acc: 0.9851
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0502 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0366 - acc: 0.9894
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0481 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0282 - acc: 0.9922
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0472 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 1.57 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.386
	P, R  : 0.284, 0.6

==================================================================================================
	XP Ends: 20/9 (21 h:19)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:19)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.073
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2103 - acc: 0.9390
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0603 - acc: 0.9815
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0273 - acc: 0.9923
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0892 - acc: 0.9812
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0249 - acc: 0.9933
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0493 - acc: 0.9882
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0117 - acc: 0.9972
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0462 - acc: 0.9891
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0073 - acc: 0.9985
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0456 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0051 - acc: 0.9991
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0453 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.3
POS tagging accuracy (MWEs) = 93.3
	TRAINING TIME: 2.37 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.413
	P, R  : 0.45, 0.382

==================================================================================================
	XP Ends: 20/9 (21 h:22)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,2              ,144            ,47             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
47             ,61             ,True           ,76             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.017          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.041          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.005          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.053          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 2, 144, 47, 7, 47, 61, True, 76, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.017, False, 20, 0.041, 256, 1, 20, categorical_crossentropy, 0.005, val_acc, adagrad, 4, False, 256, 0.053, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:22)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1694 - acc: 0.9544
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0742 - acc: 0.9788
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0488 - acc: 0.9862
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0800 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0405 - acc: 0.9886
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0278 - acc: 0.9920
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0223 - acc: 0.9936
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0187 - acc: 0.9947
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 2.08 minutes 
==================================================================================================
	Identification : 0.001
	P, R  : 0.001, 0.001

==================================================================================================
	XP Ends: 20/9 (21 h:26)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:26)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2537 - acc: 0.9213
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1284 - acc: 0.9575
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0913 - acc: 0.9705
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0778 - acc: 0.2499
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0762 - acc: 0.9761
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0545 - acc: 0.9833
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0432 - acc: 0.9873
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0354 - acc: 0.9899
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 1.55 minutes 
==================================================================================================
	PARSING TIME: 3.0 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.061

==================================================================================================
	XP Ends: 20/9 (21 h:31)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:31)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2069 - acc: 0.9392
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0656 - acc: 0.9800
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0316 - acc: 0.9911
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.6977 - acc: 0.9440
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0428 - acc: 0.9879
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0538 - acc: 0.9878
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0198 - acc: 0.9949
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0472 - acc: 0.9890
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0118 - acc: 0.9973
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0462 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0081 - acc: 0.9983
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0457 - acc: 0.9892
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0061 - acc: 0.9988
MWE identification: 6
Epoch 1/1
 - 6s - loss: 0.0455 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.439
	P, R  : 0.481, 0.404

==================================================================================================
	XP Ends: 20/9 (21 h:35)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,3              ,28             ,70             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,25             ,True           ,44             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.016          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.021          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.072          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 3, 28, 70, 6, 6, 25, True, 44, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.016, True, 20, 0.006, 128, 1, 20, categorical_crossentropy, 0.021, val_loss, adagrad, 4, False, 64, 0.072, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:35)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.072
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1748 - acc: 0.9538
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0707 - acc: 0.9798
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0564 - acc: 0.9831
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0882 - acc: 0.9773
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0299 - acc: 0.9912
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0703 - acc: 0.9823
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0201 - acc: 0.9942
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0647 - acc: 0.9840
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0159 - acc: 0.9953
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0614 - acc: 0.9849
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0132 - acc: 0.9962
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0591 - acc: 0.9856
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.469
	P, R  : 0.428, 0.519

==================================================================================================
	XP Ends: 20/9 (21 h:39)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:39)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.072
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2600 - acc: 0.9205
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1231 - acc: 0.9596
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1030 - acc: 0.9656
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0988 - acc: 0.9740
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0554 - acc: 0.9822
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0759 - acc: 0.9810
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0361 - acc: 0.9890
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0692 - acc: 0.9829
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0261 - acc: 0.9924
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0655 - acc: 0.9839
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0199 - acc: 0.9945
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0627 - acc: 0.9845
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.384
	P, R  : 0.29, 0.566

==================================================================================================
	XP Ends: 20/9 (21 h:43)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:43)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.072
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2109 - acc: 0.9391
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0601 - acc: 0.9815
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0378 - acc: 0.9883
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0772 - acc: 0.9806
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0138 - acc: 0.9961
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0614 - acc: 0.9847
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0066 - acc: 0.9984
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0566 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0040 - acc: 0.9993
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0538 - acc: 0.9869
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0028 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0518 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 3.12 minutes 
==================================================================================================
	PARSING TIME: 0.65 minutes 
==================================================================================================
	Identification : 0.408
	P, R  : 0.415, 0.402

==================================================================================================
	XP Ends: 20/9 (21 h:47)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,1              ,163            ,128            ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
8              ,59             ,True           ,91             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.009          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.011          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.066          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.049          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 1, 163, 128, 13, 8, 59, True, 91, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.009, False, 20, 0.011, 96, 2, 20, categorical_crossentropy, 0.066, val_loss, adagrad, 4, False, 128, 0.049, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.049
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1697 - acc: 0.9543
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0757 - acc: 0.9787
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0544 - acc: 0.9841
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0797 - acc: 0.9799
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0368 - acc: 0.9894
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0592 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0259 - acc: 0.9926
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0534 - acc: 0.9871
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0207 - acc: 0.9941
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0503 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0173 - acc: 0.9951
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0485 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.15 minutes 
==================================================================================================
	Identification : 0.482
	P, R  : 0.477, 0.487

==================================================================================================
	XP Ends: 20/9 (21 h:51)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:51)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.049
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2548 - acc: 0.9211
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1312 - acc: 0.9565
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1015 - acc: 0.9664
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0885 - acc: 0.9770
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0709 - acc: 0.9774
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0636 - acc: 0.9843
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0507 - acc: 0.9844
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0571 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0393 - acc: 0.9882
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0536 - acc: 0.9870
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0318 - acc: 0.9909
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0514 - acc: 0.9877
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.02 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.385
	P, R  : 0.279, 0.62

==================================================================================================
	XP Ends: 20/9 (21 h:55)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:55)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.049
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2082 - acc: 0.9390
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0676 - acc: 0.9794
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0367 - acc: 0.9891
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0737 - acc: 0.9821
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0197 - acc: 0.9945
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0532 - acc: 0.9872
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0106 - acc: 0.9973
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0491 - acc: 0.9884
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0067 - acc: 0.9985
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0473 - acc: 0.9888
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0048 - acc: 0.9990
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0463 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 3.12 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.402
	P, R  : 0.471, 0.351

==================================================================================================
	XP Ends: 20/9 (21 h:59)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,1              ,60             ,45             ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,155            ,True           ,64             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.006          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.005          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.016          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 1, 60, 45, 13, 9, 155, True, 64, False, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.006, False, 20, 0.005, 96, 2, 20, categorical_crossentropy, 0.006, val_loss, adagrad, 4, False, 256, 0.016, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (21h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2418 - acc: 0.9382
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1154 - acc: 0.9688
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0936 - acc: 0.9750
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0969 - acc: 0.9741
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0825 - acc: 0.9779
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0705 - acc: 0.9825
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0707 - acc: 0.9813
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0638 - acc: 0.9845
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0624 - acc: 0.9835
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0599 - acc: 0.9855
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0559 - acc: 0.9854
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0573 - acc: 0.9862
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.48 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.486
	P, R  : 0.448, 0.53

==================================================================================================
	XP Ends: 20/9 (22 h:3)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:3)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3363 - acc: 0.9025
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1871 - acc: 0.9406
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1589 - acc: 0.9492
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1118 - acc: 0.9691
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1446 - acc: 0.9541
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0766 - acc: 0.9807
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1283 - acc: 0.9595
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0690 - acc: 0.9830
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1166 - acc: 0.9637
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0648 - acc: 0.9841
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1071 - acc: 0.9667
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0618 - acc: 0.9848
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.97 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.283
	P, R  : 0.183, 0.626

==================================================================================================
	XP Ends: 20/9 (22 h:7)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:7)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2996 - acc: 0.9162
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1249 - acc: 0.9635
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0888 - acc: 0.9754
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0846 - acc: 0.9785
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0695 - acc: 0.9813
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0613 - acc: 0.9851
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0528 - acc: 0.9862
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0558 - acc: 0.9866
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0427 - acc: 0.9893
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0529 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0357 - acc: 0.9914
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0510 - acc: 0.9880
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 3.1 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.392
	P, R  : 0.481, 0.331

==================================================================================================
	XP Ends: 20/9 (22 h:11)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,6              ,284            ,196            ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,155            ,True           ,79             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.035          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.026          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.061          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.062          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 6, 284, 196, 8, 7, 155, True, 79, True, False, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.035, False, 20, 0.026, 128, 1, 20, categorical_crossentropy, 0.061, val_loss, adagrad, 4, False, 64, 0.062, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:11)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1716 - acc: 0.9540
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0719 - acc: 0.9796
POS tagging: 3
Epoch 1/1
 - 7s - loss: 0.0565 - acc: 0.9831
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0864 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0359 - acc: 0.9892
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0549 - acc: 0.9870
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0226 - acc: 0.9933
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0483 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0172 - acc: 0.9949
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0461 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0140 - acc: 0.9958
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0452 - acc: 0.9894
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.58 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.485
	P, R  : 0.498, 0.473

==================================================================================================
	XP Ends: 20/9 (22 h:15)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:15)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2559 - acc: 0.9210
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1253 - acc: 0.9583
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1046 - acc: 0.9649
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0932 - acc: 0.9785
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0680 - acc: 0.9781
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0568 - acc: 0.9860
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0434 - acc: 0.9865
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0504 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0314 - acc: 0.9906
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0481 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0239 - acc: 0.9933
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0472 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.397
	P, R  : 0.298, 0.593

==================================================================================================
	XP Ends: 20/9 (22 h:19)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:19)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2093 - acc: 0.9386
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0620 - acc: 0.9809
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0389 - acc: 0.9878
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0701 - acc: 0.9830
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0198 - acc: 0.9942
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0495 - acc: 0.9880
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0084 - acc: 0.9978
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0464 - acc: 0.9890
POS tagging: 6
Epoch 1/1
 - 7s - loss: 0.0048 - acc: 0.9990
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0456 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0032 - acc: 0.9994
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0453 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 3.15 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.422
	P, R  : 0.426, 0.418

==================================================================================================
	XP Ends: 20/9 (22 h:24)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,1              ,118            ,41             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,72             ,True           ,53             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.023          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.058          ,64             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.019          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 1, 118, 41, 5, 7, 72, True, 53, True, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.023, True, 20, 0.058, 64, 2, 20, categorical_crossentropy, 0.006, val_loss, adagrad, 4, False, 96, 0.019, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.058
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2225 - acc: 0.9422
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1080 - acc: 0.9708
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0866 - acc: 0.9764
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0869 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0731 - acc: 0.9802
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0545 - acc: 0.9853
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0461 - acc: 0.9876
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0402 - acc: 0.9891
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 3.0 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (22 h:29)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:29)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.058
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3130 - acc: 0.9077
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1760 - acc: 0.9434
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1489 - acc: 0.9518
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0858 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1309 - acc: 0.9586
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1043 - acc: 0.9675
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0908 - acc: 0.9719
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0809 - acc: 0.9756
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.35 minutes 
==================================================================================================
	PARSING TIME: 2.75 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (22 h:34)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:34)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.058
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2747 - acc: 0.9223
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1126 - acc: 0.9671
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.0770 - acc: 0.9777
MWE identification: 1
Epoch 1/1
 - 20s - loss: 12.0876 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0592 - acc: 0.9843
MWE identification: 2
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0350 - acc: 0.9910
MWE identification: 3
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0264 - acc: 0.9935
MWE identification: 4
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0212 - acc: 0.9949
MWE identification: 5
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 3.75 minutes 
==================================================================================================
	PARSING TIME: 1.35 minutes 
==================================================================================================
	Identification : 0.0
	P, R  : 0.0, 0.002

==================================================================================================
	XP Ends: 20/9 (22 h:40)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,3              ,44             ,35             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,45             ,True           ,60             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.033          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.01           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 3, 44, 35, 5, 6, 45, True, 60, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.033, False, 20, 0.008, 96, 1, 20, categorical_crossentropy, 0.006, val_acc, adagrad, 4, False, 64, 0.01, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:40)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3333 - acc: 0.9167
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1442 - acc: 0.9621
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1163 - acc: 0.9687
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0921 - acc: 0.9766
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0987 - acc: 0.9734
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0626 - acc: 0.9847
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0845 - acc: 0.9775
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0560 - acc: 0.9866
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0757 - acc: 0.9800
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0524 - acc: 0.9876
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0690 - acc: 0.9818
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0503 - acc: 0.9882
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0636 - acc: 0.9833
MWE identification: 6
Epoch 1/1
 - 11s - loss: 0.0490 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 3.05 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.518
	P, R  : 0.527, 0.51

==================================================================================================
	XP Ends: 20/9 (22 h:44)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:44)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4358 - acc: 0.8792
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2236 - acc: 0.9319
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1897 - acc: 0.9398
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1126 - acc: 0.9722
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1690 - acc: 0.9461
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0687 - acc: 0.9830
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1493 - acc: 0.9527
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0614 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1370 - acc: 0.9568
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0574 - acc: 0.9862
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1276 - acc: 0.9601
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0547 - acc: 0.9870
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.1198 - acc: 0.9627
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0530 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.43 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.353
	P, R  : 0.249, 0.608

==================================================================================================
	XP Ends: 20/9 (22 h:48)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:48)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4026 - acc: 0.8913
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1673 - acc: 0.9511
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1213 - acc: 0.9648
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0798 - acc: 0.9805
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0911 - acc: 0.9747
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0553 - acc: 0.9868
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0700 - acc: 0.9813
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0506 - acc: 0.9882
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0580 - acc: 0.9851
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0485 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0497 - acc: 0.9875
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0473 - acc: 0.9890
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0435 - acc: 0.9893
MWE identification: 6
Epoch 1/1
 - 15s - loss: 0.0466 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 3.75 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.369
	P, R  : 0.484, 0.298

==================================================================================================
	XP Ends: 20/9 (22 h:53)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,7              ,217            ,166            ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,136            ,True           ,28             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.009          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.03           ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.005          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.031          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 7, 217, 166, 9, 5, 136, True, 28, False, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.009, True, 20, 0.03, 128, 1, 20, categorical_crossentropy, 0.005, val_loss, adagrad, 4, False, 96, 0.031, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:53)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1893 - acc: 0.9501
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0893 - acc: 0.9754
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.0689 - acc: 0.9807
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0847 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0482 - acc: 0.9867
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0351 - acc: 0.9900
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0288 - acc: 0.9919
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0246 - acc: 0.9931
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.42 minutes 
==================================================================================================
	PARSING TIME: 2.37 minutes 
==================================================================================================
	Identification : 0.011
	P, R  : 0.006, 0.11

==================================================================================================
	XP Ends: 20/9 (22 h:58)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (22h:58)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2729 - acc: 0.9170
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1498 - acc: 0.9512
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1236 - acc: 0.9594
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1140 - acc: 0.9769
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1110 - acc: 0.9646
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0659 - acc: 0.9857
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0820 - acc: 0.9748
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0518 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0666 - acc: 0.9799
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0488 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0559 - acc: 0.9835
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0476 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.389
	P, R  : 0.285, 0.613

==================================================================================================
	XP Ends: 20/9 (23 h:2)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:2)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2288 - acc: 0.9335
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0852 - acc: 0.9749
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0534 - acc: 0.9843
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.1046 - acc: 0.9813
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0458 - acc: 0.9876
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0590 - acc: 0.9877
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0244 - acc: 0.9937
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0472 - acc: 0.9890
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0159 - acc: 0.9962
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0464 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0117 - acc: 0.9974
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0458 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.5
POS tagging accuracy (MWEs) = 92.5
	TRAINING TIME: 2.97 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.452
	P, R  : 0.478, 0.429

==================================================================================================
	XP Ends: 20/9 (23 h:6)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,4              ,32             ,143            ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
47             ,78             ,True           ,45             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.012          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.009          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.024          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.077          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 4, 32, 143, 7, 47, 78, True, 45, True, True, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.012, True, 20, 0.009, 96, 1, 20, categorical_crossentropy, 0.024, val_loss, adagrad, 4, False, 128, 0.077, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:6)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.077
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1785 - acc: 0.9534
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0711 - acc: 0.9797
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0500 - acc: 0.9853
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0825 - acc: 0.9790
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0312 - acc: 0.9910
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0642 - acc: 0.9838
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0212 - acc: 0.9939
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0586 - acc: 0.9856
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0168 - acc: 0.9951
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0553 - acc: 0.9865
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0139 - acc: 0.9959
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0530 - acc: 0.9872
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.464
	P, R  : 0.461, 0.467

==================================================================================================
	XP Ends: 20/9 (23 h:10)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:10)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.077
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2630 - acc: 0.9195
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1232 - acc: 0.9594
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0922 - acc: 0.9697
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0902 - acc: 0.9766
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0578 - acc: 0.9816
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0687 - acc: 0.9830
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0385 - acc: 0.9883
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0624 - acc: 0.9847
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0281 - acc: 0.9919
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0588 - acc: 0.9857
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0214 - acc: 0.9940
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0561 - acc: 0.9864
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.05 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.381
	P, R  : 0.279, 0.6

==================================================================================================
	XP Ends: 20/9 (23 h:14)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:14)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.077
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2112 - acc: 0.9389
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0598 - acc: 0.9818
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0309 - acc: 0.9907
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0739 - acc: 0.9816
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0148 - acc: 0.9961
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0576 - acc: 0.9857
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0075 - acc: 0.9983
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0528 - acc: 0.9871
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0046 - acc: 0.9991
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0503 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0033 - acc: 0.9994
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0486 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 3.2 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.376
	P, R  : 0.44, 0.329

==================================================================================================
	XP Ends: 20/9 (23 h:19)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
17             ,5              ,267            ,40             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
24             ,50             ,True           ,148            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.032          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.018          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.044          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 17, 5, 267, 40, 8, 24, 50, True, 148, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.032, True, 20, 0.018, 128, 1, 20, categorical_crossentropy, 0.006, val_acc, adagrad, 4, False, 96, 0.044, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:19)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1446 - acc: 0.9621
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0572 - acc: 0.9832
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0443 - acc: 0.9864
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0824 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0317 - acc: 0.9904
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0567 - acc: 0.9861
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0208 - acc: 0.9938
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0509 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0156 - acc: 0.9952
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0482 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0126 - acc: 0.9962
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0469 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.37 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.574
	P, R  : 0.746, 0.466

==================================================================================================
	XP Ends: 20/9 (23 h:22)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:22)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2490 - acc: 0.9232
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1302 - acc: 0.9564
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1075 - acc: 0.9635
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0982 - acc: 0.9778
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0801 - acc: 0.9737
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0620 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0584 - acc: 0.9816
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0542 - acc: 0.9869
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0462 - acc: 0.9858
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0512 - acc: 0.9878
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0380 - acc: 0.9888
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0495 - acc: 0.9882
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0318 - acc: 0.9907
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0486 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 1.87 minutes 
==================================================================================================
	Identification : 0.584
	P, R  : 0.653, 0.528

==================================================================================================
	XP Ends: 20/9 (23 h:27)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:27)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1932 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0683 - acc: 0.9778
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0465 - acc: 0.9849
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0950 - acc: 0.9808
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0282 - acc: 0.9915
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0542 - acc: 0.9863
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0143 - acc: 0.9962
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0497 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0084 - acc: 0.9981
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0476 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0055 - acc: 0.9989
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0465 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.93 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.426
	P, R  : 0.579, 0.337

==================================================================================================
	XP Ends: 20/9 (23 h:31)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
11             ,8              ,70             ,31             ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
12             ,41             ,True           ,48             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.044          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.043          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.007          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.025          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 11, 8, 70, 31, 11, 12, 41, True, 48, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.044, False, 20, 0.043, 96, 1, 20, categorical_crossentropy, 0.007, val_acc, adagrad, 4, False, 64, 0.025, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:31)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1683 - acc: 0.9572
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0714 - acc: 0.9799
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0583 - acc: 0.9829
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0860 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0409 - acc: 0.9880
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0297 - acc: 0.9913
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0240 - acc: 0.9929
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0203 - acc: 0.9942
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.7 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (23 h:35)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:35)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2798 - acc: 0.9161
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1541 - acc: 0.9498
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1326 - acc: 0.9556
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.5545 - acc: 0.9498
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1677 - acc: 0.9491
MWE identification: 2
Epoch 1/1
 - 7s - loss: 4.0316 - acc: 0.7495
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1058 - acc: 0.9660
MWE identification: 3
Epoch 1/1
 - 7s - loss: 4.0306 - acc: 0.7497
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0880 - acc: 0.9718
MWE identification: 4
Epoch 1/1
 - 7s - loss: 4.0303 - acc: 0.7498
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0768 - acc: 0.9756
MWE identification: 5
Epoch 1/1
 - 7s - loss: 4.0303 - acc: 0.7498
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.2 minutes 
==================================================================================================
	PARSING TIME: 2.9 minutes 
==================================================================================================
	Identification : 0.03
	P, R  : 0.017, 0.116

==================================================================================================
	XP Ends: 20/9 (23 h:41)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:41)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2284 - acc: 0.9347
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0881 - acc: 0.9726
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0661 - acc: 0.9790
MWE identification: 1
Epoch 1/1
 - 14s - loss: 12.0865 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0436 - acc: 0.9871
MWE identification: 2
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0259 - acc: 0.9928
MWE identification: 3
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0183 - acc: 0.9954
MWE identification: 4
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0138 - acc: 0.9969
MWE identification: 5
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.35 minutes 
==================================================================================================
	PARSING TIME: 1.13 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (23 h:46)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,4              ,40             ,69             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
38             ,72             ,True           ,123            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.035          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.055          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.07           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.053          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 4, 40, 69, 5, 38, 72, True, 123, True, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.035, True, 20, 0.055, 256, 1, 20, categorical_crossentropy, 0.07, val_loss, adagrad, 4, False, 256, 0.053, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1401 - acc: 0.9628
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0543 - acc: 0.9837
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0358 - acc: 0.9892
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0816 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0295 - acc: 0.9912
MWE identification: 2
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0199 - acc: 0.9940
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0153 - acc: 0.9953
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0125 - acc: 0.9962
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0105 - acc: 0.9968
MWE identification: 6
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.03 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 20/9 (23 h:50)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:50)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2482 - acc: 0.9233
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1252 - acc: 0.9583
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0915 - acc: 0.9697
MWE identification: 1
Epoch 1/1
 - 3s - loss: 1.6932 - acc: 0.8775
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1618 - acc: 0.9503
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.4953 - acc: 0.9579
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0972 - acc: 0.9694
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0562 - acc: 0.9869
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0710 - acc: 0.9779
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0505 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0571 - acc: 0.9827
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0485 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 1.57 minutes 
==================================================================================================
	PARSING TIME: 1.62 minutes 
==================================================================================================
	Identification : 0.615
	P, R  : 0.853, 0.481

==================================================================================================
	XP Ends: 20/9 (23 h:53)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:53)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1900 - acc: 0.9441
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0643 - acc: 0.9788
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0357 - acc: 0.9889
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0795 - acc: 0.2503
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0274 - acc: 0.9919
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0143 - acc: 0.9962
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0089 - acc: 0.9980
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0061 - acc: 0.9988
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0043 - acc: 0.9993
MWE identification: 6
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.45 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0.026
	P, R  : 0.02, 0.037

==================================================================================================
	XP Ends: 20/9 (23 h:57)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,5              ,91             ,45             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,106            ,True           ,28             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.007          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.043          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.012          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 5, 91, 45, 12, 9, 106, True, 28, False, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.007, True, 20, 0.008, 96, 2, 20, categorical_crossentropy, 0.043, val_loss, adagrad, 4, False, 64, 0.012, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/9 (23h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2909 - acc: 0.9269
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1317 - acc: 0.9650
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1069 - acc: 0.9710
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0913 - acc: 0.9771
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0882 - acc: 0.9763
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0628 - acc: 0.9847
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0744 - acc: 0.9802
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0563 - acc: 0.9865
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0657 - acc: 0.9827
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0528 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0592 - acc: 0.9843
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0507 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.73 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0.508
	P, R  : 0.485, 0.533

==================================================================================================
	XP Ends: 21/9 (0 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3890 - acc: 0.8907
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2081 - acc: 0.9353
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1776 - acc: 0.9431
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1089 - acc: 0.9723
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1540 - acc: 0.9510
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0687 - acc: 0.9829
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1346 - acc: 0.9575
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0615 - acc: 0.9851
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1222 - acc: 0.9616
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0576 - acc: 0.9862
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1127 - acc: 0.9649
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0550 - acc: 0.9869
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.22 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.34
	P, R  : 0.235, 0.617

==================================================================================================
	XP Ends: 21/9 (0 h:6)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:6)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3548 - acc: 0.9026
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1481 - acc: 0.9566
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1067 - acc: 0.9690
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0788 - acc: 0.9806
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0765 - acc: 0.9790
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0547 - acc: 0.9869
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0565 - acc: 0.9849
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0503 - acc: 0.9882
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0457 - acc: 0.9882
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0483 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0385 - acc: 0.9905
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0471 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 93.2
POS tagging accuracy (MWEs) = 93.2
	TRAINING TIME: 3.4 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.381
	P, R  : 0.471, 0.32

==================================================================================================
	XP Ends: 21/9 (0 h:10)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,5              ,188            ,53             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
10             ,67             ,True           ,52             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.038          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.01           ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.095          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.068          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 5, 188, 53, 6, 10, 67, True, 52, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.038, True, 20, 0.01, 128, 1, 20, categorical_crossentropy, 0.095, val_loss, adagrad, 4, False, 128, 0.068, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:10)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.068
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1474 - acc: 0.9618
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0530 - acc: 0.9841
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0384 - acc: 0.9881
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0800 - acc: 0.9800
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0244 - acc: 0.9924
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0616 - acc: 0.9845
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0159 - acc: 0.9950
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0565 - acc: 0.9860
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0119 - acc: 0.9962
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0534 - acc: 0.9870
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0095 - acc: 0.9970
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0514 - acc: 0.9876
Should stop early?
Early stopping applied
POS tagging accuracy = 96.0
POS tagging accuracy (MWEs) = 96.0
	TRAINING TIME: 2.32 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.547
	P, R  : 0.68, 0.457

==================================================================================================
	XP Ends: 21/9 (0 h:14)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:14)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.068
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2497 - acc: 0.9235
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1202 - acc: 0.9594
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0934 - acc: 0.9684
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0914 - acc: 0.9765
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0625 - acc: 0.9796
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0673 - acc: 0.9830
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0430 - acc: 0.9867
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0609 - acc: 0.9849
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0321 - acc: 0.9902
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0574 - acc: 0.9858
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0248 - acc: 0.9927
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0549 - acc: 0.9865
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.85 minutes 
==================================================================================================
	PARSING TIME: 1.87 minutes 
==================================================================================================
	Identification : 0.523
	P, R  : 0.545, 0.503

==================================================================================================
	XP Ends: 21/9 (0 h:18)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:18)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.068
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1948 - acc: 0.9435
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0608 - acc: 0.9800
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0377 - acc: 0.9878
MWE identification: 1
Epoch 1/1
 - 12s - loss: 0.0743 - acc: 0.9810
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0192 - acc: 0.9942
MWE identification: 2
Epoch 1/1
 - 12s - loss: 0.0583 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0092 - acc: 0.9976
MWE identification: 3
Epoch 1/1
 - 12s - loss: 0.0540 - acc: 0.9862
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0051 - acc: 0.9989
MWE identification: 4
Epoch 1/1
 - 12s - loss: 0.0516 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0032 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 12s - loss: 0.0498 - acc: 0.9878
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.93 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.466
	P, R  : 0.601, 0.38

==================================================================================================
	XP Ends: 21/9 (0 h:22)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,6              ,147            ,86             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
29             ,25             ,True           ,62             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.032          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.022          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.051          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.031          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 6, 147, 86, 5, 29, 25, True, 62, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.032, True, 20, 0.022, 256, 1, 20, categorical_crossentropy, 0.051, val_loss, adagrad, 4, False, 128, 0.031, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:22)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1598 - acc: 0.9591
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0662 - acc: 0.9811
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0511 - acc: 0.9850
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1104 - acc: 0.9790
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0443 - acc: 0.9870
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0607 - acc: 0.9861
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0320 - acc: 0.9907
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0512 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0250 - acc: 0.9928
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0484 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0207 - acc: 0.9941
MWE identification: 5
Epoch 1/1
 - 4s - loss: 0.0471 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.05 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.564
	P, R  : 0.676, 0.484

==================================================================================================
	XP Ends: 21/9 (0 h:25)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:25)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2649 - acc: 0.9196
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1445 - acc: 0.9521
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1197 - acc: 0.9599
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1442 - acc: 0.9735
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1041 - acc: 0.9664
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0713 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0819 - acc: 0.9739
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0548 - acc: 0.9871
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0682 - acc: 0.9785
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0513 - acc: 0.9879
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0588 - acc: 0.9819
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0496 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.75 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.572
	P, R  : 0.67, 0.499

==================================================================================================
	XP Ends: 21/9 (0 h:29)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:29)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2130 - acc: 0.9385
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0800 - acc: 0.9748
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0557 - acc: 0.9824
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.1112 - acc: 0.9786
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0462 - acc: 0.9864
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0590 - acc: 0.9860
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0273 - acc: 0.9925
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0506 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0182 - acc: 0.9954
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0483 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0134 - acc: 0.9970
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0471 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.448
	P, R  : 0.64, 0.345

==================================================================================================
	XP Ends: 21/9 (0 h:33)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
12             ,4              ,76             ,43             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,173            ,True           ,29             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.021          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.042          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.005          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.008          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 12, 4, 76, 43, 5, 7, 173, True, 29, True, False, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.021, False, 20, 0.042, 256, 1, 20, categorical_crossentropy, 0.005, val_acc, adagrad, 4, False, 256, 0.008, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:33)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.042
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4035 - acc: 0.8996
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1648 - acc: 0.9573
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1369 - acc: 0.9641
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0816 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1352 - acc: 0.9650
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1143 - acc: 0.9699
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1048 - acc: 0.9725
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0976 - acc: 0.9745
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 2.53 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.119

==================================================================================================
	XP Ends: 21/9 (0 h:38)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:38)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.042
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5093 - acc: 0.8614
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2472 - acc: 0.9262
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.2129 - acc: 0.9349
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1607 - acc: 0.9693
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.6490 - acc: 0.8417
MWE identification: 2
Epoch 1/1
 - 3s - loss: 4.0388 - acc: 0.7485
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.2793 - acc: 0.9214
MWE identification: 3
Epoch 1/1
 - 3s - loss: 4.0311 - acc: 0.7496
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.2288 - acc: 0.9321
MWE identification: 4
Epoch 1/1
 - 3s - loss: 4.0304 - acc: 0.7498
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.2082 - acc: 0.9368
MWE identification: 5
Epoch 1/1
 - 3s - loss: 4.0303 - acc: 0.7498
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 1.58 minutes 
==================================================================================================
	PARSING TIME: 3.07 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.049

==================================================================================================
	XP Ends: 21/9 (0 h:42)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:42)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.042
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4780 - acc: 0.8729
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1955 - acc: 0.9440
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1506 - acc: 0.9571
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0817 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1601 - acc: 0.9563
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1175 - acc: 0.9673
MWE identification: 3
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1018 - acc: 0.9722
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0904 - acc: 0.9759
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 2.37 minutes 
==================================================================================================
	PARSING TIME: 1.22 minutes 
==================================================================================================
	Identification : 0.001
	P, R  : 0.001, 0.002

==================================================================================================
	XP Ends: 21/9 (0 h:46)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
21             ,4              ,66             ,54             ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
19             ,132            ,True           ,87             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.037          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.024          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.035          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.009          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 21, 4, 66, 54, 10, 19, 132, True, 87, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.037, True, 20, 0.024, 256, 1, 20, categorical_crossentropy, 0.035, val_loss, adagrad, 4, False, 96, 0.009, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.024
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3404 - acc: 0.9175
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1174 - acc: 0.9710
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0925 - acc: 0.9755
MWE identification: 1
Epoch 1/1
 - 4s - loss: 8.0580 - acc: 0.4992
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0877 - acc: 0.9771
MWE identification: 2
Epoch 1/1
 - 4s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0696 - acc: 0.9806
MWE identification: 3
Epoch 1/1
 - 4s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0626 - acc: 0.9824
MWE identification: 4
Epoch 1/1
 - 4s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0575 - acc: 0.9836
MWE identification: 5
Epoch 1/1
 - 4s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.13 minutes 
==================================================================================================
	PARSING TIME: 2.38 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 21/9 (0 h:51)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:51)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.024
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4607 - acc: 0.8733
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2251 - acc: 0.9318
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1893 - acc: 0.9399
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0655 - acc: 0.2506
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1714 - acc: 0.9459
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1514 - acc: 0.9513
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1408 - acc: 0.9548
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1326 - acc: 0.9574
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.1258 - acc: 0.9597
MWE identification: 6
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.87 minutes 
==================================================================================================
	PARSING TIME: 3.0 minutes 
==================================================================================================
	Identification : 0.029
	P, R  : 0.016, 0.143

==================================================================================================
	XP Ends: 21/9 (0 h:56)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (0h:56)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.024
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4136 - acc: 0.8914
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1581 - acc: 0.9540
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1180 - acc: 0.9651
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0992 - acc: 0.9796
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1315 - acc: 0.9639
MWE identification: 2
Epoch 1/1
 - 6s - loss: 4.0289 - acc: 0.7498
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0898 - acc: 0.9739
MWE identification: 3
Epoch 1/1
 - 6s - loss: 3.9846 - acc: 0.7526
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0764 - acc: 0.9779
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0562 - acc: 0.9865
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0736 - acc: 0.9794
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0490 - acc: 0.9884
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0645 - acc: 0.9821
MWE identification: 6
Epoch 1/1
 - 6s - loss: 0.0472 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.72 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.433
	P, R  : 0.634, 0.329

==================================================================================================
	XP Ends: 21/9 (1 h:0)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
11             ,1              ,27             ,71             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,137            ,True           ,35             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.02           ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.032          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.05           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.007          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 11, 1, 27, 71, 12, 7, 137, True, 35, False, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.02, False, 20, 0.032, 128, 2, 20, categorical_crossentropy, 0.05, val_loss, adagrad, 4, False, 64, 0.007, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:0)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4404 - acc: 0.8938
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1397 - acc: 0.9666
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1044 - acc: 0.9733
MWE identification: 1
Epoch 1/1
 - 8s - loss: 8.0583 - acc: 0.4997
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1046 - acc: 0.9741
MWE identification: 2
Epoch 1/1
 - 8s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0801 - acc: 0.9781
MWE identification: 3
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0726 - acc: 0.9798
MWE identification: 4
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0675 - acc: 0.9809
MWE identification: 5
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 2.38 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 21/9 (1 h:5)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:5)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5602 - acc: 0.8488
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2567 - acc: 0.9246
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.2079 - acc: 0.9354
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1110 - acc: 0.9767
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.2626 - acc: 0.9264
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.1021 - acc: 0.9835
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.2047 - acc: 0.9388
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0510 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1808 - acc: 0.9441
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0488 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1671 - acc: 0.9474
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0477 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.626, 0.55

==================================================================================================
	XP Ends: 21/9 (1 h:10)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:10)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5174 - acc: 0.8655
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1913 - acc: 0.9468
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1372 - acc: 0.9598
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0845 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1197 - acc: 0.9660
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0933 - acc: 0.9728
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0819 - acc: 0.9763
MWE identification: 4
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0737 - acc: 0.9790
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 3.1 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.125

==================================================================================================
	XP Ends: 21/9 (1 h:15)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
14             ,2              ,37             ,156            ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
25             ,73             ,True           ,102            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.031          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.049          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.013          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.017          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 14, 2, 37, 156, 9, 25, 73, True, 102, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.031, False, 20, 0.049, 256, 1, 20, categorical_crossentropy, 0.013, val_acc, adagrad, 4, False, 256, 0.017, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:15)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.049
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2036 - acc: 0.9496
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0842 - acc: 0.9772
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0675 - acc: 0.9811
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0816 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0686 - acc: 0.9814
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0524 - acc: 0.9851
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0458 - acc: 0.9873
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0408 - acc: 0.9887
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 1.95 minutes 
==================================================================================================
	PARSING TIME: 2.27 minutes 
==================================================================================================
	Identification : 0.01
	P, R  : 0.005, 0.145

==================================================================================================
	XP Ends: 21/9 (1 h:19)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:19)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.049
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3185 - acc: 0.9073
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1743 - acc: 0.9439
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1476 - acc: 0.9520
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0669 - acc: 0.2505
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1600 - acc: 0.9507
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1254 - acc: 0.9593
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1133 - acc: 0.9630
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1041 - acc: 0.9663
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.3
POS tagging accuracy (MWEs) = 94.3
	TRAINING TIME: 1.62 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (1 h:24)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:24)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.049
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2697 - acc: 0.9250
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1061 - acc: 0.9677
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0787 - acc: 0.9763
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0819 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0842 - acc: 0.9761
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0563 - acc: 0.9836
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0457 - acc: 0.9873
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0382 - acc: 0.9896
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.35 minutes 
==================================================================================================
	PARSING TIME: 1.18 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (1 h:28)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
17             ,4              ,112            ,96             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,62             ,True           ,81             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.005          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.015          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.022          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.044          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 17, 4, 112, 96, 9, 5, 62, True, 81, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.005, True, 20, 0.015, 128, 1, 20, categorical_crossentropy, 0.022, val_loss, adagrad, 4, False, 64, 0.044, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:28)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1446 - acc: 0.9621
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0572 - acc: 0.9832
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0467 - acc: 0.9856
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0819 - acc: 0.9805
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0295 - acc: 0.9911
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0572 - acc: 0.9858
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0194 - acc: 0.9941
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0519 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0146 - acc: 0.9955
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0491 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0117 - acc: 0.9964
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0476 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.567
	P, R  : 0.714, 0.47

==================================================================================================
	XP Ends: 21/9 (1 h:32)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:32)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2490 - acc: 0.9232
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1302 - acc: 0.9564
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1114 - acc: 0.9620
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0961 - acc: 0.9775
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0759 - acc: 0.9752
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0632 - acc: 0.9845
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0552 - acc: 0.9825
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0556 - acc: 0.9865
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0435 - acc: 0.9866
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0525 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0357 - acc: 0.9895
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0505 - acc: 0.9879
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.564
	P, R  : 0.644, 0.501

==================================================================================================
	XP Ends: 21/9 (1 h:36)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:36)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1931 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0683 - acc: 0.9778
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0497 - acc: 0.9836
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0833 - acc: 0.9813
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0256 - acc: 0.9921
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0549 - acc: 0.9861
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0129 - acc: 0.9966
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0504 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0075 - acc: 0.9983
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0482 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0049 - acc: 0.9991
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0469 - acc: 0.9888
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.07 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.464
	P, R  : 0.577, 0.388

==================================================================================================
	XP Ends: 21/9 (1 h:40)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
17             ,1              ,61             ,95             ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,25             ,True           ,32             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.007          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.014          ,64             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.026          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.021          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 17, 1, 61, 95, 13, 6, 25, True, 32, True, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.007, True, 20, 0.014, 64, 2, 20, categorical_crossentropy, 0.026, val_loss, adagrad, 4, False, 96, 0.021, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:40)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2118 - acc: 0.9450
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1034 - acc: 0.9720
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0825 - acc: 0.9776
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0796 - acc: 0.9807
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0670 - acc: 0.9819
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0553 - acc: 0.9867
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0522 - acc: 0.9859
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0501 - acc: 0.9882
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0438 - acc: 0.9881
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0478 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0380 - acc: 0.9897
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0466 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 3.0 minutes 
==================================================================================================
	PARSING TIME: 1.18 minutes 
==================================================================================================
	Identification : 0.496
	P, R  : 0.526, 0.469

==================================================================================================
	XP Ends: 21/9 (1 h:44)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:44)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3016 - acc: 0.9107
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1701 - acc: 0.9454
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1433 - acc: 0.9533
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0914 - acc: 0.9781
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1218 - acc: 0.9610
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0591 - acc: 0.9856
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0990 - acc: 0.9691
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0530 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0853 - acc: 0.9739
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0504 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0755 - acc: 0.9774
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0490 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.35 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.375
	P, R  : 0.275, 0.591

==================================================================================================
	XP Ends: 21/9 (1 h:49)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:49)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2623 - acc: 0.9252
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1062 - acc: 0.9688
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.0711 - acc: 0.9793
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0751 - acc: 0.9829
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0499 - acc: 0.9864
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0510 - acc: 0.9879
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0324 - acc: 0.9916
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0477 - acc: 0.9889
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0242 - acc: 0.9940
MWE identification: 4
Epoch 1/1
 - 21s - loss: 0.0466 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0192 - acc: 0.9954
MWE identification: 5
Epoch 1/1
 - 21s - loss: 0.0460 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 3.83 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.369
	P, R  : 0.432, 0.322

==================================================================================================
	XP Ends: 21/9 (1 h:54)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,2              ,216            ,135            ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
23             ,39             ,True           ,160            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.047          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.005          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.007          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.015          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 2, 216, 135, 7, 23, 39, True, 160, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.047, True, 20, 0.005, 128, 1, 20, categorical_crossentropy, 0.007, val_loss, adagrad, 4, False, 128, 0.015, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:54)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2225 - acc: 0.9456
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0901 - acc: 0.9760
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0727 - acc: 0.9798
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0919 - acc: 0.9765
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0597 - acc: 0.9827
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0673 - acc: 0.9833
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0501 - acc: 0.9858
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0617 - acc: 0.9849
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0437 - acc: 0.9879
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0587 - acc: 0.9856
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0390 - acc: 0.9893
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0567 - acc: 0.9861
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.28 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0.581
	P, R  : 0.762, 0.469

==================================================================================================
	XP Ends: 21/9 (1 h:58)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (1h:58)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3363 - acc: 0.9032
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1823 - acc: 0.9417
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1558 - acc: 0.9494
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1114 - acc: 0.9713
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1347 - acc: 0.9562
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0745 - acc: 0.9812
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1190 - acc: 0.9614
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0678 - acc: 0.9829
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1083 - acc: 0.9651
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0642 - acc: 0.9839
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0999 - acc: 0.9679
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0615 - acc: 0.9846
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 1.87 minutes 
==================================================================================================
	PARSING TIME: 1.82 minutes 
==================================================================================================
	Identification : 0.602
	P, R  : 0.903, 0.452

==================================================================================================
	XP Ends: 21/9 (2 h:2)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:2)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2889 - acc: 0.9203
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1134 - acc: 0.9659
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0857 - acc: 0.9737
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0823 - acc: 0.9793
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0658 - acc: 0.9804
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0625 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0506 - acc: 0.9854
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0581 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0411 - acc: 0.9886
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0556 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0344 - acc: 0.9908
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0538 - acc: 0.9864
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.85 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.45
	P, R  : 0.645, 0.345

==================================================================================================
	XP Ends: 21/9 (2 h:5)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,2              ,42             ,27             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
10             ,123            ,True           ,144            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.007          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.005          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.067          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.03           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 2, 42, 27, 5, 10, 123, True, 144, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.007, True, 20, 0.005, 128, 2, 20, categorical_crossentropy, 0.067, val_loss, adagrad, 4, False, 256, 0.03, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:5)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1610 - acc: 0.9588
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0670 - acc: 0.9808
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0497 - acc: 0.9857
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0907 - acc: 0.9770
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0407 - acc: 0.9883
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0680 - acc: 0.9829
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0325 - acc: 0.9907
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0626 - acc: 0.9846
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0270 - acc: 0.9922
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0596 - acc: 0.9853
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0231 - acc: 0.9934
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0577 - acc: 0.9859
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.22 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.572
	P, R  : 0.754, 0.461

==================================================================================================
	XP Ends: 21/9 (2 h:9)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:9)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2671 - acc: 0.9190
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1457 - acc: 0.9519
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1171 - acc: 0.9613
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1069 - acc: 0.9723
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1009 - acc: 0.9671
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0747 - acc: 0.9812
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0856 - acc: 0.9726
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0682 - acc: 0.9831
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0744 - acc: 0.9763
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0648 - acc: 0.9837
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0657 - acc: 0.9798
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0623 - acc: 0.9847
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.77 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.619
	P, R  : 0.883, 0.476

==================================================================================================
	XP Ends: 21/9 (2 h:13)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:13)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2154 - acc: 0.9377
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0809 - acc: 0.9745
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0533 - acc: 0.9838
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0807 - acc: 0.9796
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0397 - acc: 0.9884
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0632 - acc: 0.9838
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0278 - acc: 0.9925
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0588 - acc: 0.9850
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0207 - acc: 0.9949
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0564 - acc: 0.9856
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0161 - acc: 0.9964
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0545 - acc: 0.9862
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.75 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.45
	P, R  : 0.633, 0.349

==================================================================================================
	XP Ends: 21/9 (2 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
22             ,2              ,30             ,82             ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
8              ,49             ,True           ,110            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.011          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.034          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.016          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 22, 2, 30, 82, 13, 8, 49, True, 110, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.011, True, 20, 0.034, 256, 1, 20, categorical_crossentropy, 0.008, val_loss, adagrad, 4, False, 64, 0.016, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2109 - acc: 0.9484
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0868 - acc: 0.9767
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0707 - acc: 0.9801
MWE identification: 1
Epoch 1/1
 - 4s - loss: 0.5413 - acc: 0.9529
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0830 - acc: 0.9789
MWE identification: 2
Epoch 1/1
 - 4s - loss: 4.0287 - acc: 0.7498
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0515 - acc: 0.9856
MWE identification: 3
Epoch 1/1
 - 4s - loss: 4.0298 - acc: 0.7499
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0426 - acc: 0.9881
MWE identification: 4
Epoch 1/1
 - 4s - loss: 4.0296 - acc: 0.7500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0371 - acc: 0.9896
MWE identification: 5
Epoch 1/1
 - 4s - loss: 4.0296 - acc: 0.7500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0330 - acc: 0.9908
MWE identification: 6
Epoch 1/1
 - 5s - loss: 4.0295 - acc: 0.7500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.43 minutes 
==================================================================================================
	PARSING TIME: 1.88 minutes 
==================================================================================================
	Identification : 0.028
	P, R  : 0.017, 0.079

==================================================================================================
	XP Ends: 21/9 (2 h:21)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:21)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3266 - acc: 0.9052
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1783 - acc: 0.9429
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1531 - acc: 0.9498
MWE identification: 1
Epoch 1/1
 - 3s - loss: 7.3979 - acc: 0.5349
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1740 - acc: 0.9489
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.1564 - acc: 0.9759
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1367 - acc: 0.9574
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.1604 - acc: 0.9795
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1196 - acc: 0.9625
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0617 - acc: 0.9865
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1069 - acc: 0.9663
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0536 - acc: 0.9880
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.92 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.582
	P, R  : 0.671, 0.514

==================================================================================================
	XP Ends: 21/9 (2 h:25)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:25)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2787 - acc: 0.9229
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1098 - acc: 0.9666
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0831 - acc: 0.9740
MWE identification: 1
Epoch 1/1
 - 6s - loss: 1.2594 - acc: 0.9090
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0949 - acc: 0.9734
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0607 - acc: 0.9862
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0638 - acc: 0.9820
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0491 - acc: 0.9884
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0465 - acc: 0.9869
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0472 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0375 - acc: 0.9897
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0464 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.62 minutes 
==================================================================================================
	PARSING TIME: 0.78 minutes 
==================================================================================================
	Identification : 0.415
	P, R  : 0.627, 0.31

==================================================================================================
	XP Ends: 21/9 (2 h:29)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
17             ,9              ,81             ,192            ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,63             ,True           ,192            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.017          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.035          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.051          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.038          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 17, 9, 81, 192, 12, 7, 63, True, 192, True, False, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.017, False, 20, 0.035, 96, 1, 20, categorical_crossentropy, 0.051, val_loss, adagrad, 4, False, 64, 0.038, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:29)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1495 - acc: 0.9610
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0605 - acc: 0.9825
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0490 - acc: 0.9850
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0851 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0302 - acc: 0.9909
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0202 - acc: 0.9940
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0155 - acc: 0.9954
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0126 - acc: 0.9962
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.72 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (2 h:34)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:34)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2518 - acc: 0.9226
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1352 - acc: 0.9551
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1157 - acc: 0.9608
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1030 - acc: 0.9782
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1019 - acc: 0.9673
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0624 - acc: 0.9856
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0729 - acc: 0.9770
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0518 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0566 - acc: 0.9824
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0490 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0465 - acc: 0.9859
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0478 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.2 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.599
	P, R  : 0.719, 0.514

==================================================================================================
	XP Ends: 21/9 (2 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1991 - acc: 0.9417
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0724 - acc: 0.9768
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0529 - acc: 0.9828
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0753 - acc: 0.9821
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0429 - acc: 0.9870
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0536 - acc: 0.9868
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0211 - acc: 0.9940
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0477 - acc: 0.9885
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0124 - acc: 0.9969
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0462 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0083 - acc: 0.9982
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0456 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.33 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.462
	P, R  : 0.607, 0.373

==================================================================================================
	XP Ends: 21/9 (2 h:42)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,5              ,25             ,41             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
11             ,97             ,True           ,28             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.024          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.06           ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.029          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.013          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 5, 25, 41, 8, 11, 97, True, 28, False, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.024, True, 20, 0.06, 128, 2, 20, categorical_crossentropy, 0.029, val_loss, adagrad, 4, False, 96, 0.013, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.06
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2753 - acc: 0.9307
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1270 - acc: 0.9661
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1033 - acc: 0.9721
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0853 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0953 - acc: 0.9749
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0740 - acc: 0.9803
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0647 - acc: 0.9830
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0579 - acc: 0.9848
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.5
POS tagging accuracy (MWEs) = 95.5
	TRAINING TIME: 2.42 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (2 h:47)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:47)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.06
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3720 - acc: 0.8947
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2021 - acc: 0.9368
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1729 - acc: 0.9447
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0826 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1710 - acc: 0.9468
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1362 - acc: 0.9567
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1223 - acc: 0.9617
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1121 - acc: 0.9653
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.95 minutes 
==================================================================================================
	PARSING TIME: 2.7 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (2 h:52)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:52)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.06
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3367 - acc: 0.9073
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1408 - acc: 0.9587
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1015 - acc: 0.9707
MWE identification: 1
Epoch 1/1
 - 11s - loss: 8.0600 - acc: 0.4997
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1299 - acc: 0.9661
MWE identification: 2
Epoch 1/1
 - 11s - loss: 8.0590 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0664 - acc: 0.9820
MWE identification: 3
Epoch 1/1
 - 11s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0518 - acc: 0.9866
MWE identification: 4
Epoch 1/1
 - 11s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0427 - acc: 0.9892
MWE identification: 5
Epoch 1/1
 - 11s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 2.95 minutes 
==================================================================================================
	PARSING TIME: 1.58 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.133

==================================================================================================
	XP Ends: 21/9 (2 h:57)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,6              ,123            ,31             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
22             ,27             ,True           ,132            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.012          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.005          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.022          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.085          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 6, 123, 31, 6, 22, 27, True, 132, True, False, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.012, False, 20, 0.005, 64, 1, 20, categorical_crossentropy, 0.022, val_loss, adagrad, 4, False, 256, 0.085, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (2h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.085
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1848 - acc: 0.9526
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0703 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0437 - acc: 0.9876
MWE identification: 1
Epoch 1/1
 - 16s - loss: 0.0866 - acc: 0.9774
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0312 - acc: 0.9913
MWE identification: 2
Epoch 1/1
 - 16s - loss: 0.0703 - acc: 0.9822
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0235 - acc: 0.9935
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0653 - acc: 0.9837
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0193 - acc: 0.9947
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0622 - acc: 0.9845
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0163 - acc: 0.9955
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0601 - acc: 0.9851
Should stop early?
Early stopping applied
POS tagging accuracy = 95.5
POS tagging accuracy (MWEs) = 95.5
	TRAINING TIME: 2.85 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.452
	P, R  : 0.398, 0.524

==================================================================================================
	XP Ends: 21/9 (3 h:1)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:1)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.085
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2707 - acc: 0.9181
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1238 - acc: 0.9589
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0825 - acc: 0.9733
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0965 - acc: 0.9740
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0592 - acc: 0.9814
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0771 - acc: 0.9804
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0424 - acc: 0.9873
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0710 - acc: 0.9823
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0322 - acc: 0.9909
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0676 - acc: 0.9831
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0252 - acc: 0.9932
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0648 - acc: 0.9839
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.15 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.37
	P, R  : 0.271, 0.582

==================================================================================================
	XP Ends: 21/9 (3 h:5)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:5)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.085
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2129 - acc: 0.9389
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0589 - acc: 0.9818
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0258 - acc: 0.9927
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0759 - acc: 0.9808
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0147 - acc: 0.9963
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0625 - acc: 0.9843
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0087 - acc: 0.9981
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0584 - acc: 0.9854
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0057 - acc: 0.9989
MWE identification: 4
Epoch 1/1
 - 21s - loss: 0.0558 - acc: 0.9862
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0042 - acc: 0.9993
MWE identification: 5
Epoch 1/1
 - 21s - loss: 0.0539 - acc: 0.9868
Should stop early?
Early stopping applied
POS tagging accuracy = 93.2
POS tagging accuracy (MWEs) = 93.2
	TRAINING TIME: 3.58 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.41
	P, R  : 0.448, 0.378

==================================================================================================
	XP Ends: 21/9 (3 h:10)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
17             ,8              ,107            ,169            ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,25             ,True           ,194            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.049          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.016          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.03           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.086          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 17, 8, 107, 169, 8, 7, 25, True, 194, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.049, True, 20, 0.016, 256, 2, 20, categorical_crossentropy, 0.03, val_loss, adagrad, 4, False, 128, 0.086, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:10)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.086
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1861 - acc: 0.9525
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0707 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0496 - acc: 0.9854
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0966 - acc: 0.9771
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0322 - acc: 0.9908
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0625 - acc: 0.9847
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0217 - acc: 0.9939
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0557 - acc: 0.9867
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0172 - acc: 0.9952
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0519 - acc: 0.9878
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0144 - acc: 0.9960
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0497 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.05 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.46
	P, R  : 0.438, 0.485

==================================================================================================
	XP Ends: 21/9 (3 h:13)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:13)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.086
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2695 - acc: 0.9191
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1223 - acc: 0.9594
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0912 - acc: 0.9697
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1018 - acc: 0.9750
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0585 - acc: 0.9815
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0652 - acc: 0.9838
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0378 - acc: 0.9886
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0580 - acc: 0.9859
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0272 - acc: 0.9921
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0540 - acc: 0.9870
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0204 - acc: 0.9944
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0515 - acc: 0.9878
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 1.7 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.36
	P, R  : 0.261, 0.582

==================================================================================================
	XP Ends: 21/9 (3 h:17)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:17)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.086
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2136 - acc: 0.9386
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0588 - acc: 0.9818
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0301 - acc: 0.9907
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0839 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0152 - acc: 0.9959
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0547 - acc: 0.9867
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0074 - acc: 0.9982
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0497 - acc: 0.9882
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0045 - acc: 0.9991
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0474 - acc: 0.9888
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0031 - acc: 0.9994
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0463 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.393
	P, R  : 0.459, 0.343

==================================================================================================
	XP Ends: 21/9 (3 h:20)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,1              ,152            ,139            ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
25             ,178            ,True           ,30             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.005          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.02           ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.011          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.045          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 1, 152, 139, 8, 25, 178, True, 30, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.005, True, 20, 0.02, 96, 1, 20, categorical_crossentropy, 0.011, val_acc, adagrad, 4, False, 128, 0.045, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:20)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.045
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1437 - acc: 0.9623
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0568 - acc: 0.9833
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0423 - acc: 0.9870
MWE identification: 1
Epoch 1/1
 - 10s - loss: 3.3739 - acc: 0.7802
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0326 - acc: 0.9903
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0571 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0219 - acc: 0.9935
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0508 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0163 - acc: 0.9952
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0480 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0131 - acc: 0.9960
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0466 - acc: 0.9890
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0110 - acc: 0.9966
MWE identification: 6
Epoch 1/1
 - 11s - loss: 0.0458 - acc: 0.9893
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.77 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.578
	P, R  : 0.742, 0.473

==================================================================================================
	XP Ends: 21/9 (3 h:25)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:25)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.045
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2489 - acc: 0.9231
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1298 - acc: 0.9565
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1040 - acc: 0.9650
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0957 - acc: 0.9784
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0828 - acc: 0.9731
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0602 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0602 - acc: 0.9813
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0532 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0477 - acc: 0.9853
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0504 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0391 - acc: 0.9884
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0488 - acc: 0.9884
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0328 - acc: 0.9904
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0480 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.18 minutes 
==================================================================================================
	PARSING TIME: 1.83 minutes 
==================================================================================================
	Identification : 0.598
	P, R  : 0.664, 0.544

==================================================================================================
	XP Ends: 21/9 (3 h:29)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:29)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.045
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1926 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0676 - acc: 0.9780
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0437 - acc: 0.9858
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0716 - acc: 0.9824
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0296 - acc: 0.9910
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0532 - acc: 0.9865
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0151 - acc: 0.9959
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0490 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0091 - acc: 0.9979
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0471 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0060 - acc: 0.9988
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0461 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.12 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.455
	P, R  : 0.593, 0.369

==================================================================================================
	XP Ends: 21/9 (3 h:33)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,1              ,55             ,143            ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
31             ,40             ,True           ,30             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.007          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.038          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.075          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.05           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 1, 55, 143, 7, 31, 40, True, 30, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.007, False, 20, 0.038, 96, 2, 20, categorical_crossentropy, 0.075, val_loss, adagrad, 4, False, 256, 0.05, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:33)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.05
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1407 - acc: 0.9626
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0551 - acc: 0.9835
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0369 - acc: 0.9890
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.1634 - acc: 0.9768
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0428 - acc: 0.9873
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0546 - acc: 0.9870
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0276 - acc: 0.9921
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0480 - acc: 0.9885
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0198 - acc: 0.9942
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0458 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0156 - acc: 0.9954
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0451 - acc: 0.9893
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.702, 0.49

==================================================================================================
	XP Ends: 21/9 (3 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:37)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.05
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2481 - acc: 0.9236
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1264 - acc: 0.9578
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0936 - acc: 0.9688
MWE identification: 1
Epoch 1/1
 - 7s - loss: 12.0812 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0799 - acc: 0.9744
MWE identification: 2
Epoch 1/1
 - 7s - loss: 12.0883 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0591 - acc: 0.9814
MWE identification: 3
Epoch 1/1
 - 7s - loss: 12.0883 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0479 - acc: 0.9856
MWE identification: 4
Epoch 1/1
 - 7s - loss: 12.0883 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0399 - acc: 0.9883
MWE identification: 5
Epoch 1/1
 - 7s - loss: 12.0883 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0339 - acc: 0.9902
MWE identification: 6
Epoch 1/1
 - 7s - loss: 12.0883 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.03 minutes 
==================================================================================================
	PARSING TIME: 2.8 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.004

==================================================================================================
	XP Ends: 21/9 (3 h:42)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:42)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.05
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1916 - acc: 0.9439
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0654 - acc: 0.9785
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0371 - acc: 0.9884
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0734 - acc: 0.9823
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0455 - acc: 0.9858
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0530 - acc: 0.9870
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0224 - acc: 0.9937
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0474 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0135 - acc: 0.9967
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0462 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0091 - acc: 0.9981
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0456 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.0 minutes 
==================================================================================================
	PARSING TIME: 0.82 minutes 
==================================================================================================
	Identification : 0.467
	P, R  : 0.569, 0.396

==================================================================================================
	XP Ends: 21/9 (3 h:46)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,69             ,74             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
18             ,67             ,True           ,75             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.046          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.013          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 69, 74, 8, 18, 67, True, 75, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.046, False, 20, 0.006, 64, 1, 20, categorical_crossentropy, 0.008, val_loss, adagrad, 4, False, 128, 0.013, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2753 - acc: 0.9307
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1270 - acc: 0.9661
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1037 - acc: 0.9721
MWE identification: 1
Epoch 1/1
 - 16s - loss: 0.0912 - acc: 0.9760
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0876 - acc: 0.9764
MWE identification: 2
Epoch 1/1
 - 16s - loss: 0.0665 - acc: 0.9837
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0742 - acc: 0.9803
MWE identification: 3
Epoch 1/1
 - 16s - loss: 0.0600 - acc: 0.9855
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0654 - acc: 0.9828
MWE identification: 4
Epoch 1/1
 - 16s - loss: 0.0563 - acc: 0.9866
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0588 - acc: 0.9846
MWE identification: 5
Epoch 1/1
 - 16s - loss: 0.0540 - acc: 0.9871
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 3.03 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.495
	P, R  : 0.459, 0.537

==================================================================================================
	XP Ends: 21/9 (3 h:51)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:51)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3720 - acc: 0.8947
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2021 - acc: 0.9368
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1731 - acc: 0.9447
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.1041 - acc: 0.9719
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1530 - acc: 0.9512
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0723 - acc: 0.9820
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1345 - acc: 0.9577
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0650 - acc: 0.9841
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1221 - acc: 0.9616
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0611 - acc: 0.9851
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1125 - acc: 0.9650
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0583 - acc: 0.9858
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.25 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.303
	P, R  : 0.201, 0.615

==================================================================================================
	XP Ends: 21/9 (3 h:55)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (3h:55)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3367 - acc: 0.9073
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1408 - acc: 0.9587
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1021 - acc: 0.9708
MWE identification: 1
Epoch 1/1
 - 23s - loss: 0.0800 - acc: 0.9799
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0750 - acc: 0.9795
MWE identification: 2
Epoch 1/1
 - 23s - loss: 0.0575 - acc: 0.9861
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0561 - acc: 0.9852
MWE identification: 3
Epoch 1/1
 - 23s - loss: 0.0526 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0453 - acc: 0.9885
MWE identification: 4
Epoch 1/1
 - 23s - loss: 0.0502 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0381 - acc: 0.9907
MWE identification: 5
Epoch 1/1
 - 23s - loss: 0.0486 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 3.85 minutes 
==================================================================================================
	PARSING TIME: 0.67 minutes 
==================================================================================================
	Identification : 0.411
	P, R  : 0.501, 0.349

==================================================================================================
	XP Ends: 21/9 (4 h:0)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,1              ,30             ,84             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
41             ,152            ,True           ,76             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.014          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.023          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.009          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.01           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 1, 30, 84, 5, 41, 152, True, 76, True, True, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.014, False, 20, 0.023, 64, 1, 20, categorical_crossentropy, 0.009, val_acc, adagrad, 4, False, 64, 0.01, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:0)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3333 - acc: 0.9167
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1442 - acc: 0.9621
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1163 - acc: 0.9687
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.1978 - acc: 0.9745
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1179 - acc: 0.9693
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0521 - acc: 0.9877
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0968 - acc: 0.9747
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0472 - acc: 0.9890
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0844 - acc: 0.9779
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0457 - acc: 0.9893
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0759 - acc: 0.9801
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0451 - acc: 0.9895
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0694 - acc: 0.9818
MWE identification: 6
Epoch 1/1
 - 15s - loss: 0.0448 - acc: 0.9895
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 3.45 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.506
	P, R  : 0.484, 0.53

==================================================================================================
	XP Ends: 21/9 (4 h:5)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:5)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4358 - acc: 0.8792
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2236 - acc: 0.9319
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1897 - acc: 0.9398
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.4518 - acc: 0.9569
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1962 - acc: 0.9403
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0576 - acc: 0.9862
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1670 - acc: 0.9479
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0508 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1491 - acc: 0.9528
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0488 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1371 - acc: 0.9568
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0478 - acc: 0.9887
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.1277 - acc: 0.9599
MWE identification: 6
Epoch 1/1
 - 10s - loss: 0.0474 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.68 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.417
	P, R  : 0.319, 0.602

==================================================================================================
	XP Ends: 21/9 (4 h:9)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:9)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4026 - acc: 0.8913
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1673 - acc: 0.9511
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1213 - acc: 0.9648
MWE identification: 1
Epoch 1/1
 - 20s - loss: 0.0664 - acc: 0.9836
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1167 - acc: 0.9676
MWE identification: 2
Epoch 1/1
 - 20s - loss: 0.0489 - acc: 0.9885
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0826 - acc: 0.9779
MWE identification: 3
Epoch 1/1
 - 20s - loss: 0.0464 - acc: 0.9891
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0664 - acc: 0.9827
MWE identification: 4
Epoch 1/1
 - 20s - loss: 0.0457 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0564 - acc: 0.9854
MWE identification: 5
Epoch 1/1
 - 20s - loss: 0.0453 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 3.87 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.455
	P, R  : 0.492, 0.424

==================================================================================================
	XP Ends: 21/9 (4 h:14)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
11             ,2              ,212            ,27             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,90             ,True           ,47             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.013          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.071          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.061          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.074          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 11, 2, 212, 27, 12, 6, 90, True, 47, True, False, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.013, False, 20, 0.071, 128, 1, 20, categorical_crossentropy, 0.061, val_acc, adagrad, 4, False, 128, 0.074, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:14)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1759 - acc: 0.9540
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0703 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0493 - acc: 0.9854
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.5263 - acc: 0.9538
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0672 - acc: 0.9805
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0608 - acc: 0.9868
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0385 - acc: 0.9892
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0477 - acc: 0.9889
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0263 - acc: 0.9926
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0453 - acc: 0.9893
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0194 - acc: 0.9944
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0447 - acc: 0.9895
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0161 - acc: 0.9954
MWE identification: 6
Epoch 1/1
 - 8s - loss: 0.0445 - acc: 0.9895
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.62 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.482
	P, R  : 0.468, 0.496

==================================================================================================
	XP Ends: 21/9 (4 h:18)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:18)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2606 - acc: 0.9204
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1227 - acc: 0.9596
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0917 - acc: 0.9697
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0820 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0673 - acc: 0.9786
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0401 - acc: 0.9879
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0289 - acc: 0.9916
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0220 - acc: 0.9941
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 1.95 minutes 
==================================================================================================
	PARSING TIME: 2.78 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (4 h:23)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:23)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2111 - acc: 0.9389
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0599 - acc: 0.9817
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0309 - acc: 0.9907
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0858 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0177 - acc: 0.9950
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0076 - acc: 0.9981
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0045 - acc: 0.9991
MWE identification: 4
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0030 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 2.87 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (4 h:28)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,3              ,90             ,48             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,41             ,True           ,140            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.025          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.089          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.072          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.014          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 3, 90, 48, 6, 7, 41, True, 140, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.025, True, 20, 0.089, 64, 1, 20, categorical_crossentropy, 0.072, val_loss, adagrad, 4, False, 128, 0.014, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:28)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.089
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2321 - acc: 0.9433
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0922 - acc: 0.9756
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0747 - acc: 0.9793
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0866 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0807 - acc: 0.9788
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0572 - acc: 0.9837
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0495 - acc: 0.9861
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0441 - acc: 0.9877
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.9 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (4 h:33)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:33)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.089
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3476 - acc: 0.9007
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1869 - acc: 0.9404
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1598 - acc: 0.9482
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0852 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1729 - acc: 0.9468
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1318 - acc: 0.9571
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1186 - acc: 0.9613
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1091 - acc: 0.9648
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 2.28 minutes 
==================================================================================================
	PARSING TIME: 2.87 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (4 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.089
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3012 - acc: 0.9173
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1182 - acc: 0.9647
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0895 - acc: 0.9726
MWE identification: 1
Epoch 1/1
 - 20s - loss: 12.0868 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1032 - acc: 0.9698
MWE identification: 2
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0646 - acc: 0.9810
MWE identification: 3
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0520 - acc: 0.9852
MWE identification: 4
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0437 - acc: 0.9877
MWE identification: 5
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 3.6 minutes 
==================================================================================================
	PARSING TIME: 1.18 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (4 h:44)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,5              ,140            ,113            ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
10             ,42             ,True           ,38             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.047          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.02           ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.016          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.028          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 5, 140, 113, 5, 10, 42, True, 38, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.047, True, 20, 0.02, 256, 2, 20, categorical_crossentropy, 0.016, val_acc, adagrad, 4, False, 96, 0.028, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1636 - acc: 0.9583
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0685 - acc: 0.9805
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0541 - acc: 0.9842
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0810 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0374 - acc: 0.9890
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0276 - acc: 0.9919
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0222 - acc: 0.9935
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0186 - acc: 0.9945
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.12 minutes 
==================================================================================================
	PARSING TIME: 2.63 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.11

==================================================================================================
	XP Ends: 21/9 (4 h:49)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:49)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2723 - acc: 0.9180
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1492 - acc: 0.9510
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1258 - acc: 0.9576
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.6818 - acc: 0.9407
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1065 - acc: 0.9652
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0744 - acc: 0.9835
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0848 - acc: 0.9730
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0561 - acc: 0.9867
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0713 - acc: 0.9775
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0524 - acc: 0.9878
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0619 - acc: 0.9809
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0506 - acc: 0.9882
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0547 - acc: 0.9833
MWE identification: 6
Epoch 1/1
 - 3s - loss: 0.0494 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.9 minutes 
==================================================================================================
	PARSING TIME: 1.83 minutes 
==================================================================================================
	Identification : 0.581
	P, R  : 0.644, 0.53

==================================================================================================
	XP Ends: 21/9 (4 h:53)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:53)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2200 - acc: 0.9367
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0826 - acc: 0.9741
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0596 - acc: 0.9811
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0874 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0447 - acc: 0.9867
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0587 - acc: 0.9860
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0274 - acc: 0.9926
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0499 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0187 - acc: 0.9954
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0478 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0139 - acc: 0.9968
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0467 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.437
	P, R  : 0.629, 0.335

==================================================================================================
	XP Ends: 21/9 (4 h:56)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,1              ,159            ,26             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,58             ,True           ,33             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.008          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.007          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.016          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.033          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 1, 159, 26, 9, 7, 58, True, 33, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.008, False, 20, 0.007, 256, 1, 20, categorical_crossentropy, 0.016, val_loss, adagrad, 4, False, 128, 0.033, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (4h:56)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.033
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1576 - acc: 0.9595
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0643 - acc: 0.9815
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0494 - acc: 0.9855
MWE identification: 1
Epoch 1/1
 - 4s - loss: 0.1001 - acc: 0.9756
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0351 - acc: 0.9896
MWE identification: 2
Epoch 1/1
 - 4s - loss: 0.0668 - acc: 0.9832
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0258 - acc: 0.9924
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0610 - acc: 0.9850
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0206 - acc: 0.9940
MWE identification: 4
Epoch 1/1
 - 4s - loss: 0.0576 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0172 - acc: 0.9950
MWE identification: 5
Epoch 1/1
 - 4s - loss: 0.0555 - acc: 0.9865
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.03 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.757, 0.466

==================================================================================================
	XP Ends: 21/9 (5 h:0)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:0)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.033
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2600 - acc: 0.9206
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1410 - acc: 0.9532
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1163 - acc: 0.9610
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1140 - acc: 0.9716
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0898 - acc: 0.9704
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0716 - acc: 0.9820
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0718 - acc: 0.9772
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0648 - acc: 0.9839
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0600 - acc: 0.9812
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0611 - acc: 0.9848
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0516 - acc: 0.9842
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0585 - acc: 0.9856
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.68 minutes 
==================================================================================================
	PARSING TIME: 1.78 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.823, 0.463

==================================================================================================
	XP Ends: 21/9 (5 h:3)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:3)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.033
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2066 - acc: 0.9399
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0769 - acc: 0.9755
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0529 - acc: 0.9832
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0855 - acc: 0.9786
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0324 - acc: 0.9903
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0618 - acc: 0.9842
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0200 - acc: 0.9947
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0571 - acc: 0.9854
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0137 - acc: 0.9968
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0544 - acc: 0.9863
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0101 - acc: 0.9978
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0525 - acc: 0.9870
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.47 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.461
	P, R  : 0.631, 0.363

==================================================================================================
	XP Ends: 21/9 (5 h:7)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,4              ,154            ,57             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,134            ,True           ,129            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.066          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.009          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.039          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 4, 154, 57, 6, 7, 134, True, 129, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.006, True, 20, 0.066, 256, 1, 20, categorical_crossentropy, 0.009, val_acc, adagrad, 4, False, 256, 0.039, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:7)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1483 - acc: 0.9612
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0599 - acc: 0.9825
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0421 - acc: 0.9875
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0817 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0383 - acc: 0.9887
MWE identification: 2
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0262 - acc: 0.9922
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0207 - acc: 0.9938
MWE identification: 4
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0171 - acc: 0.9950
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 1.95 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (5 h:11)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:11)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2511 - acc: 0.9228
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1344 - acc: 0.9550
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1035 - acc: 0.9657
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0769 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1062 - acc: 0.9655
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0756 - acc: 0.9759
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0625 - acc: 0.9805
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0532 - acc: 0.9839
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.6 minutes 
==================================================================================================
	PARSING TIME: 2.78 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (5 h:16)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:16)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1969 - acc: 0.9424
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0721 - acc: 0.9768
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0442 - acc: 0.9864
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0820 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0413 - acc: 0.9876
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0221 - acc: 0.9940
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0150 - acc: 0.9965
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0110 - acc: 0.9977
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.37 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (5 h:20)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
11             ,3              ,27             ,42             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,38             ,True           ,158            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.014          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.01           ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.01           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.005          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 11, 3, 27, 42, 5, 7, 38, True, 158, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.014, False, 20, 0.01, 64, 1, 20, categorical_crossentropy, 0.01, val_loss, adagrad, 4, False, 256, 0.005, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:20)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6382 - acc: 0.8425
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2345 - acc: 0.9404
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1856 - acc: 0.9528
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0876 - acc: 0.9781
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1803 - acc: 0.9553
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0585 - acc: 0.9858
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1564 - acc: 0.9603
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0527 - acc: 0.9876
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1427 - acc: 0.9633
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0498 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1330 - acc: 0.9654
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0482 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 94.8
POS tagging accuracy (MWEs) = 94.8
	TRAINING TIME: 2.82 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.524
	P, R  : 0.5, 0.551

==================================================================================================
	XP Ends: 21/9 (5 h:24)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:24)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.7487 - acc: 0.8008
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.3301 - acc: 0.9075
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.2696 - acc: 0.9216
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.1005 - acc: 0.9742
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.2655 - acc: 0.9236
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0634 - acc: 0.9843
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.2366 - acc: 0.9303
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0568 - acc: 0.9863
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.2206 - acc: 0.9336
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0534 - acc: 0.9872
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.2092 - acc: 0.9363
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0513 - acc: 0.9878
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.386
	P, R  : 0.279, 0.626

==================================================================================================
	XP Ends: 21/9 (5 h:28)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:28)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.7073 - acc: 0.8129
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2805 - acc: 0.9242
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.2161 - acc: 0.9394
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0786 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.2068 - acc: 0.9426
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0517 - acc: 0.9875
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1680 - acc: 0.9533
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0479 - acc: 0.9887
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1481 - acc: 0.9589
MWE identification: 4
Epoch 1/1
 - 21s - loss: 0.0465 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1344 - acc: 0.9629
MWE identification: 5
Epoch 1/1
 - 21s - loss: 0.0458 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 91.9
POS tagging accuracy (MWEs) = 91.9
	TRAINING TIME: 3.63 minutes 
==================================================================================================
	PARSING TIME: 0.8 minutes 
==================================================================================================
	Identification : 0.441
	P, R  : 0.477, 0.41

==================================================================================================
	XP Ends: 21/9 (5 h:33)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,5              ,226            ,53             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
45             ,158            ,True           ,186            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.012          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.01           ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.025          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.04           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 5, 226, 53, 6, 45, 158, True, 186, False, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.012, True, 20, 0.01, 256, 2, 20, categorical_crossentropy, 0.025, val_loss, adagrad, 4, False, 64, 0.04, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:33)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1753 - acc: 0.9530
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0810 - acc: 0.9773
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0634 - acc: 0.9816
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0965 - acc: 0.9767
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0388 - acc: 0.9889
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0635 - acc: 0.9842
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0279 - acc: 0.9920
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0571 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0225 - acc: 0.9937
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0534 - acc: 0.9873
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0190 - acc: 0.9946
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0512 - acc: 0.9879
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.27 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.485
	P, R  : 0.482, 0.488

==================================================================================================
	XP Ends: 21/9 (5 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:37)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2581 - acc: 0.9199
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1378 - acc: 0.9549
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1151 - acc: 0.9614
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1087 - acc: 0.9727
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0748 - acc: 0.9763
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0679 - acc: 0.9834
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0547 - acc: 0.9832
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0608 - acc: 0.9853
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0433 - acc: 0.9868
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0568 - acc: 0.9865
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0356 - acc: 0.9897
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0542 - acc: 0.9871
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 1.92 minutes 
==================================================================================================
	PARSING TIME: 1.77 minutes 
==================================================================================================
	Identification : 0.379
	P, R  : 0.273, 0.62

==================================================================================================
	XP Ends: 21/9 (5 h:41)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:41)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2122 - acc: 0.9373
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0741 - acc: 0.9778
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0466 - acc: 0.9857
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0879 - acc: 0.9801
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0215 - acc: 0.9939
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0556 - acc: 0.9866
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0118 - acc: 0.9970
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0506 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0077 - acc: 0.9982
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0484 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0055 - acc: 0.9988
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0472 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.2
POS tagging accuracy (MWEs) = 93.2
	TRAINING TIME: 2.73 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.388
	P, R  : 0.466, 0.333

==================================================================================================
	XP Ends: 21/9 (5 h:44)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
23             ,2              ,58             ,140            ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
19             ,88             ,True           ,70             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.007          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.018          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.094          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 23, 2, 58, 140, 12, 19, 88, True, 70, True, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.007, False, 20, 0.018, 256, 2, 20, categorical_crossentropy, 0.094, val_loss, adagrad, 4, False, 96, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1170 - acc: 0.9709
MWE identification: 1
Epoch 1/1
 - 5s - loss: 8.0570 - acc: 0.4992
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1043 - acc: 0.9742
MWE identification: 2
Epoch 1/1
 - 5s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0865 - acc: 0.9769
MWE identification: 3
Epoch 1/1
 - 5s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0792 - acc: 0.9785
MWE identification: 4
Epoch 1/1
 - 5s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0740 - acc: 0.9796
MWE identification: 5
Epoch 1/1
 - 5s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.12 minutes 
==================================================================================================
	PARSING TIME: 2.38 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 21/9 (5 h:49)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:49)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.2258 - acc: 0.9317
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1689 - acc: 0.9709
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.2280 - acc: 0.9327
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0887 - acc: 0.9833
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1985 - acc: 0.9393
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0543 - acc: 0.9871
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1813 - acc: 0.9432
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0511 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1707 - acc: 0.9461
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0495 - acc: 0.9883
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 1.78 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.609
	P, R  : 0.811, 0.488

==================================================================================================
	XP Ends: 21/9 (5 h:53)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:53)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1557 - acc: 0.9547
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0796 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1278 - acc: 0.9631
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1076 - acc: 0.9689
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0960 - acc: 0.9722
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0875 - acc: 0.9749
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0805 - acc: 0.9771
MWE identification: 6
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.68 minutes 
==================================================================================================
	PARSING TIME: 1.78 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.063

==================================================================================================
	XP Ends: 21/9 (5 h:58)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
14             ,3              ,61             ,31             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,45             ,True           ,88             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.024          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.009          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.022          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.045          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 14, 3, 61, 31, 8, 7, 45, True, 88, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.024, False, 20, 0.009, 96, 2, 20, categorical_crossentropy, 0.022, val_acc, adagrad, 4, False, 128, 0.045, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (5h:58)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.045
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1437 - acc: 0.9622
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0568 - acc: 0.9833
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0423 - acc: 0.9870
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0820 - acc: 0.9795
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0287 - acc: 0.9913
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0617 - acc: 0.9845
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0196 - acc: 0.9939
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0566 - acc: 0.9860
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0150 - acc: 0.9954
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0535 - acc: 0.9869
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0122 - acc: 0.9963
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0516 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.48 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.567
	P, R  : 0.709, 0.472

==================================================================================================
	XP Ends: 21/9 (6 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.045
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2489 - acc: 0.9231
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1298 - acc: 0.9565
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1040 - acc: 0.9651
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0917 - acc: 0.9765
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0757 - acc: 0.9751
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0668 - acc: 0.9831
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0563 - acc: 0.9821
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0605 - acc: 0.9850
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0449 - acc: 0.9862
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0571 - acc: 0.9860
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0370 - acc: 0.9891
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0547 - acc: 0.9866
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0311 - acc: 0.9911
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0530 - acc: 0.9872
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.17 minutes 
==================================================================================================
	PARSING TIME: 1.77 minutes 
==================================================================================================
	Identification : 0.58
	P, R  : 0.68, 0.505

==================================================================================================
	XP Ends: 21/9 (6 h:6)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:6)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.045
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1926 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0676 - acc: 0.9780
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0437 - acc: 0.9858
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0749 - acc: 0.9812
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0246 - acc: 0.9926
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0584 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0133 - acc: 0.9965
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0540 - acc: 0.9864
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0082 - acc: 0.9982
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0515 - acc: 0.9872
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0055 - acc: 0.9989
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0497 - acc: 0.9878
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.12 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.466
	P, R  : 0.573, 0.392

==================================================================================================
	XP Ends: 21/9 (6 h:10)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
17             ,1              ,31             ,70             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,55             ,True           ,28             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.009          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.027          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.043          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 17, 1, 31, 70, 9, 7, 55, True, 28, True, False, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.009, False, 20, 0.006, 128, 2, 20, categorical_crossentropy, 0.027, val_loss, adagrad, 4, False, 128, 0.043, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:10)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1456 - acc: 0.9619
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0578 - acc: 0.9830
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0431 - acc: 0.9868
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0865 - acc: 0.9780
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0288 - acc: 0.9913
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0666 - acc: 0.9832
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0201 - acc: 0.9939
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0614 - acc: 0.9849
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0154 - acc: 0.9953
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0584 - acc: 0.9857
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0127 - acc: 0.9961
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0563 - acc: 0.9863
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.32 minutes 
==================================================================================================
	PARSING TIME: 1.22 minutes 
==================================================================================================
	Identification : 0.576
	P, R  : 0.743, 0.47

==================================================================================================
	XP Ends: 21/9 (6 h:14)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:14)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2493 - acc: 0.9230
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1308 - acc: 0.9561
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1052 - acc: 0.9646
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0998 - acc: 0.9741
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0758 - acc: 0.9753
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0731 - acc: 0.9816
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0574 - acc: 0.9818
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0667 - acc: 0.9833
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0460 - acc: 0.9860
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0634 - acc: 0.9842
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0381 - acc: 0.9887
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0608 - acc: 0.9848
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.88 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.581
	P, R  : 0.733, 0.481

==================================================================================================
	XP Ends: 21/9 (6 h:18)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:18)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1939 - acc: 0.9433
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0688 - acc: 0.9776
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0447 - acc: 0.9857
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0777 - acc: 0.9803
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0242 - acc: 0.9927
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0615 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0135 - acc: 0.9965
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0575 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0084 - acc: 0.9981
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0551 - acc: 0.9860
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0057 - acc: 0.9988
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0533 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.83 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.481
	P, R  : 0.598, 0.402

==================================================================================================
	XP Ends: 21/9 (6 h:21)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,7              ,130            ,73             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
20             ,26             ,True           ,109            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.026          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.019          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.027          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 7, 130, 73, 8, 20, 26, True, 109, False, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.026, True, 20, 0.019, 96, 1, 20, categorical_crossentropy, 0.006, val_loss, adagrad, 4, False, 64, 0.027, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:22)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.027
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1645 - acc: 0.9579
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0693 - acc: 0.9803
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0565 - acc: 0.9834
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.2555 - acc: 0.9711
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0444 - acc: 0.9870
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0553 - acc: 0.9868
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0321 - acc: 0.9907
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0501 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0255 - acc: 0.9927
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0477 - acc: 0.9888
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0212 - acc: 0.9939
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0465 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.75 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.564
	P, R  : 0.687, 0.479

==================================================================================================
	XP Ends: 21/9 (6 h:26)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:26)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.027
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2743 - acc: 0.9174
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1506 - acc: 0.9507
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1295 - acc: 0.9563
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.5590 - acc: 0.9498
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1065 - acc: 0.9653
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0610 - acc: 0.9855
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0846 - acc: 0.9730
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0529 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0713 - acc: 0.9774
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0504 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0620 - acc: 0.9809
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0489 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.2 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.578
	P, R  : 0.675, 0.506

==================================================================================================
	XP Ends: 21/9 (6 h:30)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:30)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.027
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2227 - acc: 0.9360
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0843 - acc: 0.9735
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0630 - acc: 0.9797
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0991 - acc: 0.9807
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0446 - acc: 0.9866
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0533 - acc: 0.9867
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0267 - acc: 0.9926
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0486 - acc: 0.9882
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0184 - acc: 0.9953
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0469 - acc: 0.9888
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0137 - acc: 0.9968
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0460 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.33 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.475
	P, R  : 0.601, 0.392

==================================================================================================
	XP Ends: 21/9 (6 h:34)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,5              ,167            ,42             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,26             ,True           ,65             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.006          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.065          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.023          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 5, 167, 42, 12, 9, 26, True, 65, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.006, False, 20, 0.065, 64, 1, 20, categorical_crossentropy, 0.008, val_loss, adagrad, 4, False, 96, 0.023, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:34)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.065
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1738 - acc: 0.9558
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0737 - acc: 0.9794
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.0592 - acc: 0.9827
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0869 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0484 - acc: 0.9861
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0346 - acc: 0.9900
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0282 - acc: 0.9919
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0240 - acc: 0.9931
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.97 minutes 
==================================================================================================
	PARSING TIME: 2.08 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (6 h:40)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:40)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.065
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2856 - acc: 0.9146
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1578 - acc: 0.9485
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1340 - acc: 0.9553
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0857 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1192 - acc: 0.9610
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0926 - acc: 0.9698
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0800 - acc: 0.9745
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0709 - acc: 0.9777
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.33 minutes 
==================================================================================================
	PARSING TIME: 2.8 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (6 h:45)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:45)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.065
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2340 - acc: 0.9331
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0908 - acc: 0.9718
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0668 - acc: 0.9789
MWE identification: 1
Epoch 1/1
 - 20s - loss: 12.0873 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0503 - acc: 0.9850
MWE identification: 2
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0306 - acc: 0.9913
MWE identification: 3
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0222 - acc: 0.9942
MWE identification: 4
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0171 - acc: 0.9959
MWE identification: 5
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.72 minutes 
==================================================================================================
	PARSING TIME: 1.22 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (6 h:50)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
13             ,1              ,44             ,40             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
44             ,148            ,True           ,49             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.037          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.026          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.047          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.015          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 13, 1, 44, 40, 6, 44, 148, True, 49, False, True, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.037, True, 20, 0.026, 256, 1, 20, categorical_crossentropy, 0.047, val_acc, adagrad, 4, False, 96, 0.015, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:50)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2516 - acc: 0.9362
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1188 - acc: 0.9681
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0963 - acc: 0.9739
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0803 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0788 - acc: 0.9792
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0637 - acc: 0.9829
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0553 - acc: 0.9854
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0491 - acc: 0.9871
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 2.83 minutes 
==================================================================================================
	Identification : 0.014
	P, R  : 0.007, 0.324

==================================================================================================
	XP Ends: 21/9 (6 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (6h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3460 - acc: 0.9005
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1913 - acc: 0.9393
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1632 - acc: 0.9476
MWE identification: 1
Epoch 1/1
 - 3s - loss: 8.0575 - acc: 0.4988
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1456 - acc: 0.9544
MWE identification: 2
Epoch 1/1
 - 3s - loss: 8.0596 - acc: 0.4998
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1208 - acc: 0.9619
MWE identification: 3
Epoch 1/1
 - 3s - loss: 8.0595 - acc: 0.4998
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1081 - acc: 0.9664
MWE identification: 4
Epoch 1/1
 - 3s - loss: 8.0594 - acc: 0.4998
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0983 - acc: 0.9697
MWE identification: 5
Epoch 1/1
 - 3s - loss: 8.0594 - acc: 0.4998
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.77 minutes 
==================================================================================================
	PARSING TIME: 3.6 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.145

==================================================================================================
	XP Ends: 21/9 (7 h:1)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:1)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3097 - acc: 0.9137
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1295 - acc: 0.9621
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.0919 - acc: 0.9737
MWE identification: 1
Epoch 1/1
 - 6s - loss: 8.0581 - acc: 0.4993
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0730 - acc: 0.9804
MWE identification: 2
Epoch 1/1
 - 6s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0473 - acc: 0.9873
MWE identification: 3
Epoch 1/1
 - 6s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0372 - acc: 0.9907
MWE identification: 4
Epoch 1/1
 - 6s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0306 - acc: 0.9927
MWE identification: 5
Epoch 1/1
 - 6s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.58 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.133

==================================================================================================
	XP Ends: 21/9 (7 h:6)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,5              ,37             ,34             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,37             ,True           ,148            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.032          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.021          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.026          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.012          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 5, 37, 34, 5, 9, 37, True, 148, True, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.032, True, 20, 0.021, 128, 1, 20, categorical_crossentropy, 0.026, val_acc, adagrad, 4, False, 128, 0.012, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:6)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2909 - acc: 0.9269
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1317 - acc: 0.9650
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1079 - acc: 0.9711
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.1855 - acc: 0.9743
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1083 - acc: 0.9722
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0572 - acc: 0.9871
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0892 - acc: 0.9769
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0487 - acc: 0.9887
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0768 - acc: 0.9799
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0465 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0684 - acc: 0.9821
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0457 - acc: 0.9894
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0622 - acc: 0.9837
MWE identification: 6
Epoch 1/1
 - 8s - loss: 0.0452 - acc: 0.9895
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.53 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.496
	P, R  : 0.477, 0.516

==================================================================================================
	XP Ends: 21/9 (7 h:10)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:10)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3890 - acc: 0.8907
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2081 - acc: 0.9353
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1785 - acc: 0.9431
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.1511 - acc: 0.9736
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1818 - acc: 0.9438
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0638 - acc: 0.9855
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1543 - acc: 0.9519
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0529 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1377 - acc: 0.9566
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0501 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1262 - acc: 0.9604
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0487 - acc: 0.9886
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.1170 - acc: 0.9634
MWE identification: 6
Epoch 1/1
 - 6s - loss: 0.0481 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.429
	P, R  : 0.335, 0.597

==================================================================================================
	XP Ends: 21/9 (7 h:14)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:14)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3548 - acc: 0.9026
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1481 - acc: 0.9566
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1082 - acc: 0.9691
MWE identification: 1
Epoch 1/1
 - 12s - loss: 0.1115 - acc: 0.9804
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1044 - acc: 0.9710
MWE identification: 2
Epoch 1/1
 - 12s - loss: 0.0517 - acc: 0.9881
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0742 - acc: 0.9807
MWE identification: 3
Epoch 1/1
 - 12s - loss: 0.0476 - acc: 0.9889
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0592 - acc: 0.9848
MWE identification: 4
Epoch 1/1
 - 12s - loss: 0.0463 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0494 - acc: 0.9875
MWE identification: 5
Epoch 1/1
 - 12s - loss: 0.0458 - acc: 0.9892
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0424 - acc: 0.9894
MWE identification: 6
Epoch 1/1
 - 12s - loss: 0.0456 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 3.22 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.384
	P, R  : 0.447, 0.337

==================================================================================================
	XP Ends: 21/9 (7 h:18)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,1              ,158            ,47             ,14             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
40             ,45             ,True           ,38             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.01           ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.041          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.041          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.014          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 1, 158, 47, 14, 40, 45, True, 38, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.01, True, 20, 0.041, 128, 1, 20, categorical_crossentropy, 0.041, val_loss, adagrad, 4, False, 128, 0.014, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:18)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2321 - acc: 0.9433
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0922 - acc: 0.9756
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0747 - acc: 0.9793
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0849 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0672 - acc: 0.9817
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0530 - acc: 0.9849
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0462 - acc: 0.9872
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0413 - acc: 0.9886
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.33 minutes 
==================================================================================================
	PARSING TIME: 2.37 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.179

==================================================================================================
	XP Ends: 21/9 (7 h:23)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:23)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3476 - acc: 0.9007
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1869 - acc: 0.9404
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1598 - acc: 0.9482
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0821 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1513 - acc: 0.9520
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1252 - acc: 0.9593
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1137 - acc: 0.9631
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1049 - acc: 0.9661
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0978 - acc: 0.9689
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 2.02 minutes 
==================================================================================================
	PARSING TIME: 2.95 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (7 h:28)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:28)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3012 - acc: 0.9173
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1182 - acc: 0.9647
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0895 - acc: 0.9726
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0848 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0787 - acc: 0.9772
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0556 - acc: 0.9838
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0449 - acc: 0.9874
MWE identification: 4
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0377 - acc: 0.9897
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.85 minutes 
==================================================================================================
	PARSING TIME: 1.23 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (7 h:33)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,7              ,125            ,117            ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,118            ,True           ,183            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.007          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.012          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.091          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.009          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 7, 125, 117, 10, 7, 118, True, 183, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.007, False, 20, 0.012, 96, 1, 20, categorical_crossentropy, 0.091, val_loss, adagrad, 4, False, 128, 0.009, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:33)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3637 - acc: 0.9093
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1528 - acc: 0.9601
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1248 - acc: 0.9668
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0919 - acc: 0.9783
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1145 - acc: 0.9699
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0579 - acc: 0.9862
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0986 - acc: 0.9739
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0520 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0887 - acc: 0.9765
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0492 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0814 - acc: 0.9787
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0477 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.509
	P, R  : 0.497, 0.522

==================================================================================================
	XP Ends: 21/9 (7 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:37)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4674 - acc: 0.8716
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2339 - acc: 0.9297
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1995 - acc: 0.9376
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1073 - acc: 0.9747
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1907 - acc: 0.9403
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0627 - acc: 0.9848
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1684 - acc: 0.9469
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0561 - acc: 0.9867
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1550 - acc: 0.9509
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0529 - acc: 0.9876
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1449 - acc: 0.9544
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0508 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.02 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.379
	P, R  : 0.273, 0.617

==================================================================================================
	XP Ends: 21/9 (7 h:41)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:41)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4335 - acc: 0.8837
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1797 - acc: 0.9479
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1337 - acc: 0.9615
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0789 - acc: 0.9817
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1153 - acc: 0.9679
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0518 - acc: 0.9878
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0883 - acc: 0.9763
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0478 - acc: 0.9888
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0738 - acc: 0.9805
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0465 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0638 - acc: 0.9835
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0459 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.415
	P, R  : 0.511, 0.349

==================================================================================================
	XP Ends: 21/9 (7 h:45)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,1              ,37             ,103            ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
19             ,40             ,True           ,67             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.039          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.025          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.075          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.015          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 1, 37, 103, 10, 19, 40, True, 67, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.039, True, 20, 0.025, 128, 2, 20, categorical_crossentropy, 0.075, val_loss, adagrad, 4, False, 64, 0.015, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:45)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2225 - acc: 0.9456
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0901 - acc: 0.9760
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0730 - acc: 0.9795
MWE identification: 1
Epoch 1/1
 - 8s - loss: 8.0585 - acc: 0.4997
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0614 - acc: 0.9829
MWE identification: 2
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0471 - acc: 0.9867
MWE identification: 3
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0405 - acc: 0.9888
MWE identification: 4
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0357 - acc: 0.9901
MWE identification: 5
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 2.35 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 21/9 (7 h:50)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:50)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3363 - acc: 0.9032
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1823 - acc: 0.9417
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1564 - acc: 0.9490
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1409 - acc: 0.9752
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1526 - acc: 0.9518
MWE identification: 2
Epoch 1/1
 - 5s - loss: 1.8379 - acc: 0.8798
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1278 - acc: 0.9592
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0546 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1145 - acc: 0.9633
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0507 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1041 - acc: 0.9668
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0489 - acc: 0.9885
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0958 - acc: 0.9696
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0482 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 2.28 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.569
	P, R  : 0.656, 0.503

==================================================================================================
	XP Ends: 21/9 (7 h:54)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:54)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2889 - acc: 0.9203
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1134 - acc: 0.9659
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0861 - acc: 0.9732
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.3771 - acc: 0.9639
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0856 - acc: 0.9753
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0806 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0606 - acc: 0.9828
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0486 - acc: 0.9885
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0474 - acc: 0.9868
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0470 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0390 - acc: 0.9893
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0461 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 3.08 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.43
	P, R  : 0.622, 0.329

==================================================================================================
	XP Ends: 21/9 (7 h:58)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,251            ,119            ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,121            ,True           ,90             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.009          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,64             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.03           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.014          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 251, 119, 10, 5, 121, True, 90, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.009, False, 20, 0.006, 64, 2, 20, categorical_crossentropy, 0.03, val_loss, adagrad, 4, False, 256, 0.014, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (7h:58)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2615 - acc: 0.9340
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1227 - acc: 0.9672
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1007 - acc: 0.9731
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0916 - acc: 0.9760
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0908 - acc: 0.9756
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0664 - acc: 0.9836
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0784 - acc: 0.9792
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0599 - acc: 0.9855
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0699 - acc: 0.9817
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0563 - acc: 0.9865
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0632 - acc: 0.9836
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0539 - acc: 0.9871
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.77 minutes 
==================================================================================================
	PARSING TIME: 1.15 minutes 
==================================================================================================
	Identification : 0.504
	P, R  : 0.48, 0.531

==================================================================================================
	XP Ends: 21/9 (8 h:3)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:3)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3583 - acc: 0.8979
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1964 - acc: 0.9382
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1683 - acc: 0.9465
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.1037 - acc: 0.9719
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1565 - acc: 0.9502
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0719 - acc: 0.9820
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1396 - acc: 0.9558
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0649 - acc: 0.9841
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1277 - acc: 0.9598
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0611 - acc: 0.9851
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1182 - acc: 0.9631
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0582 - acc: 0.9859
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.18 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.28
	P, R  : 0.181, 0.62

==================================================================================================
	XP Ends: 21/9 (8 h:7)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:7)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3227 - acc: 0.9104
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1341 - acc: 0.9608
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0976 - acc: 0.9727
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0803 - acc: 0.9798
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0795 - acc: 0.9782
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0581 - acc: 0.9860
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0617 - acc: 0.9838
MWE identification: 3
Epoch 1/1
 - 20s - loss: 0.0531 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0508 - acc: 0.9872
MWE identification: 4
Epoch 1/1
 - 20s - loss: 0.0506 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0431 - acc: 0.9894
MWE identification: 5
Epoch 1/1
 - 20s - loss: 0.0490 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 3.55 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.39
	P, R  : 0.471, 0.333

==================================================================================================
	XP Ends: 21/9 (8 h:11)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,1              ,27             ,118            ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
38             ,172            ,True           ,76             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.01           ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.02           ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.051          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 1, 27, 118, 7, 38, 172, True, 76, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.01, True, 20, 0.02, 96, 2, 20, categorical_crossentropy, 0.006, val_loss, adagrad, 4, False, 128, 0.051, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:11)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1402 - acc: 0.9629
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0548 - acc: 0.9837
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0403 - acc: 0.9874
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0801 - acc: 0.9814
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0302 - acc: 0.9908
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0550 - acc: 0.9865
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0193 - acc: 0.9942
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0501 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0143 - acc: 0.9955
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0475 - acc: 0.9888
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0115 - acc: 0.9965
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0462 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.6 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.561
	P, R  : 0.672, 0.481

==================================================================================================
	XP Ends: 21/9 (8 h:15)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:16)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2478 - acc: 0.9236
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1261 - acc: 0.9579
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0999 - acc: 0.9664
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0923 - acc: 0.9786
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0772 - acc: 0.9746
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0599 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0548 - acc: 0.9825
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0531 - acc: 0.9873
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0425 - acc: 0.9871
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0504 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0343 - acc: 0.9898
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0489 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.02 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.609
	P, R  : 0.708, 0.535

==================================================================================================
	XP Ends: 21/9 (8 h:19)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:20)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1913 - acc: 0.9437
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0655 - acc: 0.9784
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0418 - acc: 0.9864
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0720 - acc: 0.9822
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0277 - acc: 0.9916
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0537 - acc: 0.9865
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0136 - acc: 0.9963
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0493 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0080 - acc: 0.9983
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0473 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0052 - acc: 0.9990
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0462 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 3.07 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.458
	P, R  : 0.564, 0.386

==================================================================================================
	XP Ends: 21/9 (8 h:24)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,1              ,79             ,54             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
30             ,94             ,True           ,26             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.006          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.08           ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.048          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.005          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 1, 79, 54, 6, 30, 94, True, 26, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.006, False, 20, 0.08, 96, 1, 20, categorical_crossentropy, 0.048, val_acc, adagrad, 4, False, 96, 0.005, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6418 - acc: 0.8429
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1948 - acc: 0.9543
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1336 - acc: 0.9677
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0851 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1651 - acc: 0.9639
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1077 - acc: 0.9729
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0964 - acc: 0.9751
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0893 - acc: 0.9766
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 1.93 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (8 h:28)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:28)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.7461 - acc: 0.8006
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.3238 - acc: 0.9094
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.2485 - acc: 0.9268
MWE identification: 1
Epoch 1/1
 - 7s - loss: 1.2274 - acc: 0.8863
POS tagging: 4
Epoch 1/1
 - 4s - loss: 2.9421 - acc: 0.2268
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0776 - acc: 0.9817
POS tagging: 5
Epoch 1/1
 - 4s - loss: 1.8240 - acc: 0.4502
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0638 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 4s - loss: 1.3579 - acc: 0.5985
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0618 - acc: 0.9867
POS tagging: 7
Epoch 1/1
 - 4s - loss: 1.1047 - acc: 0.6657
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0519 - acc: 0.9879
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.9159 - acc: 0.7157
MWE identification: 6
Epoch 1/1
 - 8s - loss: 0.0504 - acc: 0.9883
Should stop early?
Early stopping applied
POS tagging accuracy = 56.9
POS tagging accuracy (MWEs) = 56.9
	TRAINING TIME: 2.32 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.456
	P, R  : 0.617, 0.362

==================================================================================================
	XP Ends: 21/9 (8 h:33)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:33)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.7034 - acc: 0.8166
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2518 - acc: 0.9352
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1790 - acc: 0.9493
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0938 - acc: 0.9770
POS tagging: 4
Epoch 1/1
 - 4s - loss: 1.1568 - acc: 0.6737
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0563 - acc: 0.9866
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.6927 - acc: 0.7950
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0487 - acc: 0.9883
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.4680 - acc: 0.8706
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0470 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.3673 - acc: 0.9044
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0462 - acc: 0.9891
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.3111 - acc: 0.9206
MWE identification: 6
Epoch 1/1
 - 14s - loss: 0.0460 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 85.6
POS tagging accuracy (MWEs) = 85.6
	TRAINING TIME: 3.48 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.46
	P, R  : 0.471, 0.449

==================================================================================================
	XP Ends: 21/9 (8 h:37)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,6              ,47             ,159            ,14             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,196            ,True           ,137            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.032          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.007          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.041          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.019          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 6, 47, 159, 14, 7, 196, True, 137, True, True, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.032, False, 20, 0.007, 64, 1, 20, categorical_crossentropy, 0.041, val_loss, adagrad, 4, False, 96, 0.019, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:37)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2225 - acc: 0.9422
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1080 - acc: 0.9708
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0866 - acc: 0.9764
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0879 - acc: 0.9773
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0670 - acc: 0.9819
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0644 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0538 - acc: 0.9854
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0584 - acc: 0.9860
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0458 - acc: 0.9876
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0549 - acc: 0.9869
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0401 - acc: 0.9891
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0527 - acc: 0.9876
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.98 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.505
	P, R  : 0.511, 0.5

==================================================================================================
	XP Ends: 21/9 (8 h:42)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:42)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3130 - acc: 0.9077
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1760 - acc: 0.9434
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1489 - acc: 0.9518
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0983 - acc: 0.9741
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1219 - acc: 0.9611
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0687 - acc: 0.9829
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1022 - acc: 0.9679
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0619 - acc: 0.9849
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0895 - acc: 0.9724
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0582 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0800 - acc: 0.9758
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0556 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.33 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.325
	P, R  : 0.222, 0.606

==================================================================================================
	XP Ends: 21/9 (8 h:46)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:46)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2747 - acc: 0.9223
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1126 - acc: 0.9671
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0770 - acc: 0.9777
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0762 - acc: 0.9814
POS tagging: 4
Epoch 1/1
 - 5s - loss: 0.0489 - acc: 0.9867
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0554 - acc: 0.9867
POS tagging: 5
Epoch 1/1
 - 5s - loss: 0.0335 - acc: 0.9915
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0510 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 5s - loss: 0.0257 - acc: 0.9936
MWE identification: 4
Epoch 1/1
 - 21s - loss: 0.0489 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 5s - loss: 0.0208 - acc: 0.9950
MWE identification: 5
Epoch 1/1
 - 21s - loss: 0.0476 - acc: 0.9888
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 3.77 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.373
	P, R  : 0.421, 0.335

==================================================================================================
	XP Ends: 21/9 (8 h:51)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
11             ,2              ,89             ,34             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
11             ,27             ,True           ,161            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.008          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.009          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.028          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.046          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 11, 2, 89, 34, 5, 11, 27, True, 161, False, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.008, True, 20, 0.009, 96, 2, 20, categorical_crossentropy, 0.028, val_acc, adagrad, 4, False, 96, 0.046, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.046
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1429 - acc: 0.9624
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0563 - acc: 0.9834
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0435 - acc: 0.9865
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0812 - acc: 0.9797
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0275 - acc: 0.9916
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0617 - acc: 0.9846
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0184 - acc: 0.9943
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0567 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0139 - acc: 0.9956
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0536 - acc: 0.9870
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0113 - acc: 0.9965
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0517 - acc: 0.9876
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.58 minutes 
==================================================================================================
	PARSING TIME: 1.13 minutes 
==================================================================================================
	Identification : 0.544
	P, R  : 0.654, 0.466

==================================================================================================
	XP Ends: 21/9 (8 h:55)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:55)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.046
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2487 - acc: 0.9232
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1294 - acc: 0.9565
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1064 - acc: 0.9637
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0906 - acc: 0.9767
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0732 - acc: 0.9760
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0667 - acc: 0.9832
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0537 - acc: 0.9830
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0606 - acc: 0.9849
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0424 - acc: 0.9871
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0572 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0348 - acc: 0.9897
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0548 - acc: 0.9866
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0290 - acc: 0.9915
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0531 - acc: 0.9872
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.27 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.544
	P, R  : 0.572, 0.519

==================================================================================================
	XP Ends: 21/9 (8 h:59)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (8h:59)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.046
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1927 - acc: 0.9435
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0673 - acc: 0.9780
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0460 - acc: 0.9850
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0746 - acc: 0.9812
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0235 - acc: 0.9928
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0584 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0125 - acc: 0.9966
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0540 - acc: 0.9864
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0075 - acc: 0.9983
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0515 - acc: 0.9873
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0049 - acc: 0.9991
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0497 - acc: 0.9879
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.15 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.463
	P, R  : 0.587, 0.382

==================================================================================================
	XP Ends: 21/9 (9 h:3)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,167            ,67             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,26             ,True           ,31             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.081          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.088          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.008          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 167, 67, 12, 5, 26, True, 31, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.006, True, 20, 0.081, 256, 2, 20, categorical_crossentropy, 0.088, val_acc, adagrad, 4, False, 96, 0.008, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:3)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.081
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3836 - acc: 0.9070
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1269 - acc: 0.9692
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0985 - acc: 0.9745
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0815 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1407 - acc: 0.9692
MWE identification: 2
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0859 - acc: 0.9773
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0759 - acc: 0.9795
MWE identification: 4
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0695 - acc: 0.9808
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 1.82 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (9 h:8)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:8)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.081
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5031 - acc: 0.8631
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2385 - acc: 0.9287
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1985 - acc: 0.9377
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0770 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.2736 - acc: 0.9256
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1883 - acc: 0.9416
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1713 - acc: 0.9462
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1603 - acc: 0.9493
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.73 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (9 h:12)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:12)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.081
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4625 - acc: 0.8796
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1727 - acc: 0.9504
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1274 - acc: 0.9625
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0825 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1942 - acc: 0.9493
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1108 - acc: 0.9681
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0938 - acc: 0.9729
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0831 - acc: 0.9763
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (9 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
12             ,2              ,51             ,49             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
29             ,80             ,True           ,40             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.05           ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.087          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.035          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.013          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 12, 2, 51, 49, 9, 29, 80, True, 40, True, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.05, True, 20, 0.087, 256, 1, 20, categorical_crossentropy, 0.035, val_loss, adagrad, 4, False, 96, 0.013, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.087
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2471 - acc: 0.9401
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0961 - acc: 0.9749
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0775 - acc: 0.9787
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0813 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1030 - acc: 0.9754
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0646 - acc: 0.9822
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0559 - acc: 0.9846
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0500 - acc: 0.9862
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0455 - acc: 0.9876
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.25 minutes 
==================================================================================================
	PARSING TIME: 1.8 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (9 h:21)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:21)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.087
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3616 - acc: 0.8974
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1924 - acc: 0.9390
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1645 - acc: 0.9467
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0739 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.2012 - acc: 0.9398
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1429 - acc: 0.9540
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1280 - acc: 0.9584
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1176 - acc: 0.9615
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.1095 - acc: 0.9645
MWE identification: 6
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.87 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (9 h:26)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:26)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.087
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3187 - acc: 0.9134
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1232 - acc: 0.9636
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0933 - acc: 0.9713
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0812 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1233 - acc: 0.9649
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0712 - acc: 0.9791
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0577 - acc: 0.9836
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0488 - acc: 0.9860
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0420 - acc: 0.9884
MWE identification: 6
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.67 minutes 
==================================================================================================
	PARSING TIME: 1.23 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (9 h:30)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
19             ,7              ,75             ,53             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
12             ,33             ,True           ,56             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.014          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.005          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.012          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.058          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 19, 7, 75, 53, 7, 12, 33, True, 56, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.014, True, 20, 0.005, 128, 1, 20, categorical_crossentropy, 0.012, val_loss, adagrad, 4, False, 64, 0.058, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:30)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.058
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1406 - acc: 0.9627
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0530 - acc: 0.9841
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0436 - acc: 0.9862
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0859 - acc: 0.9779
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0227 - acc: 0.9927
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0689 - acc: 0.9824
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0145 - acc: 0.9954
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0639 - acc: 0.9840
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0108 - acc: 0.9965
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0610 - acc: 0.9848
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0088 - acc: 0.9972
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0590 - acc: 0.9853
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.541
	P, R  : 0.658, 0.46

==================================================================================================
	XP Ends: 21/9 (9 h:34)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:34)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.058
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2488 - acc: 0.9236
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1237 - acc: 0.9585
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1061 - acc: 0.9638
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0982 - acc: 0.9739
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0628 - acc: 0.9795
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0762 - acc: 0.9803
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0439 - acc: 0.9862
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0701 - acc: 0.9820
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0332 - acc: 0.9899
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0666 - acc: 0.9829
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0260 - acc: 0.9923
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0642 - acc: 0.9837
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.559
	P, R  : 0.691, 0.47

==================================================================================================
	XP Ends: 21/9 (9 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.058
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1924 - acc: 0.9438
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0635 - acc: 0.9790
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0463 - acc: 0.9845
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0789 - acc: 0.9796
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0184 - acc: 0.9943
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0641 - acc: 0.9835
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0089 - acc: 0.9976
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0601 - acc: 0.9845
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0049 - acc: 0.9989
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0578 - acc: 0.9851
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0030 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0560 - acc: 0.9857
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.05 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.48
	P, R  : 0.619, 0.392

==================================================================================================
	XP Ends: 21/9 (9 h:42)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,1              ,83             ,55             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
34             ,65             ,True           ,38             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.033          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.045          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.009          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 1, 83, 55, 7, 34, 65, True, 38, False, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.033, True, 20, 0.045, 256, 2, 20, categorical_crossentropy, 0.008, val_loss, adagrad, 4, False, 128, 0.009, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.045
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3404 - acc: 0.9175
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1174 - acc: 0.9710
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0933 - acc: 0.9754
MWE identification: 1
Epoch 1/1
 - 4s - loss: 7.6256 - acc: 0.5232
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.2136 - acc: 0.9555
MWE identification: 2
Epoch 1/1
 - 4s - loss: 0.1115 - acc: 0.9808
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1158 - acc: 0.9725
MWE identification: 3
Epoch 1/1
 - 4s - loss: 0.0621 - acc: 0.9866
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0956 - acc: 0.9757
MWE identification: 4
Epoch 1/1
 - 4s - loss: 0.0500 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0831 - acc: 0.9779
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0480 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 95.9
POS tagging accuracy (MWEs) = 95.9
	TRAINING TIME: 2.03 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.763, 0.476

==================================================================================================
	XP Ends: 21/9 (9 h:46)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:46)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.045
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4607 - acc: 0.8733
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2251 - acc: 0.9318
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1904 - acc: 0.9398
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0666 - acc: 0.2503
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1975 - acc: 0.9404
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1609 - acc: 0.9485
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1484 - acc: 0.9525
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1393 - acc: 0.9551
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.1320 - acc: 0.9578
MWE identification: 6
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.78 minutes 
==================================================================================================
	PARSING TIME: 2.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (9 h:51)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:51)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.045
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4136 - acc: 0.8914
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1581 - acc: 0.9540
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1192 - acc: 0.9650
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0814 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1189 - acc: 0.9665
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0865 - acc: 0.9748
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0742 - acc: 0.9786
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0656 - acc: 0.9814
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0586 - acc: 0.9836
MWE identification: 6
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.58 minutes 
==================================================================================================
	PARSING TIME: 1.23 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (9 h:55)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
22             ,1              ,38             ,90             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,188            ,True           ,144            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.01           ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.037          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.05           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.007          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 22, 1, 38, 90, 5, 7, 188, True, 144, True, True, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.01, False, 20, 0.037, 64, 1, 20, categorical_crossentropy, 0.05, val_loss, adagrad, 4, False, 96, 0.007, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (9h:55)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.037
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4570 - acc: 0.8873
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1791 - acc: 0.9539
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.1415 - acc: 0.9627
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0864 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1313 - acc: 0.9663
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1089 - acc: 0.9710
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0994 - acc: 0.9737
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0924 - acc: 0.9756
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.98 minutes 
==================================================================================================
	PARSING TIME: 2.42 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.167

==================================================================================================
	XP Ends: 21/9 (10 h:1)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:1)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.037
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5647 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2650 - acc: 0.9222
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.2195 - acc: 0.9328
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0843 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.2093 - acc: 0.9368
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1804 - acc: 0.9432
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1683 - acc: 0.9466
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1592 - acc: 0.9494
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.35 minutes 
==================================================================================================
	PARSING TIME: 2.98 minutes 
==================================================================================================
	Identification : 0.01
	P, R  : 0.006, 0.038

==================================================================================================
	XP Ends: 21/9 (10 h:6)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:6)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.037
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5276 - acc: 0.8603
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2150 - acc: 0.9393
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1579 - acc: 0.9545
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.2200 - acc: 0.9740
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.2338 - acc: 0.9370
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0506 - acc: 0.9882
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1540 - acc: 0.9584
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0463 - acc: 0.9891
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1210 - acc: 0.9665
MWE identification: 4
Epoch 1/1
 - 20s - loss: 0.0457 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1050 - acc: 0.9710
MWE identification: 5
Epoch 1/1
 - 20s - loss: 0.0453 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.6
POS tagging accuracy (MWEs) = 92.6
	TRAINING TIME: 3.72 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.477
	P, R  : 0.44, 0.52

==================================================================================================
	XP Ends: 21/9 (10 h:11)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
21             ,3              ,119            ,41             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
26             ,138            ,True           ,57             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.012          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.035          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.01           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.025          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 21, 3, 119, 41, 6, 26, 138, True, 57, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.012, True, 20, 0.035, 96, 2, 20, categorical_crossentropy, 0.01, val_loss, adagrad, 4, False, 96, 0.025, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:11)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1683 - acc: 0.9572
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0714 - acc: 0.9799
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0571 - acc: 0.9834
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0861 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0415 - acc: 0.9879
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0309 - acc: 0.9910
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0251 - acc: 0.9927
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0212 - acc: 0.9940
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.63 minutes 
==================================================================================================
	PARSING TIME: 2.53 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.116

==================================================================================================
	XP Ends: 21/9 (10 h:17)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:17)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2798 - acc: 0.9161
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1541 - acc: 0.9498
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1307 - acc: 0.9563
MWE identification: 1
Epoch 1/1
 - 7s - loss: 12.0818 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1067 - acc: 0.9655
MWE identification: 2
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0851 - acc: 0.9728
MWE identification: 3
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0731 - acc: 0.9767
MWE identification: 4
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0643 - acc: 0.9802
MWE identification: 5
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0575 - acc: 0.9824
MWE identification: 6
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.25 minutes 
==================================================================================================
	PARSING TIME: 2.97 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (10 h:22)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:22)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2284 - acc: 0.9347
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0881 - acc: 0.9726
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0644 - acc: 0.9797
MWE identification: 1
Epoch 1/1
 - 14s - loss: 12.0863 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0430 - acc: 0.9873
MWE identification: 2
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0268 - acc: 0.9926
MWE identification: 3
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0192 - acc: 0.9951
MWE identification: 4
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0146 - acc: 0.9966
MWE identification: 5
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 1.38 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.024

==================================================================================================
	XP Ends: 21/9 (10 h:27)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,5              ,76             ,41             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,62             ,True           ,43             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.041          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.005          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.009          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.025          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 5, 76, 41, 6, 9, 62, True, 43, True, False, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.041, True, 20, 0.005, 96, 1, 20, categorical_crossentropy, 0.009, val_loss, adagrad, 4, False, 64, 0.025, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:27)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1993 - acc: 0.9475
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0967 - acc: 0.9738
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0773 - acc: 0.9786
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0931 - acc: 0.9756
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0526 - acc: 0.9854
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0705 - acc: 0.9824
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0406 - acc: 0.9886
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0644 - acc: 0.9842
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0338 - acc: 0.9907
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0608 - acc: 0.9853
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0292 - acc: 0.9918
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0582 - acc: 0.9860
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.77 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.475
	P, R  : 0.463, 0.487

==================================================================================================
	XP Ends: 21/9 (10 h:31)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:31)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2883 - acc: 0.9130
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1609 - acc: 0.9481
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1362 - acc: 0.9553
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1050 - acc: 0.9717
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0996 - acc: 0.9684
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0750 - acc: 0.9813
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0802 - acc: 0.9753
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0681 - acc: 0.9832
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0679 - acc: 0.9796
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0641 - acc: 0.9842
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0591 - acc: 0.9828
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0613 - acc: 0.9850
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.25 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.363
	P, R  : 0.261, 0.597

==================================================================================================
	XP Ends: 21/9 (10 h:35)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:35)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2462 - acc: 0.9288
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0956 - acc: 0.9718
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0634 - acc: 0.9812
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0800 - acc: 0.9801
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0332 - acc: 0.9909
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0600 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0215 - acc: 0.9944
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0550 - acc: 0.9867
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0159 - acc: 0.9962
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0523 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0125 - acc: 0.9972
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0506 - acc: 0.9880
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 3.43 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.354
	P, R  : 0.437, 0.298

==================================================================================================
	XP Ends: 21/9 (10 h:40)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,1              ,30             ,91             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
13             ,59             ,True           ,65             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.014          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.092          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.018          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 1, 30, 91, 5, 13, 59, True, 65, False, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.014, True, 20, 0.008, 96, 1, 20, categorical_crossentropy, 0.092, val_loss, adagrad, 4, False, 256, 0.018, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:40)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1971 - acc: 0.9510
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0820 - acc: 0.9775
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0654 - acc: 0.9816
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0865 - acc: 0.9790
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0598 - acc: 0.9829
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0609 - acc: 0.9851
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0506 - acc: 0.9856
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0562 - acc: 0.9863
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0444 - acc: 0.9877
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0535 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0396 - acc: 0.9891
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0518 - acc: 0.9876
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.42 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.583
	P, R  : 0.805, 0.457

==================================================================================================
	XP Ends: 21/9 (10 h:44)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:44)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3110 - acc: 0.9091
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1714 - acc: 0.9447
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1445 - acc: 0.9530
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1064 - acc: 0.9744
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1339 - acc: 0.9564
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0672 - acc: 0.9833
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1182 - acc: 0.9617
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0610 - acc: 0.9850
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1074 - acc: 0.9653
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0576 - acc: 0.9860
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0988 - acc: 0.9681
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0551 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.95 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.624
	P, R  : 0.887, 0.481

==================================================================================================
	XP Ends: 21/9 (10 h:48)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:48)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2615 - acc: 0.9270
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1026 - acc: 0.9685
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0755 - acc: 0.9771
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0762 - acc: 0.9811
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0662 - acc: 0.9805
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0573 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0509 - acc: 0.9852
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0531 - acc: 0.9867
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0412 - acc: 0.9885
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0508 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0344 - acc: 0.9908
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0492 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.98 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.439
	P, R  : 0.603, 0.345

==================================================================================================
	XP Ends: 21/9 (10 h:52)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,8              ,34             ,40             ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
32             ,34             ,True           ,37             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.018          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.007          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.021          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 8, 34, 40, 13, 32, 34, True, 37, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.018, False, 20, 0.008, 256, 2, 20, categorical_crossentropy, 0.007, val_loss, adagrad, 4, False, 96, 0.021, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:52)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1825 - acc: 0.9541
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0771 - acc: 0.9787
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0620 - acc: 0.9821
MWE identification: 1
Epoch 1/1
 - 4s - loss: 0.1054 - acc: 0.9760
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0474 - acc: 0.9864
MWE identification: 2
Epoch 1/1
 - 4s - loss: 0.0647 - acc: 0.9839
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0374 - acc: 0.9893
MWE identification: 3
Epoch 1/1
 - 4s - loss: 0.0589 - acc: 0.9856
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0312 - acc: 0.9911
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0557 - acc: 0.9865
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0269 - acc: 0.9924
MWE identification: 5
Epoch 1/1
 - 4s - loss: 0.0537 - acc: 0.9871
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.579
	P, R  : 0.78, 0.46

==================================================================================================
	XP Ends: 21/9 (10 h:55)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:55)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2940 - acc: 0.9129
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1630 - acc: 0.9472
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1387 - acc: 0.9540
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1258 - acc: 0.9708
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1142 - acc: 0.9625
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0712 - acc: 0.9822
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0963 - acc: 0.9688
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0634 - acc: 0.9845
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0847 - acc: 0.9729
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0595 - acc: 0.9855
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0759 - acc: 0.9763
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0569 - acc: 0.9862
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.75 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.609
	P, R  : 0.859, 0.472

==================================================================================================
	XP Ends: 21/9 (10 h:59)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (10h:59)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2431 - acc: 0.9308
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0955 - acc: 0.9705
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0710 - acc: 0.9776
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0882 - acc: 0.9792
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0489 - acc: 0.9855
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0599 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0336 - acc: 0.9904
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0548 - acc: 0.9863
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0252 - acc: 0.9933
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0522 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0198 - acc: 0.9950
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0504 - acc: 0.9878
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.451
	P, R  : 0.613, 0.357

==================================================================================================
	XP Ends: 21/9 (11 h:2)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,4              ,30             ,29             ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
14             ,117            ,True           ,117            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.022          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.029          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.085          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 4, 30, 29, 11, 14, 117, True, 117, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.022, False, 20, 0.029, 128, 2, 20, categorical_crossentropy, 0.006, val_loss, adagrad, 4, False, 96, 0.085, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.085
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1619 - acc: 0.9589
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0539 - acc: 0.9838
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0417 - acc: 0.9869
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0867 - acc: 0.9803
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0289 - acc: 0.9909
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0559 - acc: 0.9861
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0171 - acc: 0.9947
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0502 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0124 - acc: 0.9961
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0474 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0098 - acc: 0.9970
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0460 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.558
	P, R  : 0.782, 0.434

==================================================================================================
	XP Ends: 21/9 (11 h:6)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:6)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.085
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2663 - acc: 0.9219
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1196 - acc: 0.9594
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0974 - acc: 0.9664
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1001 - acc: 0.9773
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0673 - acc: 0.9774
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0599 - acc: 0.9851
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0426 - acc: 0.9866
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0529 - acc: 0.9871
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0303 - acc: 0.9909
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0498 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0229 - acc: 0.9933
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0482 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.587
	P, R  : 0.621, 0.557

==================================================================================================
	XP Ends: 21/9 (11 h:10)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:10)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.085
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1999 - acc: 0.9427
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0600 - acc: 0.9803
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0403 - acc: 0.9865
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.5920 - acc: 0.9502
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0231 - acc: 0.9928
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0541 - acc: 0.9862
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0089 - acc: 0.9976
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0491 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0044 - acc: 0.9991
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0469 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0026 - acc: 0.9996
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0459 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.95 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.468
	P, R  : 0.604, 0.382

==================================================================================================
	XP Ends: 21/9 (11 h:14)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,5              ,128            ,86             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
14             ,27             ,True           ,199            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.016          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.011          ,64             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.011          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 5, 128, 86, 8, 14, 27, True, 199, True, False, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.016, False, 20, 0.011, 64, 2, 20, categorical_crossentropy, 0.006, val_loss, adagrad, 4, False, 256, 0.011, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:14)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3107 - acc: 0.9220
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1376 - acc: 0.9636
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1146 - acc: 0.9696
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0857 - acc: 0.9790
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1099 - acc: 0.9712
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0577 - acc: 0.9862
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0952 - acc: 0.9749
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0521 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0856 - acc: 0.9775
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0494 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0783 - acc: 0.9796
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0479 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.83 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.526
	P, R  : 0.52, 0.533

==================================================================================================
	XP Ends: 21/9 (11 h:18)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:18)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4105 - acc: 0.8855
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2154 - acc: 0.9338
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1865 - acc: 0.9412
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.1034 - acc: 0.9753
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1850 - acc: 0.9420
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0624 - acc: 0.9845
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1642 - acc: 0.9483
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0560 - acc: 0.9865
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1509 - acc: 0.9523
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0527 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1407 - acc: 0.9558
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0506 - acc: 0.9880
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.18 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.414
	P, R  : 0.316, 0.599

==================================================================================================
	XP Ends: 21/9 (11 h:23)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:23)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3755 - acc: 0.8977
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1569 - acc: 0.9542
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1184 - acc: 0.9666
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0721 - acc: 0.9824
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1078 - acc: 0.9702
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0510 - acc: 0.9878
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0836 - acc: 0.9776
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0476 - acc: 0.9888
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0701 - acc: 0.9817
MWE identification: 4
Epoch 1/1
 - 21s - loss: 0.0464 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0605 - acc: 0.9845
MWE identification: 5
Epoch 1/1
 - 21s - loss: 0.0457 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 3.6 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.452
	P, R  : 0.5, 0.412

==================================================================================================
	XP Ends: 21/9 (11 h:27)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,3              ,242            ,28             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
8              ,53             ,True           ,81             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.016          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.061          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.03           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 3, 242, 28, 6, 8, 53, True, 81, False, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.016, True, 20, 0.006, 96, 1, 20, categorical_crossentropy, 0.061, val_loss, adagrad, 4, False, 128, 0.03, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:27)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1610 - acc: 0.9588
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0669 - acc: 0.9808
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0518 - acc: 0.9848
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0865 - acc: 0.9783
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0377 - acc: 0.9889
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0654 - acc: 0.9838
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0283 - acc: 0.9917
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0604 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0228 - acc: 0.9934
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0574 - acc: 0.9860
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0192 - acc: 0.9944
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0556 - acc: 0.9865
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.588
	P, R  : 0.78, 0.472

==================================================================================================
	XP Ends: 21/9 (11 h:31)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:31)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2671 - acc: 0.9190
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1457 - acc: 0.9519
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1209 - acc: 0.9594
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0983 - acc: 0.9746
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0953 - acc: 0.9689
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0714 - acc: 0.9821
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0772 - acc: 0.9754
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0652 - acc: 0.9839
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0653 - acc: 0.9794
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0618 - acc: 0.9848
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0567 - acc: 0.9827
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0593 - acc: 0.9854
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.0 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.603
	P, R  : 0.829, 0.474

==================================================================================================
	XP Ends: 21/9 (11 h:35)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:35)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2154 - acc: 0.9377
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0809 - acc: 0.9746
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0564 - acc: 0.9823
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0777 - acc: 0.9804
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0355 - acc: 0.9895
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0615 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0228 - acc: 0.9939
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0571 - acc: 0.9855
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0162 - acc: 0.9961
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0546 - acc: 0.9862
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0122 - acc: 0.9974
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0528 - acc: 0.9868
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.454
	P, R  : 0.623, 0.357

==================================================================================================
	XP Ends: 21/9 (11 h:39)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
17             ,1              ,255            ,64             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
18             ,92             ,True           ,44             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.007          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.005          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.014          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.048          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 17, 1, 255, 64, 6, 18, 92, True, 44, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.007, True, 20, 0.005, 128, 1, 20, categorical_crossentropy, 0.014, val_loss, adagrad, 4, False, 256, 0.048, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:39)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1415 - acc: 0.9627
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0560 - acc: 0.9835
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0378 - acc: 0.9886
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0872 - acc: 0.9776
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0286 - acc: 0.9914
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0677 - acc: 0.9828
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0211 - acc: 0.9939
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0628 - acc: 0.9842
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0166 - acc: 0.9950
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0599 - acc: 0.9851
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0137 - acc: 0.9959
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0580 - acc: 0.9857
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.22 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.554
	P, R  : 0.695, 0.46

==================================================================================================
	XP Ends: 21/9 (11 h:43)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:43)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2487 - acc: 0.9231
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1284 - acc: 0.9569
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0957 - acc: 0.9682
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1001 - acc: 0.9737
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0764 - acc: 0.9754
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0744 - acc: 0.9811
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0604 - acc: 0.9810
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0683 - acc: 0.9828
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0495 - acc: 0.9850
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0651 - acc: 0.9836
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0416 - acc: 0.9877
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0627 - acc: 0.9843
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.77 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.595
	P, R  : 0.761, 0.488

==================================================================================================
	XP Ends: 21/9 (11 h:47)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:47)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1924 - acc: 0.9436
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0669 - acc: 0.9783
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0386 - acc: 0.9882
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0794 - acc: 0.9800
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0252 - acc: 0.9928
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0633 - acc: 0.9837
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0159 - acc: 0.9960
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0592 - acc: 0.9847
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0107 - acc: 0.9976
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0568 - acc: 0.9855
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0077 - acc: 0.9985
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0550 - acc: 0.9861
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.73 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.458
	P, R  : 0.626, 0.361

==================================================================================================
	XP Ends: 21/9 (11 h:50)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,4              ,173            ,38             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
47             ,156            ,True           ,121            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.007          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.027          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.011          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 4, 173, 38, 7, 47, 156, True, 121, False, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.007, True, 20, 0.006, 96, 1, 20, categorical_crossentropy, 0.027, val_loss, adagrad, 4, False, 96, 0.011, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:50)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3107 - acc: 0.9220
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1376 - acc: 0.9636
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1121 - acc: 0.9699
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0948 - acc: 0.9750
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0944 - acc: 0.9747
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0672 - acc: 0.9835
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0809 - acc: 0.9785
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0604 - acc: 0.9854
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0721 - acc: 0.9810
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0565 - acc: 0.9865
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0654 - acc: 0.9829
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0541 - acc: 0.9871
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.62 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.492
	P, R  : 0.453, 0.539

==================================================================================================
	XP Ends: 21/9 (11 h:54)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:54)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4105 - acc: 0.8855
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2154 - acc: 0.9338
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1842 - acc: 0.9414
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1121 - acc: 0.9697
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1622 - acc: 0.9483
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0735 - acc: 0.9817
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1439 - acc: 0.9545
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0661 - acc: 0.9838
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1319 - acc: 0.9584
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0620 - acc: 0.9849
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1225 - acc: 0.9616
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0590 - acc: 0.9856
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.317
	P, R  : 0.214, 0.613

==================================================================================================
	XP Ends: 21/9 (11 h:59)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (11h:59)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3755 - acc: 0.8977
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1569 - acc: 0.9542
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.1147 - acc: 0.9670
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0825 - acc: 0.9792
POS tagging: 4
Epoch 1/1
 - 5s - loss: 0.0850 - acc: 0.9765
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0584 - acc: 0.9860
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0651 - acc: 0.9828
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0532 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0537 - acc: 0.9863
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0507 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 5s - loss: 0.0458 - acc: 0.9886
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0491 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.2
POS tagging accuracy (MWEs) = 93.2
	TRAINING TIME: 3.27 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.363
	P, R  : 0.479, 0.292

==================================================================================================
	XP Ends: 21/9 (12 h:3)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
20             ,3              ,221            ,51             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
14             ,35             ,True           ,88             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.024          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.069          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.028          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.022          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 20, 3, 221, 51, 5, 14, 35, True, 88, True, False, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.024, False, 20, 0.069, 128, 1, 20, categorical_crossentropy, 0.028, val_loss, adagrad, 4, False, 256, 0.022, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:3)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.069
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2079 - acc: 0.9458
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1016 - acc: 0.9725
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0791 - acc: 0.9789
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0853 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0797 - acc: 0.9788
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0584 - acc: 0.9843
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0495 - acc: 0.9868
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0431 - acc: 0.9884
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.33 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (12 h:7)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:7)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.069
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2974 - acc: 0.9110
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1672 - acc: 0.9462
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1376 - acc: 0.9558
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0820 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1427 - acc: 0.9553
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1104 - acc: 0.9655
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0965 - acc: 0.9700
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0861 - acc: 0.9738
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0779 - acc: 0.9769
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.9 minutes 
==================================================================================================
	PARSING TIME: 2.8 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (12 h:12)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:12)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.069
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2569 - acc: 0.9265
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1031 - acc: 0.9697
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0665 - acc: 0.9818
MWE identification: 1
Epoch 1/1
 - 11s - loss: 8.0684 - acc: 0.4991
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1301 - acc: 0.9677
MWE identification: 2
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0518 - acc: 0.9864
MWE identification: 3
Epoch 1/1
 - 13s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0378 - acc: 0.9904
MWE identification: 4
Epoch 1/1
 - 11s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0298 - acc: 0.9928
MWE identification: 5
Epoch 1/1
 - 11s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 2.78 minutes 
==================================================================================================
	PARSING TIME: 1.6 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.133

==================================================================================================
	XP Ends: 21/9 (12 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,7              ,214            ,193            ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
42             ,49             ,True           ,106            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.009          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.009          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.016          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.007          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 7, 214, 193, 8, 42, 49, True, 106, True, False, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.009, True, 20, 0.009, 64, 1, 20, categorical_crossentropy, 0.016, val_loss, adagrad, 4, False, 128, 0.007, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4570 - acc: 0.8873
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1791 - acc: 0.9539
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1433 - acc: 0.9624
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0882 - acc: 0.9776
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1298 - acc: 0.9659
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0603 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1131 - acc: 0.9701
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0541 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1031 - acc: 0.9728
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0509 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0957 - acc: 0.9748
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0491 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.93 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0.505
	P, R  : 0.477, 0.536

==================================================================================================
	XP Ends: 21/9 (12 h:22)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:22)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5647 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2650 - acc: 0.9222
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.2214 - acc: 0.9326
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.1005 - acc: 0.9741
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.2079 - acc: 0.9363
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0648 - acc: 0.9838
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1867 - acc: 0.9416
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0582 - acc: 0.9859
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1741 - acc: 0.9448
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0547 - acc: 0.9868
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1645 - acc: 0.9478
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0524 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.18 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.353
	P, R  : 0.246, 0.627

==================================================================================================
	XP Ends: 21/9 (12 h:26)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:26)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5276 - acc: 0.8603
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2150 - acc: 0.9393
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1603 - acc: 0.9540
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0792 - acc: 0.9808
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1371 - acc: 0.9616
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0535 - acc: 0.9872
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1096 - acc: 0.9697
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0491 - acc: 0.9885
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0945 - acc: 0.9740
MWE identification: 4
Epoch 1/1
 - 21s - loss: 0.0474 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0837 - acc: 0.9776
MWE identification: 5
Epoch 1/1
 - 21s - loss: 0.0464 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 3.83 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.405
	P, R  : 0.462, 0.361

==================================================================================================
	XP Ends: 21/9 (12 h:31)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,8              ,249            ,54             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
29             ,25             ,True           ,66             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.011          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.011          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.009          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.04           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 8, 249, 54, 9, 29, 25, True, 66, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.011, False, 20, 0.011, 96, 2, 20, categorical_crossentropy, 0.009, val_loss, adagrad, 4, False, 128, 0.04, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:31)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1753 - acc: 0.9530
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0810 - acc: 0.9773
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0594 - acc: 0.9830
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0804 - acc: 0.9800
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0418 - acc: 0.9881
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0585 - acc: 0.9855
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0304 - acc: 0.9915
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0529 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0246 - acc: 0.9932
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0499 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0207 - acc: 0.9942
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0483 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.499
	P, R  : 0.501, 0.497

==================================================================================================
	XP Ends: 21/9 (12 h:35)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:35)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2582 - acc: 0.9200
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1377 - acc: 0.9550
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1087 - acc: 0.9642
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0904 - acc: 0.9769
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0799 - acc: 0.9748
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0632 - acc: 0.9845
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0593 - acc: 0.9819
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0567 - acc: 0.9864
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0474 - acc: 0.9857
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0534 - acc: 0.9872
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0393 - acc: 0.9886
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0511 - acc: 0.9878
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.03 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.352
	P, R  : 0.244, 0.629

==================================================================================================
	XP Ends: 21/9 (12 h:39)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:39)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2122 - acc: 0.9373
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0741 - acc: 0.9778
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0421 - acc: 0.9876
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0749 - acc: 0.9822
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0243 - acc: 0.9934
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0530 - acc: 0.9873
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0137 - acc: 0.9965
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0489 - acc: 0.9885
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0092 - acc: 0.9979
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0472 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0066 - acc: 0.9986
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0463 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 3.17 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.374
	P, R  : 0.45, 0.32

==================================================================================================
	XP Ends: 21/9 (12 h:43)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,1              ,251            ,69             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
26             ,164            ,True           ,93             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.02           ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.02           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.036          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 1, 251, 69, 7, 26, 164, True, 93, True, False, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.02, False, 20, 0.008, 64, 1, 20, categorical_crossentropy, 0.02, val_loss, adagrad, 4, False, 96, 0.036, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:43)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1519 - acc: 0.9606
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0623 - acc: 0.9820
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0488 - acc: 0.9854
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0799 - acc: 0.9800
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0329 - acc: 0.9901
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0615 - acc: 0.9848
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0233 - acc: 0.9930
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0566 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0181 - acc: 0.9946
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0538 - acc: 0.9869
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0150 - acc: 0.9956
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0519 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.97 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.734, 0.475

==================================================================================================
	XP Ends: 21/9 (12 h:47)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:47)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2535 - acc: 0.9221
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1377 - acc: 0.9542
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1150 - acc: 0.9612
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0887 - acc: 0.9772
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0841 - acc: 0.9723
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0665 - acc: 0.9834
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0650 - acc: 0.9795
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0603 - acc: 0.9850
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0533 - acc: 0.9835
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0570 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0451 - acc: 0.9864
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0546 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.35 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.574
	P, R  : 0.667, 0.503

==================================================================================================
	XP Ends: 21/9 (12 h:52)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:52)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2029 - acc: 0.9408
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0745 - acc: 0.9763
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0523 - acc: 0.9832
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0738 - acc: 0.9813
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0293 - acc: 0.9912
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0583 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0171 - acc: 0.9956
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0541 - acc: 0.9863
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0114 - acc: 0.9973
MWE identification: 4
Epoch 1/1
 - 21s - loss: 0.0517 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0083 - acc: 0.9983
MWE identification: 5
Epoch 1/1
 - 21s - loss: 0.0500 - acc: 0.9878
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.73 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.449
	P, R  : 0.605, 0.357

==================================================================================================
	XP Ends: 21/9 (12 h:57)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,113            ,31             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
11             ,36             ,True           ,119            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.031          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.037          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.071          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.034          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 113, 31, 6, 11, 36, True, 119, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.031, False, 20, 0.037, 96, 1, 20, categorical_crossentropy, 0.071, val_loss, adagrad, 4, False, 256, 0.034, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (12h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.037
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1554 - acc: 0.9599
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0636 - acc: 0.9817
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0461 - acc: 0.9866
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0856 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0397 - acc: 0.9886
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0292 - acc: 0.9914
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0238 - acc: 0.9932
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0200 - acc: 0.9942
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.43 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (13 h:1)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:1)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.037
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2576 - acc: 0.9211
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1399 - acc: 0.9538
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1107 - acc: 0.9634
MWE identification: 1
Epoch 1/1
 - 8s - loss: 8.2781 - acc: 0.4859
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1069 - acc: 0.9659
MWE identification: 2
Epoch 1/1
 - 8s - loss: 8.0596 - acc: 0.4998
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0820 - acc: 0.9740
MWE identification: 3
Epoch 1/1
 - 8s - loss: 8.0594 - acc: 0.4998
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0696 - acc: 0.9783
MWE identification: 4
Epoch 1/1
 - 8s - loss: 8.0594 - acc: 0.4998
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0606 - acc: 0.9813
MWE identification: 5
Epoch 1/1
 - 8s - loss: 8.0594 - acc: 0.4998
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.98 minutes 
==================================================================================================
	PARSING TIME: 3.6 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.145

==================================================================================================
	XP Ends: 21/9 (13 h:7)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:7)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.037
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2043 - acc: 0.9404
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0760 - acc: 0.9756
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0480 - acc: 0.9853
MWE identification: 1
Epoch 1/1
 - 14s - loss: 12.0865 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0379 - acc: 0.9893
MWE identification: 2
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0234 - acc: 0.9937
MWE identification: 3
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0166 - acc: 0.9960
MWE identification: 4
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0125 - acc: 0.9973
MWE identification: 5
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.05 minutes 
==================================================================================================
	PARSING TIME: 1.18 minutes 
==================================================================================================
	Identification : 0.011
	P, R  : 0.008, 0.016

==================================================================================================
	XP Ends: 21/9 (13 h:12)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,212            ,183            ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
8              ,99             ,True           ,82             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.012          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.048          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.005          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.064          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 212, 183, 10, 8, 99, True, 82, False, False, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.012, True, 20, 0.048, 64, 1, 20, categorical_crossentropy, 0.005, val_loss, adagrad, 4, False, 256, 0.064, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:12)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1722 - acc: 0.9537
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0715 - acc: 0.9795
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0453 - acc: 0.9870
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.6010 - acc: 0.9499
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0602 - acc: 0.9824
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0523 - acc: 0.9878
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0358 - acc: 0.9899
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0464 - acc: 0.9891
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0256 - acc: 0.9927
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0451 - acc: 0.9894
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0202 - acc: 0.9942
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0447 - acc: 0.9895
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.82 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.496
	P, R  : 0.493, 0.5

==================================================================================================
	XP Ends: 21/9 (13 h:16)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:16)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2567 - acc: 0.9208
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1250 - acc: 0.9584
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0855 - acc: 0.9724
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0862 - acc: 0.2499
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0699 - acc: 0.9783
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0479 - acc: 0.9855
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0370 - acc: 0.9893
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0296 - acc: 0.9918
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.15 minutes 
==================================================================================================
	PARSING TIME: 2.77 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.004, 0.004

==================================================================================================
	XP Ends: 21/9 (13 h:21)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:21)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2086 - acc: 0.9391
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0615 - acc: 0.9812
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0281 - acc: 0.9919
MWE identification: 1
Epoch 1/1
 - 21s - loss: 12.0872 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0180 - acc: 0.9954
MWE identification: 2
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0099 - acc: 0.9977
MWE identification: 3
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0065 - acc: 0.9987
MWE identification: 4
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0046 - acc: 0.9992
MWE identification: 5
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 3.53 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.018

==================================================================================================
	XP Ends: 21/9 (13 h:26)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,184            ,129            ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,28             ,True           ,39             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.026          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.048          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.024          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.008          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 184, 129, 11, 9, 28, True, 39, True, False, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.026, True, 20, 0.048, 128, 1, 20, categorical_crossentropy, 0.024, val_loss, adagrad, 4, False, 128, 0.008, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:26)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4035 - acc: 0.8996
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1648 - acc: 0.9573
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1334 - acc: 0.9649
MWE identification: 1
Epoch 1/1
 - 9s - loss: 12.0853 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1256 - acc: 0.9674
MWE identification: 2
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1043 - acc: 0.9724
MWE identification: 3
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0946 - acc: 0.9751
MWE identification: 4
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0875 - acc: 0.9772
MWE identification: 5
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.5
POS tagging accuracy (MWEs) = 95.5
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 2.4 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.143

==================================================================================================
	XP Ends: 21/9 (13 h:31)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:31)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5093 - acc: 0.8614
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2472 - acc: 0.9262
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.2093 - acc: 0.9353
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1144 - acc: 0.9741
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.6790 - acc: 0.8308
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.1046 - acc: 0.9831
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.3442 - acc: 0.9103
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0518 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.2597 - acc: 0.9265
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0484 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.2284 - acc: 0.9328
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0474 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 92.6
POS tagging accuracy (MWEs) = 92.6
	TRAINING TIME: 1.85 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.352
	P, R  : 0.249, 0.599

==================================================================================================
	XP Ends: 21/9 (13 h:35)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:35)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4780 - acc: 0.8729
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1955 - acc: 0.9440
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1455 - acc: 0.9582
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0856 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1542 - acc: 0.9590
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1055 - acc: 0.9708
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0892 - acc: 0.9759
MWE identification: 4
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0778 - acc: 0.9794
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.2
POS tagging accuracy (MWEs) = 93.2
	TRAINING TIME: 2.83 minutes 
==================================================================================================
	PARSING TIME: 1.15 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (13 h:39)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,1              ,65             ,68             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
13             ,40             ,True           ,159            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.038          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.019          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.013          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.014          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 1, 65, 68, 8, 13, 40, True, 159, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.038, True, 20, 0.019, 128, 2, 20, categorical_crossentropy, 0.013, val_loss, adagrad, 4, False, 256, 0.014, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:39)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2321 - acc: 0.9433
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0922 - acc: 0.9756
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0748 - acc: 0.9795
MWE identification: 1
Epoch 1/1
 - 8s - loss: 8.0580 - acc: 0.4996
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0725 - acc: 0.9804
MWE identification: 2
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0593 - acc: 0.9831
MWE identification: 3
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0529 - acc: 0.9852
MWE identification: 4
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0480 - acc: 0.9866
MWE identification: 5
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.27 minutes 
==================================================================================================
	PARSING TIME: 2.6 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 21/9 (13 h:45)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:45)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3476 - acc: 0.9007
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1869 - acc: 0.9404
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1600 - acc: 0.9486
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.8244 - acc: 0.9330
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1699 - acc: 0.9466
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0632 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1477 - acc: 0.9531
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0536 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1335 - acc: 0.9571
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0509 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1235 - acc: 0.9602
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0493 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.78 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.567
	P, R  : 0.622, 0.521

==================================================================================================
	XP Ends: 21/9 (13 h:48)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:48)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3012 - acc: 0.9173
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1182 - acc: 0.9647
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0899 - acc: 0.9731
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0806 - acc: 0.9816
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0991 - acc: 0.9715
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0540 - acc: 0.9868
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0761 - acc: 0.9781
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0492 - acc: 0.9882
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0632 - acc: 0.9818
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0474 - acc: 0.9888
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0543 - acc: 0.9846
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0464 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.72 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.421
	P, R  : 0.615, 0.32

==================================================================================================
	XP Ends: 21/9 (13 h:52)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
21             ,1              ,58             ,54             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,105            ,True           ,64             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.032          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.014          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.071          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 21, 1, 58, 54, 8, 7, 105, True, 64, False, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.032, False, 20, 0.006, 128, 1, 20, categorical_crossentropy, 0.014, val_loss, adagrad, 4, False, 96, 0.071, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:52)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1743 - acc: 0.9541
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0707 - acc: 0.9798
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0522 - acc: 0.9846
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0883 - acc: 0.9775
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0301 - acc: 0.9913
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0703 - acc: 0.9823
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0204 - acc: 0.9941
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0645 - acc: 0.9840
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0161 - acc: 0.9953
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0613 - acc: 0.9848
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0135 - acc: 0.9961
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0589 - acc: 0.9855
Should stop early?
Early stopping applied
POS tagging accuracy = 95.5
POS tagging accuracy (MWEs) = 95.5
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.437
	P, R  : 0.359, 0.557

==================================================================================================
	XP Ends: 21/9 (13 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (13h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2595 - acc: 0.9204
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1236 - acc: 0.9591
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0972 - acc: 0.9675
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0979 - acc: 0.9741
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0567 - acc: 0.9819
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0754 - acc: 0.9812
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0373 - acc: 0.9887
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0689 - acc: 0.9829
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0272 - acc: 0.9921
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0651 - acc: 0.9841
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0209 - acc: 0.9943
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0623 - acc: 0.9847
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 1.97 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.361
	P, R  : 0.271, 0.542

==================================================================================================
	XP Ends: 21/9 (14 h:0)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:0)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2104 - acc: 0.9389
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0602 - acc: 0.9816
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0338 - acc: 0.9897
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0773 - acc: 0.9807
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0140 - acc: 0.9961
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0614 - acc: 0.9847
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0070 - acc: 0.9983
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0565 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0042 - acc: 0.9991
MWE identification: 4
Epoch 1/1
 - 12s - loss: 0.0538 - acc: 0.9869
POS tagging: 7
Epoch 1/1
 - 5s - loss: 0.0029 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 12s - loss: 0.0518 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 93.3
POS tagging accuracy (MWEs) = 93.3
	TRAINING TIME: 3.02 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.388
	P, R  : 0.406, 0.371

==================================================================================================
	XP Ends: 21/9 (14 h:4)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
11             ,6              ,43             ,195            ,14             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,44             ,True           ,61             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.04           ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.038          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.036          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.021          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 11, 6, 43, 195, 14, 5, 44, True, 61, True, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.04, True, 20, 0.038, 128, 2, 20, categorical_crossentropy, 0.036, val_loss, adagrad, 4, False, 256, 0.021, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:4)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1825 - acc: 0.9541
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0771 - acc: 0.9787
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0603 - acc: 0.9828
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0848 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0566 - acc: 0.9842
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0439 - acc: 0.9877
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0376 - acc: 0.9896
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0329 - acc: 0.9909
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.23 minutes 
==================================================================================================
	PARSING TIME: 1.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (14 h:8)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:8)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2940 - acc: 0.9129
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1630 - acc: 0.9472
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1358 - acc: 0.9554
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0807 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1272 - acc: 0.9586
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1075 - acc: 0.9650
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0964 - acc: 0.9691
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0876 - acc: 0.9720
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0804 - acc: 0.9747
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 1.92 minutes 
==================================================================================================
	PARSING TIME: 2.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (14 h:13)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:14)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2431 - acc: 0.9308
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0955 - acc: 0.9705
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0686 - acc: 0.9791
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0827 - acc: 0.9817
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1081 - acc: 0.9693
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0553 - acc: 0.9871
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0694 - acc: 0.9808
MWE identification: 3
Epoch 1/1
 - 13s - loss: 0.0477 - acc: 0.9887
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0515 - acc: 0.9857
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0464 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0414 - acc: 0.9885
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0458 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 2.75 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.463
	P, R  : 0.64, 0.363

==================================================================================================
	XP Ends: 21/9 (14 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
12             ,1              ,178            ,192            ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
40             ,118            ,True           ,60             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.03           ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.054          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 12, 1, 178, 192, 13, 40, 118, True, 60, False, False, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.03, False, 20, 0.054, 96, 2, 20, categorical_crossentropy, 0.008, val_loss, adagrad, 4, False, 64, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5305 - acc: 0.8691
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2006 - acc: 0.9491
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1517 - acc: 0.9602
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0858 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1445 - acc: 0.9631
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1181 - acc: 0.9688
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1080 - acc: 0.9715
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1008 - acc: 0.9734
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.75 minutes 
==================================================================================================
	PARSING TIME: 1.88 minutes 
==================================================================================================
	Identification : 0.001
	P, R  : 0.001, 0.001

==================================================================================================
	XP Ends: 21/9 (14 h:22)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:22)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6402 - acc: 0.8285
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2899 - acc: 0.9161
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.2316 - acc: 0.9301
MWE identification: 1
Epoch 1/1
 - 7s - loss: 12.0833 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.2489 - acc: 0.9283
MWE identification: 2
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1965 - acc: 0.9390
MWE identification: 3
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1829 - acc: 0.9425
MWE identification: 4
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1733 - acc: 0.9451
MWE identification: 5
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.22 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (14 h:28)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:28)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6064 - acc: 0.8403
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2447 - acc: 0.9321
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1749 - acc: 0.9496
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0741 - acc: 0.9823
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.4504 - acc: 0.8777
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0648 - acc: 0.9872
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.2422 - acc: 0.9359
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0468 - acc: 0.9890
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1777 - acc: 0.9513
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0458 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1522 - acc: 0.9575
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0453 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 91.0
POS tagging accuracy (MWEs) = 91.0
	TRAINING TIME: 3.37 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.468
	P, R  : 0.414, 0.539

==================================================================================================
	XP Ends: 21/9 (14 h:32)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
13             ,4              ,35             ,76             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,51             ,True           ,54             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.008          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.031          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.095          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.076          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 13, 4, 35, 76, 5, 7, 51, True, 54, True, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.008, True, 20, 0.031, 96, 1, 20, categorical_crossentropy, 0.095, val_loss, adagrad, 4, False, 128, 0.076, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:32)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1770 - acc: 0.9535
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0703 - acc: 0.9799
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0494 - acc: 0.9853
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.1050 - acc: 0.9797
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0378 - acc: 0.9887
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0530 - acc: 0.9871
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0233 - acc: 0.9933
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0472 - acc: 0.9888
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0176 - acc: 0.9949
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0455 - acc: 0.9893
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0143 - acc: 0.9958
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0449 - acc: 0.9895
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.53 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0.476
	P, R  : 0.498, 0.455

==================================================================================================
	XP Ends: 21/9 (14 h:36)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:36)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2623 - acc: 0.9199
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1231 - acc: 0.9595
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0918 - acc: 0.9699
MWE identification: 1
Epoch 1/1
 - 7s - loss: 1.9103 - acc: 0.8689
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0695 - acc: 0.9776
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0570 - acc: 0.9858
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0432 - acc: 0.9869
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0498 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0304 - acc: 0.9912
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0478 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0228 - acc: 0.9937
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0470 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.02 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.393
	P, R  : 0.291, 0.604

==================================================================================================
	XP Ends: 21/9 (14 h:40)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:40)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2122 - acc: 0.9388
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0597 - acc: 0.9815
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0309 - acc: 0.9907
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0779 - acc: 0.9828
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0209 - acc: 0.9941
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0486 - acc: 0.9883
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0086 - acc: 0.9979
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0460 - acc: 0.9891
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0049 - acc: 0.9990
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0454 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0033 - acc: 0.9994
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0451 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 3.17 minutes 
==================================================================================================
	PARSING TIME: 0.65 minutes 
==================================================================================================
	Identification : 0.408
	P, R  : 0.447, 0.375

==================================================================================================
	XP Ends: 21/9 (14 h:44)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,7              ,119            ,110            ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
14             ,49             ,True           ,47             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.029          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.016          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.038          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 7, 119, 110, 7, 14, 49, True, 47, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.029, True, 20, 0.016, 128, 1, 20, categorical_crossentropy, 0.006, val_loss, adagrad, 4, False, 128, 0.038, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1771 - acc: 0.9525
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0818 - acc: 0.9771
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0603 - acc: 0.9828
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.1983 - acc: 0.9735
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0450 - acc: 0.9873
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0563 - acc: 0.9865
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0322 - acc: 0.9909
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0500 - acc: 0.9883
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0258 - acc: 0.9927
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0475 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0217 - acc: 0.9939
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0463 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.38 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.484
	P, R  : 0.481, 0.488

==================================================================================================
	XP Ends: 21/9 (14 h:48)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:48)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2589 - acc: 0.9200
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1396 - acc: 0.9543
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1113 - acc: 0.9635
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0932 - acc: 0.9772
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0863 - acc: 0.9728
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0606 - acc: 0.9852
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0638 - acc: 0.9806
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0535 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0514 - acc: 0.9846
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0507 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0428 - acc: 0.9875
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0491 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 1.87 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.365
	P, R  : 0.258, 0.624

==================================================================================================
	XP Ends: 21/9 (14 h:52)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:52)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2135 - acc: 0.9367
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0761 - acc: 0.9772
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0439 - acc: 0.9872
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0836 - acc: 0.9820
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0286 - acc: 0.9922
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0522 - acc: 0.9877
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0157 - acc: 0.9961
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0476 - acc: 0.9889
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0104 - acc: 0.9976
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0464 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0075 - acc: 0.9984
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0458 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 2.9 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.395
	P, R  : 0.444, 0.355

==================================================================================================
	XP Ends: 21/9 (14 h:56)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,7              ,134            ,54             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
44             ,79             ,True           ,78             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.019          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.057          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.083          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.054          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 7, 134, 54, 5, 44, 79, True, 78, False, False, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.019, True, 20, 0.057, 256, 2, 20, categorical_crossentropy, 0.083, val_loss, adagrad, 4, False, 96, 0.054, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (14h:56)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.057
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1698 - acc: 0.9544
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0742 - acc: 0.9788
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0550 - acc: 0.9837
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1127 - acc: 0.9767
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0745 - acc: 0.9791
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.2785 - acc: 0.9732
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0419 - acc: 0.9881
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0491 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0286 - acc: 0.9919
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0462 - acc: 0.9893
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0223 - acc: 0.9936
MWE identification: 5
Epoch 1/1
 - 4s - loss: 0.0453 - acc: 0.9895
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0186 - acc: 0.9947
MWE identification: 6
Epoch 1/1
 - 4s - loss: 0.0450 - acc: 0.9895
Should stop early?
Early stopping applied
POS tagging accuracy = 95.0
POS tagging accuracy (MWEs) = 95.0
	TRAINING TIME: 2.22 minutes 
==================================================================================================
	PARSING TIME: 1.15 minutes 
==================================================================================================
	Identification : 0.481
	P, R  : 0.479, 0.484

==================================================================================================
	XP Ends: 21/9 (15 h:0)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:0)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.057
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2533 - acc: 0.9215
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1275 - acc: 0.9576
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1015 - acc: 0.9661
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.4027 - acc: 0.9568
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1072 - acc: 0.9659
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.2025 - acc: 0.9766
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0652 - acc: 0.9794
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0713 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0484 - acc: 0.9852
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0503 - acc: 0.9883
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0365 - acc: 0.9891
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0482 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 1.75 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.353
	P, R  : 0.249, 0.609

==================================================================================================
	XP Ends: 21/9 (15 h:3)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:3)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.057
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2065 - acc: 0.9392
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0643 - acc: 0.9803
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0365 - acc: 0.9891
MWE identification: 1
Epoch 1/1
 - 7s - loss: 12.0830 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 5s - loss: 0.0193 - acc: 0.9947
MWE identification: 2
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 5s - loss: 0.0089 - acc: 0.9976
MWE identification: 3
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 5s - loss: 0.0053 - acc: 0.9988
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0037 - acc: 0.9993
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 2.6 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.053

==================================================================================================
	XP Ends: 21/9 (15 h:8)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,1              ,133            ,48             ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
15             ,87             ,True           ,83             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.012          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.012          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.083          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.078          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 1, 133, 48, 13, 15, 87, True, 83, False, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.012, False, 20, 0.012, 96, 2, 20, categorical_crossentropy, 0.083, val_loss, adagrad, 4, False, 96, 0.078, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:8)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.078
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1562 - acc: 0.9601
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0527 - acc: 0.9844
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0403 - acc: 0.9874
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0778 - acc: 0.9805
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0238 - acc: 0.9925
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0602 - acc: 0.9850
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0147 - acc: 0.9954
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0553 - acc: 0.9864
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0109 - acc: 0.9965
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0523 - acc: 0.9873
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0087 - acc: 0.9973
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0504 - acc: 0.9879
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.57
	P, R  : 0.696, 0.482

==================================================================================================
	XP Ends: 21/9 (15 h:12)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:12)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.078
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2547 - acc: 0.9227
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1180 - acc: 0.9596
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0955 - acc: 0.9671
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0880 - acc: 0.9773
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0585 - acc: 0.9807
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0657 - acc: 0.9832
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0382 - acc: 0.9878
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0594 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0273 - acc: 0.9916
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0557 - acc: 0.9861
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0204 - acc: 0.9941
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0533 - acc: 0.9870
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.05 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.525
	P, R  : 0.51, 0.541

==================================================================================================
	XP Ends: 21/9 (15 h:16)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:16)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.078
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1978 - acc: 0.9432
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0603 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0405 - acc: 0.9867
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0744 - acc: 0.9812
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0190 - acc: 0.9943
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0581 - acc: 0.9850
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0088 - acc: 0.9978
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0536 - acc: 0.9865
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0050 - acc: 0.9990
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0509 - acc: 0.9874
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0032 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0490 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.468
	P, R  : 0.604, 0.382

==================================================================================================
	XP Ends: 21/9 (15 h:20)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,5              ,117            ,30             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
16             ,30             ,True           ,55             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.005          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.015          ,64             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.014          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.071          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 5, 117, 30, 7, 16, 30, True, 55, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.005, True, 20, 0.015, 64, 2, 20, categorical_crossentropy, 0.014, val_loss, adagrad, 4, False, 64, 0.071, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:20)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1490 - acc: 0.9615
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0526 - acc: 0.9843
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0438 - acc: 0.9863
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0753 - acc: 0.9811
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0244 - acc: 0.9923
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0579 - acc: 0.9855
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0148 - acc: 0.9953
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0528 - acc: 0.9870
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0109 - acc: 0.9965
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0498 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0087 - acc: 0.9973
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0481 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 3.1 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.569
	P, R  : 0.721, 0.47

==================================================================================================
	XP Ends: 21/9 (15 h:25)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:25)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2511 - acc: 0.9234
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1197 - acc: 0.9595
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1034 - acc: 0.9645
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0834 - acc: 0.9786
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0618 - acc: 0.9798
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0619 - acc: 0.9843
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0404 - acc: 0.9872
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0559 - acc: 0.9862
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0293 - acc: 0.9911
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0527 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0223 - acc: 0.9934
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0506 - acc: 0.9878
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.543
	P, R  : 0.564, 0.524

==================================================================================================
	XP Ends: 21/9 (15 h:29)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:29)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1956 - acc: 0.9436
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0609 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0456 - acc: 0.9847
MWE identification: 1
Epoch 1/1
 - 20s - loss: 0.0702 - acc: 0.9819
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0194 - acc: 0.9941
MWE identification: 2
Epoch 1/1
 - 20s - loss: 0.0560 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0085 - acc: 0.9978
MWE identification: 3
Epoch 1/1
 - 20s - loss: 0.0517 - acc: 0.9870
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0046 - acc: 0.9991
MWE identification: 4
Epoch 1/1
 - 20s - loss: 0.0492 - acc: 0.9879
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0028 - acc: 0.9996
MWE identification: 5
Epoch 1/1
 - 20s - loss: 0.0476 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.85 minutes 
==================================================================================================
	PARSING TIME: 0.82 minutes 
==================================================================================================
	Identification : 0.458
	P, R  : 0.559, 0.388

==================================================================================================
	XP Ends: 21/9 (15 h:34)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
12             ,2              ,61             ,42             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,150            ,True           ,31             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.023          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.01           ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.012          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 12, 2, 61, 42, 5, 7, 150, True, 31, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.023, True, 20, 0.008, 96, 1, 20, categorical_crossentropy, 0.01, val_acc, adagrad, 4, False, 256, 0.012, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:34)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2643 - acc: 0.9359
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1003 - acc: 0.9742
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0815 - acc: 0.9782
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0867 - acc: 0.9788
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0761 - acc: 0.9790
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0605 - acc: 0.9851
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0663 - acc: 0.9813
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0558 - acc: 0.9863
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0599 - acc: 0.9831
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0532 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0550 - acc: 0.9844
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0516 - acc: 0.9877
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0508 - acc: 0.9857
MWE identification: 6
Epoch 1/1
 - 10s - loss: 0.0503 - acc: 0.9880
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.62 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.592
	P, R  : 0.83, 0.46

==================================================================================================
	XP Ends: 21/9 (15 h:38)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:38)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3791 - acc: 0.8933
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1986 - acc: 0.9376
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1707 - acc: 0.9455
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1095 - acc: 0.9735
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1620 - acc: 0.9481
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0673 - acc: 0.9832
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1458 - acc: 0.9531
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0610 - acc: 0.9850
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1353 - acc: 0.9565
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0574 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1270 - acc: 0.9590
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0549 - acc: 0.9867
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.1199 - acc: 0.9613
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0533 - acc: 0.9872
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.03 minutes 
==================================================================================================
	PARSING TIME: 1.85 minutes 
==================================================================================================
	Identification : 0.616
	P, R  : 0.871, 0.476

==================================================================================================
	XP Ends: 21/9 (15 h:42)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:42)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3356 - acc: 0.9096
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1296 - acc: 0.9618
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0994 - acc: 0.9707
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0808 - acc: 0.9805
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0918 - acc: 0.9730
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0580 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0752 - acc: 0.9782
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0537 - acc: 0.9867
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0648 - acc: 0.9814
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0513 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0569 - acc: 0.9839
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0496 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.0 minutes 
==================================================================================================
	PARSING TIME: 0.82 minutes 
==================================================================================================
	Identification : 0.436
	P, R  : 0.646, 0.329

==================================================================================================
	XP Ends: 21/9 (15 h:47)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,7              ,111            ,175            ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
26             ,48             ,True           ,29             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.022          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.055          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.098          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.007          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 7, 111, 175, 8, 26, 48, True, 29, False, False, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.022, True, 20, 0.055, 256, 1, 20, categorical_crossentropy, 0.098, val_acc, adagrad, 4, False, 256, 0.007, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4570 - acc: 0.8873
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1791 - acc: 0.9539
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1477 - acc: 0.9615
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0816 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1561 - acc: 0.9605
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1260 - acc: 0.9668
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1152 - acc: 0.9698
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1073 - acc: 0.9719
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0.042
	P, R  : 0.027, 0.093

==================================================================================================
	XP Ends: 21/9 (15 h:51)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:51)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5647 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2650 - acc: 0.9222
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.2261 - acc: 0.9320
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0762 - acc: 0.2499
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.2669 - acc: 0.9255
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.2070 - acc: 0.9366
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1921 - acc: 0.9405
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1817 - acc: 0.9431
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 1.53 minutes 
==================================================================================================
	PARSING TIME: 3.0 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (15 h:55)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:56)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5276 - acc: 0.8603
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2150 - acc: 0.9393
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1665 - acc: 0.9525
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.2504 - acc: 0.9684
POS tagging: 4
Epoch 1/1
 - 2s - loss: 1.0330 - acc: 0.7118
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0821 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.3800 - acc: 0.9039
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0495 - acc: 0.9887
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.2478 - acc: 0.9379
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0467 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1974 - acc: 0.9479
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0460 - acc: 0.9892
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.1722 - acc: 0.9539
MWE identification: 6
Epoch 1/1
 - 6s - loss: 0.0457 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 90.6
POS tagging accuracy (MWEs) = 90.6
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.463
	P, R  : 0.449, 0.478

==================================================================================================
	XP Ends: 21/9 (15 h:59)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
13             ,3              ,109            ,109            ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
36             ,44             ,True           ,57             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.008          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 13, 3, 109, 109, 5, 36, 44, True, 57, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.006, True, 20, 0.008, 128, 2, 20, categorical_crossentropy, 0.008, val_loss, adagrad, 4, False, 128, 0.008, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (15h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3836 - acc: 0.9070
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1269 - acc: 0.9692
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0995 - acc: 0.9744
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0926 - acc: 0.9777
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0877 - acc: 0.9767
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0614 - acc: 0.9850
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0765 - acc: 0.9788
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0561 - acc: 0.9864
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0698 - acc: 0.9805
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0534 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0649 - acc: 0.9816
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0517 - acc: 0.9876
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.3 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.583
	P, R  : 0.777, 0.467

==================================================================================================
	XP Ends: 21/9 (16 h:3)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:3)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5031 - acc: 0.8631
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2385 - acc: 0.9287
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1999 - acc: 0.9375
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1159 - acc: 0.9718
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1830 - acc: 0.9423
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0681 - acc: 0.9831
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1648 - acc: 0.9476
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0615 - acc: 0.9849
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1538 - acc: 0.9508
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0579 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1455 - acc: 0.9532
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0553 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.87 minutes 
==================================================================================================
	PARSING TIME: 1.78 minutes 
==================================================================================================
	Identification : 0.617
	P, R  : 0.882, 0.474

==================================================================================================
	XP Ends: 21/9 (16 h:7)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:7)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4625 - acc: 0.8796
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1727 - acc: 0.9504
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1289 - acc: 0.9622
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0818 - acc: 0.9801
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1115 - acc: 0.9678
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0577 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0916 - acc: 0.9732
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0533 - acc: 0.9868
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0802 - acc: 0.9768
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0509 - acc: 0.9876
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0719 - acc: 0.9796
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0492 - acc: 0.9882
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.85 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.454
	P, R  : 0.642, 0.351

==================================================================================================
	XP Ends: 21/9 (16 h:11)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,57             ,59             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
14             ,129            ,True           ,30             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.006          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.012          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.094          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.03           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 57, 59, 7, 14, 129, True, 30, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.006, False, 20, 0.012, 128, 1, 20, categorical_crossentropy, 0.094, val_acc, adagrad, 4, False, 128, 0.03, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:11)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1609 - acc: 0.9588
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0669 - acc: 0.9808
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0518 - acc: 0.9848
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0834 - acc: 0.9802
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0405 - acc: 0.9880
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0583 - acc: 0.9856
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0297 - acc: 0.9912
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0532 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0238 - acc: 0.9931
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0505 - acc: 0.9879
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0199 - acc: 0.9942
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0489 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.33 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.569
	P, R  : 0.732, 0.466

==================================================================================================
	XP Ends: 21/9 (16 h:14)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:14)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2671 - acc: 0.9190
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1457 - acc: 0.9519
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1209 - acc: 0.9594
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.1132 - acc: 0.9764
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0993 - acc: 0.9676
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0653 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0795 - acc: 0.9747
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0572 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0671 - acc: 0.9790
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0539 - acc: 0.9872
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0582 - acc: 0.9821
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0517 - acc: 0.9877
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0513 - acc: 0.9845
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0504 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.561
	P, R  : 0.648, 0.495

==================================================================================================
	XP Ends: 21/9 (16 h:18)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:18)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2154 - acc: 0.9377
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0809 - acc: 0.9745
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0564 - acc: 0.9823
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0790 - acc: 0.9812
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0391 - acc: 0.9885
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0562 - acc: 0.9857
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0243 - acc: 0.9934
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0516 - acc: 0.9873
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0169 - acc: 0.9958
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0493 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0126 - acc: 0.9972
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0478 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.85 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.436
	P, R  : 0.626, 0.335

==================================================================================================
	XP Ends: 21/9 (16 h:22)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
21             ,2              ,96             ,33             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
14             ,86             ,True           ,91             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.021          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.019          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.019          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 21, 2, 96, 33, 6, 14, 86, True, 91, True, True, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.021, True, 20, 0.019, 256, 1, 20, categorical_crossentropy, 0.006, val_acc, adagrad, 4, False, 64, 0.019, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:22)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2225 - acc: 0.9422
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1080 - acc: 0.9708
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0871 - acc: 0.9762
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1058 - acc: 0.9781
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0728 - acc: 0.9802
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0747 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0567 - acc: 0.9847
MWE identification: 3
Epoch 1/1
 - 4s - loss: 0.0499 - acc: 0.9885
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0471 - acc: 0.9873
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0474 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0407 - acc: 0.9889
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0463 - acc: 0.9893
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0362 - acc: 0.9902
MWE identification: 6
Epoch 1/1
 - 4s - loss: 0.0457 - acc: 0.9894
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.45 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0.493
	P, R  : 0.504, 0.482

==================================================================================================
	XP Ends: 21/9 (16 h:26)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:26)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3130 - acc: 0.9077
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1760 - acc: 0.9434
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1499 - acc: 0.9513
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.2969 - acc: 0.9627
POS tagging: 4
Epoch 1/1
 - 7s - loss: 0.1287 - acc: 0.9593
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.1150 - acc: 0.9819
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1056 - acc: 0.9671
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0563 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0913 - acc: 0.9718
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0522 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0811 - acc: 0.9754
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0505 - acc: 0.9885
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0731 - acc: 0.9782
MWE identification: 6
Epoch 1/1
 - 3s - loss: 0.0494 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.396
	P, R  : 0.305, 0.566

==================================================================================================
	XP Ends: 21/9 (16 h:30)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:30)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2747 - acc: 0.9223
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1126 - acc: 0.9670
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0776 - acc: 0.9772
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0990 - acc: 0.9807
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0574 - acc: 0.9843
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0576 - acc: 0.9876
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0368 - acc: 0.9904
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0479 - acc: 0.9890
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0271 - acc: 0.9932
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0466 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0215 - acc: 0.9948
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0461 - acc: 0.9892
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0179 - acc: 0.9957
MWE identification: 6
Epoch 1/1
 - 6s - loss: 0.0458 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 2.93 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.376
	P, R  : 0.505, 0.3

==================================================================================================
	XP Ends: 21/9 (16 h:34)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,2              ,82             ,67             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
10             ,156            ,True           ,60             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.026          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.016          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.042          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.07           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 2, 82, 67, 5, 10, 156, True, 60, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.026, False, 20, 0.016, 96, 1, 20, categorical_crossentropy, 0.042, val_loss, adagrad, 4, False, 96, 0.07, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:34)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.07
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1479 - acc: 0.9614
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0524 - acc: 0.9842
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0402 - acc: 0.9873
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0777 - acc: 0.9812
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0252 - acc: 0.9922
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0569 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0155 - acc: 0.9951
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0518 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0113 - acc: 0.9964
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0490 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0089 - acc: 0.9972
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0474 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.558
	P, R  : 0.708, 0.46

==================================================================================================
	XP Ends: 21/9 (16 h:38)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:38)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.07
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2509 - acc: 0.9233
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1196 - acc: 0.9597
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0973 - acc: 0.9665
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0840 - acc: 0.9784
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0631 - acc: 0.9796
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0609 - acc: 0.9846
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0421 - acc: 0.9868
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0549 - acc: 0.9864
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0307 - acc: 0.9908
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0518 - acc: 0.9874
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0235 - acc: 0.9930
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0499 - acc: 0.9880
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.28 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.546
	P, R  : 0.558, 0.535

==================================================================================================
	XP Ends: 21/9 (16 h:43)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:43)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.07
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1954 - acc: 0.9438
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0608 - acc: 0.9802
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0409 - acc: 0.9863
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0725 - acc: 0.9817
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0200 - acc: 0.9938
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0559 - acc: 0.9857
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0088 - acc: 0.9977
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0513 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0047 - acc: 0.9990
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0488 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0029 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0472 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 0.78 minutes 
==================================================================================================
	Identification : 0.46
	P, R  : 0.61, 0.369

==================================================================================================
	XP Ends: 21/9 (16 h:47)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,2              ,164            ,42             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
37             ,38             ,True           ,67             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.034          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.009          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.096          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.044          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 2, 164, 42, 7, 37, 38, True, 67, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.034, True, 20, 0.009, 96, 2, 20, categorical_crossentropy, 0.096, val_loss, adagrad, 4, False, 96, 0.044, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1447 - acc: 0.9621
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0572 - acc: 0.9832
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0443 - acc: 0.9863
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0813 - acc: 0.9797
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0285 - acc: 0.9914
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0619 - acc: 0.9845
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0193 - acc: 0.9941
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0567 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0147 - acc: 0.9955
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0536 - acc: 0.9870
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0120 - acc: 0.9963
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0517 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.55
	P, R  : 0.684, 0.46

==================================================================================================
	XP Ends: 21/9 (16 h:51)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:51)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2490 - acc: 0.9232
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1302 - acc: 0.9564
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1075 - acc: 0.9636
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0925 - acc: 0.9763
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0747 - acc: 0.9755
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0674 - acc: 0.9832
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0554 - acc: 0.9825
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0610 - acc: 0.9848
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0440 - acc: 0.9866
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0575 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0363 - acc: 0.9892
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0551 - acc: 0.9865
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.566
	P, R  : 0.656, 0.497

==================================================================================================
	XP Ends: 21/9 (16 h:55)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:55)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1933 - acc: 0.9433
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0684 - acc: 0.9778
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0467 - acc: 0.9847
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0743 - acc: 0.9812
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0239 - acc: 0.9928
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0579 - acc: 0.9850
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0127 - acc: 0.9966
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0536 - acc: 0.9864
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0076 - acc: 0.9984
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0511 - acc: 0.9873
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0050 - acc: 0.9991
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0494 - acc: 0.9879
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.447
	P, R  : 0.559, 0.373

==================================================================================================
	XP Ends: 21/9 (16 h:59)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
21             ,9              ,44             ,112            ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
26             ,78             ,True           ,59             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.01           ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.039          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.061          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.083          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 21, 9, 44, 112, 6, 26, 78, True, 59, False, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.01, False, 20, 0.039, 256, 1, 20, categorical_crossentropy, 0.061, val_loss, adagrad, 4, False, 256, 0.083, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (16h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.083
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1818 - acc: 0.9532
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0698 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0434 - acc: 0.9875
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1104 - acc: 0.9779
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0445 - acc: 0.9873
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0547 - acc: 0.9868
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0282 - acc: 0.9922
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0477 - acc: 0.9888
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0214 - acc: 0.9940
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0458 - acc: 0.9893
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0173 - acc: 0.9951
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0451 - acc: 0.9894
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 1.95 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.481
	P, R  : 0.466, 0.496

==================================================================================================
	XP Ends: 21/9 (17 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.083
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2689 - acc: 0.9187
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1240 - acc: 0.9589
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0828 - acc: 0.9734
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1399 - acc: 0.9734
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0782 - acc: 0.9750
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0615 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0512 - acc: 0.9843
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0509 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0375 - acc: 0.9891
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0483 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0290 - acc: 0.9919
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0474 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 1.58 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.4
	P, R  : 0.298, 0.608

==================================================================================================
	XP Ends: 21/9 (17 h:6)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:6)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.083
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2135 - acc: 0.9388
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0590 - acc: 0.9816
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0257 - acc: 0.9927
MWE identification: 1
Epoch 1/1
 - 7s - loss: 8.0622 - acc: 0.4995
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0172 - acc: 0.9957
MWE identification: 2
Epoch 1/1
 - 7s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0089 - acc: 0.9980
MWE identification: 3
Epoch 1/1
 - 7s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0058 - acc: 0.9989
MWE identification: 4
Epoch 1/1
 - 7s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0041 - acc: 0.9993
MWE identification: 5
Epoch 1/1
 - 7s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.3
POS tagging accuracy (MWEs) = 93.3
	TRAINING TIME: 2.43 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (17 h:10)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,28             ,151            ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,67             ,True           ,111            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.008          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.021          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 28, 151, 12, 5, 67, True, 111, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.008, False, 20, 0.006, 64, 1, 20, categorical_crossentropy, 0.006, val_loss, adagrad, 4, False, 128, 0.021, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:10)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1825 - acc: 0.9541
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0771 - acc: 0.9786
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0614 - acc: 0.9824
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0823 - acc: 0.9791
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0484 - acc: 0.9861
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0637 - acc: 0.9842
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0386 - acc: 0.9889
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0590 - acc: 0.9856
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0324 - acc: 0.9909
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0562 - acc: 0.9864
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0281 - acc: 0.9921
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0544 - acc: 0.9869
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.87 minutes 
==================================================================================================
	PARSING TIME: 1.17 minutes 
==================================================================================================
	Identification : 0.58
	P, R  : 0.777, 0.463

==================================================================================================
	XP Ends: 21/9 (17 h:14)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:14)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2940 - acc: 0.9129
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1630 - acc: 0.9472
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1377 - acc: 0.9545
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0967 - acc: 0.9750
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1153 - acc: 0.9621
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0701 - acc: 0.9824
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0982 - acc: 0.9683
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0639 - acc: 0.9841
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0867 - acc: 0.9724
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0606 - acc: 0.9850
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0779 - acc: 0.9756
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0581 - acc: 0.9857
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.27 minutes 
==================================================================================================
	PARSING TIME: 1.83 minutes 
==================================================================================================
	Identification : 0.605
	P, R  : 0.865, 0.465

==================================================================================================
	XP Ends: 21/9 (17 h:19)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:19)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2431 - acc: 0.9308
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0955 - acc: 0.9705
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0702 - acc: 0.9781
MWE identification: 1
Epoch 1/1
 - 20s - loss: 0.0753 - acc: 0.9811
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0501 - acc: 0.9852
MWE identification: 2
Epoch 1/1
 - 20s - loss: 0.0600 - acc: 0.9846
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0352 - acc: 0.9900
MWE identification: 3
Epoch 1/1
 - 20s - loss: 0.0557 - acc: 0.9858
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0267 - acc: 0.9929
MWE identification: 4
Epoch 1/1
 - 20s - loss: 0.0533 - acc: 0.9866
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0211 - acc: 0.9947
MWE identification: 5
Epoch 1/1
 - 21s - loss: 0.0516 - acc: 0.9873
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.65 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.449
	P, R  : 0.605, 0.357

==================================================================================================
	XP Ends: 21/9 (17 h:23)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
12             ,1              ,219            ,82             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,152            ,True           ,29             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.039          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.025          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.012          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.019          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 12, 1, 219, 82, 8, 9, 152, True, 29, True, True, False, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.039, False, 20, 0.025, 64, 1, 20, categorical_crossentropy, 0.012, val_loss, adagrad, 4, False, 96, 0.019, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:23)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2225 - acc: 0.9422
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1080 - acc: 0.9708
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0866 - acc: 0.9764
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0862 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0666 - acc: 0.9821
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0528 - acc: 0.9857
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0449 - acc: 0.9878
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0393 - acc: 0.9894
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 3.02 minutes 
==================================================================================================
	PARSING TIME: 2.53 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.118

==================================================================================================
	XP Ends: 21/9 (17 h:29)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:29)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3130 - acc: 0.9077
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1760 - acc: 0.9434
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1489 - acc: 0.9518
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.3152 - acc: 0.9657
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1439 - acc: 0.9548
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0578 - acc: 0.9864
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1157 - acc: 0.9642
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0503 - acc: 0.9882
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0990 - acc: 0.9693
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0486 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0876 - acc: 0.9733
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0477 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.35 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.412
	P, R  : 0.32, 0.58

==================================================================================================
	XP Ends: 21/9 (17 h:34)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:34)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2747 - acc: 0.9223
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1126 - acc: 0.9671
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0770 - acc: 0.9777
MWE identification: 1
Epoch 1/1
 - 21s - loss: 8.0590 - acc: 0.4999
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0530 - acc: 0.9858
MWE identification: 2
Epoch 1/1
 - 21s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0341 - acc: 0.9913
MWE identification: 3
Epoch 1/1
 - 21s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0258 - acc: 0.9937
MWE identification: 4
Epoch 1/1
 - 21s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0208 - acc: 0.9950
MWE identification: 5
Epoch 1/1
 - 21s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 3.78 minutes 
==================================================================================================
	PARSING TIME: 1.58 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.133

==================================================================================================
	XP Ends: 21/9 (17 h:39)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,7              ,119            ,35             ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
18             ,26             ,True           ,117            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.007          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.017          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.051          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 7, 119, 35, 11, 18, 26, True, 117, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.007, False, 20, 0.008, 96, 1, 20, categorical_crossentropy, 0.017, val_acc, adagrad, 4, False, 128, 0.051, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:39)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1403 - acc: 0.9627
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0548 - acc: 0.9838
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0402 - acc: 0.9875
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0799 - acc: 0.9798
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0262 - acc: 0.9919
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0624 - acc: 0.9843
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0175 - acc: 0.9946
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0575 - acc: 0.9858
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0132 - acc: 0.9958
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0545 - acc: 0.9867
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0107 - acc: 0.9967
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0526 - acc: 0.9871
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.562
	P, R  : 0.669, 0.485

==================================================================================================
	XP Ends: 21/9 (17 h:43)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:43)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2478 - acc: 0.9236
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1261 - acc: 0.9579
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0999 - acc: 0.9664
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0918 - acc: 0.9762
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0700 - acc: 0.9772
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0682 - acc: 0.9828
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0511 - acc: 0.9841
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0621 - acc: 0.9845
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0399 - acc: 0.9878
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0587 - acc: 0.9855
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0324 - acc: 0.9904
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0562 - acc: 0.9861
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0268 - acc: 0.9923
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0545 - acc: 0.9867
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.2 minutes 
==================================================================================================
	PARSING TIME: 1.77 minutes 
==================================================================================================
	Identification : 0.557
	P, R  : 0.634, 0.497

==================================================================================================
	XP Ends: 21/9 (17 h:48)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:48)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1914 - acc: 0.9437
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0655 - acc: 0.9784
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0418 - acc: 0.9864
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0756 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0221 - acc: 0.9933
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0597 - acc: 0.9846
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0119 - acc: 0.9968
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0555 - acc: 0.9860
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0070 - acc: 0.9985
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0529 - acc: 0.9868
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0046 - acc: 0.9991
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0511 - acc: 0.9874
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 3.13 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.471
	P, R  : 0.586, 0.394

==================================================================================================
	XP Ends: 21/9 (17 h:52)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
22             ,1              ,64             ,53             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
11             ,146            ,True           ,160            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.017          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.064          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.088          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 22, 1, 64, 53, 9, 11, 146, True, 160, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.017, True, 20, 0.064, 256, 2, 20, categorical_crossentropy, 0.088, val_loss, adagrad, 4, False, 256, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:52)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1239 - acc: 0.9699
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0817 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1535 - acc: 0.9663
MWE identification: 2
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1070 - acc: 0.9728
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0963 - acc: 0.9752
MWE identification: 4
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0893 - acc: 0.9767
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0840 - acc: 0.9778
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.05 minutes 
==================================================================================================
	PARSING TIME: 2.38 minutes 
==================================================================================================
	Identification : 0.01
	P, R  : 0.005, 0.118

==================================================================================================
	XP Ends: 21/9 (17 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (17h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.2349 - acc: 0.9303
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.9923 - acc: 0.9169
POS tagging: 4
Epoch 1/1
 - 2s - loss: 1.3365 - acc: 0.6540
MWE identification: 2
Epoch 1/1
 - 3s - loss: 4.0749 - acc: 0.7468
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.5500 - acc: 0.8601
MWE identification: 3
Epoch 1/1
 - 3s - loss: 4.0360 - acc: 0.7494
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.3571 - acc: 0.9036
MWE identification: 4
Epoch 1/1
 - 3s - loss: 4.0331 - acc: 0.7498
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.2769 - acc: 0.9199
MWE identification: 5
Epoch 1/1
 - 3s - loss: 4.0330 - acc: 0.7498
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.2485 - acc: 0.9263
MWE identification: 6
Epoch 1/1
 - 3s - loss: 4.0331 - acc: 0.7498
Should stop early?
Early stopping applied
POS tagging accuracy = 92.3
POS tagging accuracy (MWEs) = 92.3
	TRAINING TIME: 1.68 minutes 
==================================================================================================
	PARSING TIME: 3.07 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.071

==================================================================================================
	XP Ends: 21/9 (18 h:1)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:1)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1650 - acc: 0.9527
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0793 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.2992 - acc: 0.9318
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1550 - acc: 0.9553
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1342 - acc: 0.9613
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1214 - acc: 0.9649
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.1120 - acc: 0.9679
MWE identification: 6
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.3
POS tagging accuracy (MWEs) = 93.3
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (18 h:6)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,1              ,299            ,66             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
35             ,111            ,True           ,44             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.035          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.009          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.009          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.022          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 1, 299, 66, 6, 35, 111, True, 44, False, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.035, False, 20, 0.009, 128, 1, 20, categorical_crossentropy, 0.009, val_acc, adagrad, 4, False, 256, 0.022, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:6)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1782 - acc: 0.9550
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0755 - acc: 0.9790
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0588 - acc: 0.9833
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0880 - acc: 0.9792
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0527 - acc: 0.9849
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0608 - acc: 0.9852
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0434 - acc: 0.9876
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0557 - acc: 0.9865
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0372 - acc: 0.9895
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0531 - acc: 0.9874
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0326 - acc: 0.9909
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0514 - acc: 0.9878
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.22 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.573
	P, R  : 0.733, 0.47

==================================================================================================
	XP Ends: 21/9 (18 h:9)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:9)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2890 - acc: 0.9137
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1598 - acc: 0.9479
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1327 - acc: 0.9563
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1057 - acc: 0.9747
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1219 - acc: 0.9599
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0668 - acc: 0.9833
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1056 - acc: 0.9661
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0600 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0945 - acc: 0.9694
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0566 - acc: 0.9863
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0857 - acc: 0.9727
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0541 - acc: 0.9870
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0784 - acc: 0.9754
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0525 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 1.88 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.588
	P, R  : 0.697, 0.508

==================================================================================================
	XP Ends: 21/9 (18 h:13)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:13)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2373 - acc: 0.9321
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0925 - acc: 0.9711
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0655 - acc: 0.9800
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0805 - acc: 0.9808
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0566 - acc: 0.9832
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0576 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0416 - acc: 0.9881
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0531 - acc: 0.9868
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0324 - acc: 0.9912
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0507 - acc: 0.9877
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0261 - acc: 0.9933
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0491 - acc: 0.9882
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.78 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.455
	P, R  : 0.617, 0.361

==================================================================================================
	XP Ends: 21/9 (18 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
14             ,4              ,148            ,189            ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,89             ,True           ,31             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.012          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.017          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.044          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 14, 4, 148, 189, 5, 9, 89, True, 31, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.012, False, 20, 0.017, 256, 1, 20, categorical_crossentropy, 0.044, val_loss, adagrad, 4, False, 128, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1875 - acc: 0.9528
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0787 - acc: 0.9784
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0631 - acc: 0.9819
MWE identification: 1
Epoch 1/1
 - 4s - loss: 0.1483 - acc: 0.9753
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0566 - acc: 0.9839
MWE identification: 2
Epoch 1/1
 - 4s - loss: 0.0634 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0445 - acc: 0.9875
MWE identification: 3
Epoch 1/1
 - 4s - loss: 0.0536 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0374 - acc: 0.9895
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0507 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0324 - acc: 0.9908
MWE identification: 5
Epoch 1/1
 - 4s - loss: 0.0491 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.12 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.597
	P, R  : 0.76, 0.491

==================================================================================================
	XP Ends: 21/9 (18 h:21)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:21)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2987 - acc: 0.9120
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1653 - acc: 0.9465
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1400 - acc: 0.9539
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1597 - acc: 0.9718
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1273 - acc: 0.9586
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0709 - acc: 0.9839
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1071 - acc: 0.9654
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0564 - acc: 0.9867
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0942 - acc: 0.9696
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0528 - acc: 0.9876
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0848 - acc: 0.9729
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0509 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.68 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.594
	P, R  : 0.786, 0.477

==================================================================================================
	XP Ends: 21/9 (18 h:24)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:24)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2483 - acc: 0.9298
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0979 - acc: 0.9700
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0721 - acc: 0.9775
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.1525 - acc: 0.9764
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0623 - acc: 0.9818
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0588 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0432 - acc: 0.9878
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0511 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0325 - acc: 0.9912
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0489 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0257 - acc: 0.9934
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0475 - acc: 0.9888
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.47 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.444
	P, R  : 0.652, 0.337

==================================================================================================
	XP Ends: 21/9 (18 h:28)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
11             ,2              ,37             ,79             ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
33             ,68             ,True           ,65             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.01           ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.048          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.088          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 11, 2, 37, 79, 10, 33, 68, True, 65, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.01, True, 20, 0.048, 64, 1, 20, categorical_crossentropy, 0.008, val_loss, adagrad, 4, False, 256, 0.088, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:28)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.088
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1614 - acc: 0.9592
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0537 - acc: 0.9840
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0336 - acc: 0.9899
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0712 - acc: 0.2509
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0265 - acc: 0.9921
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0175 - acc: 0.9947
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0134 - acc: 0.9960
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0109 - acc: 0.9967
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0094 - acc: 0.9972
MWE identification: 6
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 3.1 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (18 h:32)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:32)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.088
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2663 - acc: 0.9217
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1196 - acc: 0.9591
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0824 - acc: 0.9723
MWE identification: 1
Epoch 1/1
 - 11s - loss: 8.0590 - acc: 0.4998
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0672 - acc: 0.9779
MWE identification: 2
Epoch 1/1
 - 11s - loss: 8.0594 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0460 - acc: 0.9859
MWE identification: 3
Epoch 1/1
 - 11s - loss: 8.0593 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0340 - acc: 0.9902
MWE identification: 4
Epoch 1/1
 - 11s - loss: 8.0593 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0263 - acc: 0.9927
MWE identification: 5
Epoch 1/1
 - 11s - loss: 8.0593 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.27 minutes 
==================================================================================================
	PARSING TIME: 2.77 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (18 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.088
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.048
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2026 - acc: 0.9424
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0598 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0303 - acc: 0.9904
MWE identification: 1
Epoch 1/1
 - 20s - loss: 1.7399 - acc: 0.8804
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0364 - acc: 0.9882
MWE identification: 2
Epoch 1/1
 - 20s - loss: 0.0530 - acc: 0.9865
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0156 - acc: 0.9957
MWE identification: 3
Epoch 1/1
 - 20s - loss: 0.0479 - acc: 0.9884
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0083 - acc: 0.9982
MWE identification: 4
Epoch 1/1
 - 20s - loss: 0.0463 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0051 - acc: 0.9991
MWE identification: 5
Epoch 1/1
 - 20s - loss: 0.0456 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.53 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.473
	P, R  : 0.583, 0.398

==================================================================================================
	XP Ends: 21/9 (18 h:42)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
22             ,3              ,87             ,29             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
10             ,36             ,True           ,39             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.035          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.013          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.009          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 22, 3, 87, 29, 12, 10, 36, True, 39, False, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.035, True, 20, 0.013, 256, 1, 20, categorical_crossentropy, 0.008, val_loss, adagrad, 4, False, 96, 0.009, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3637 - acc: 0.9093
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1528 - acc: 0.9601
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1237 - acc: 0.9670
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1179 - acc: 0.9744
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1114 - acc: 0.9705
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0642 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0960 - acc: 0.9746
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0548 - acc: 0.9873
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0862 - acc: 0.9772
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0513 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0791 - acc: 0.9793
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0492 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.13 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.477, 0.519

==================================================================================================
	XP Ends: 21/9 (18 h:46)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:46)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4674 - acc: 0.8716
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2339 - acc: 0.9297
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1984 - acc: 0.9378
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1841 - acc: 0.9668
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1871 - acc: 0.9414
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0668 - acc: 0.9839
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1649 - acc: 0.9480
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0586 - acc: 0.9864
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1516 - acc: 0.9520
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0545 - acc: 0.9874
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1416 - acc: 0.9553
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0522 - acc: 0.9880
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.75 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.412
	P, R  : 0.319, 0.58

==================================================================================================
	XP Ends: 21/9 (18 h:50)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:50)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4335 - acc: 0.8837
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1797 - acc: 0.9479
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1322 - acc: 0.9618
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.1040 - acc: 0.9787
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1124 - acc: 0.9687
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0564 - acc: 0.9872
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0858 - acc: 0.9769
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0491 - acc: 0.9887
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0711 - acc: 0.9814
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0474 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0613 - acc: 0.9841
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0466 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.442
	P, R  : 0.524, 0.382

==================================================================================================
	XP Ends: 21/9 (18 h:53)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,1              ,58             ,126            ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,103            ,True           ,56             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.027          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.067          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.017          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.014          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 1, 58, 126, 13, 6, 103, True, 56, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.027, True, 20, 0.067, 64, 1, 20, categorical_crossentropy, 0.017, val_loss, adagrad, 4, False, 256, 0.014, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:53)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.067
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2321 - acc: 0.9433
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0922 - acc: 0.9756
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0748 - acc: 0.9795
MWE identification: 1
Epoch 1/1
 - 16s - loss: 12.0866 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0896 - acc: 0.9779
MWE identification: 2
Epoch 1/1
 - 16s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0626 - acc: 0.9823
MWE identification: 3
Epoch 1/1
 - 16s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0551 - acc: 0.9846
MWE identification: 4
Epoch 1/1
 - 16s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0497 - acc: 0.9861
MWE identification: 5
Epoch 1/1
 - 16s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.87 minutes 
==================================================================================================
	PARSING TIME: 1.95 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (18 h:58)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (18h:58)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.067
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3476 - acc: 0.9007
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1869 - acc: 0.9404
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1600 - acc: 0.9486
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0851 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1696 - acc: 0.9475
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1375 - acc: 0.9552
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1258 - acc: 0.9591
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1169 - acc: 0.9622
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 2.17 minutes 
==================================================================================================
	PARSING TIME: 3.15 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (19 h:4)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:4)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.067
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3012 - acc: 0.9173
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1182 - acc: 0.9647
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0899 - acc: 0.9731
MWE identification: 1
Epoch 1/1
 - 20s - loss: 12.0868 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1052 - acc: 0.9699
MWE identification: 2
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0704 - acc: 0.9793
MWE identification: 3
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0584 - acc: 0.9834
MWE identification: 4
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0500 - acc: 0.9859
MWE identification: 5
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 3.52 minutes 
==================================================================================================
	PARSING TIME: 1.17 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (19 h:9)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
12             ,1              ,50             ,141            ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
13             ,36             ,True           ,62             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.032          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.038          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.021          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 12, 1, 50, 141, 8, 13, 36, True, 62, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.032, False, 20, 0.038, 256, 1, 20, categorical_crossentropy, 0.008, val_acc, adagrad, 4, False, 64, 0.021, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:9)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1825 - acc: 0.9541
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0771 - acc: 0.9786
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0629 - acc: 0.9819
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0817 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0463 - acc: 0.9867
MWE identification: 2
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0349 - acc: 0.9900
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0288 - acc: 0.9918
MWE identification: 4
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0247 - acc: 0.9931
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.25 minutes 
==================================================================================================
	PARSING TIME: 2.47 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.082

==================================================================================================
	XP Ends: 21/9 (19 h:14)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:14)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2940 - acc: 0.9129
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1630 - acc: 0.9472
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1401 - acc: 0.9534
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0757 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1162 - acc: 0.9621
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0934 - acc: 0.9698
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0815 - acc: 0.9742
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0727 - acc: 0.9771
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 3.05 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.036

==================================================================================================
	XP Ends: 21/9 (19 h:19)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:19)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2431 - acc: 0.9308
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0955 - acc: 0.9705
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0723 - acc: 0.9769
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0813 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0483 - acc: 0.9855
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0315 - acc: 0.9911
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0232 - acc: 0.9939
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0181 - acc: 0.9956
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.7 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.002, 0.002

==================================================================================================
	XP Ends: 21/9 (19 h:24)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
12             ,4              ,159            ,115            ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
43             ,96             ,True           ,28             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.029          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.017          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.012          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.055          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 12, 4, 159, 115, 6, 43, 96, True, 28, False, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.029, False, 20, 0.017, 64, 1, 20, categorical_crossentropy, 0.012, val_loss, adagrad, 4, False, 256, 0.055, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1695 - acc: 0.9545
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0736 - acc: 0.9790
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0481 - acc: 0.9863
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0765 - acc: 0.9815
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0401 - acc: 0.9886
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0535 - acc: 0.9870
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0285 - acc: 0.9920
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0488 - acc: 0.9884
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0229 - acc: 0.9935
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0467 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0190 - acc: 0.9946
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0457 - acc: 0.9893
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.83 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.517
	P, R  : 0.55, 0.488

==================================================================================================
	XP Ends: 21/9 (19 h:28)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:28)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2536 - acc: 0.9212
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1271 - acc: 0.9579
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0899 - acc: 0.9709
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0840 - acc: 0.9789
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0755 - acc: 0.9760
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0581 - acc: 0.9857
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0550 - acc: 0.9832
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0522 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0433 - acc: 0.9872
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0495 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0351 - acc: 0.9900
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0482 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.17 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.374
	P, R  : 0.269, 0.613

==================================================================================================
	XP Ends: 21/9 (19 h:32)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:32)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2078 - acc: 0.9389
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0652 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0311 - acc: 0.9911
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0696 - acc: 0.9830
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0233 - acc: 0.9937
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0507 - acc: 0.9878
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0129 - acc: 0.9968
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0473 - acc: 0.9889
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0086 - acc: 0.9981
MWE identification: 4
Epoch 1/1
 - 22s - loss: 0.0462 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0061 - acc: 0.9988
MWE identification: 5
Epoch 1/1
 - 23s - loss: 0.0456 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.3
POS tagging accuracy (MWEs) = 93.3
	TRAINING TIME: 3.68 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.385
	P, R  : 0.435, 0.345

==================================================================================================
	XP Ends: 21/9 (19 h:37)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,2              ,82             ,38             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
25             ,52             ,True           ,126            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.008          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.063          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.007          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 2, 82, 38, 7, 25, 52, True, 126, True, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.008, True, 20, 0.063, 128, 1, 20, categorical_crossentropy, 0.007, val_loss, adagrad, 4, False, 128, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:37)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5305 - acc: 0.8691
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2006 - acc: 0.9491
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1571 - acc: 0.9591
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0852 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1590 - acc: 0.9597
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1267 - acc: 0.9666
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1154 - acc: 0.9696
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1075 - acc: 0.9718
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.35 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.003, 0.007

==================================================================================================
	XP Ends: 21/9 (19 h:41)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:41)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6402 - acc: 0.8285
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2899 - acc: 0.9161
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.2373 - acc: 0.9291
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0812 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.2808 - acc: 0.9221
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.2092 - acc: 0.9360
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1936 - acc: 0.9399
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1830 - acc: 0.9428
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.1748 - acc: 0.9451
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.02 minutes 
==================================================================================================
	PARSING TIME: 2.87 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (19 h:46)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:46)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6064 - acc: 0.8403
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2447 - acc: 0.9321
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1823 - acc: 0.9479
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0841 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.2144 - acc: 0.9445
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1425 - acc: 0.9598
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1237 - acc: 0.9653
MWE identification: 4
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1107 - acc: 0.9694
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 92.7
POS tagging accuracy (MWEs) = 92.7
	TRAINING TIME: 2.88 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (19 h:51)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
12             ,2              ,58             ,69             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
8              ,178            ,True           ,158            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.022          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.007          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.012          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.067          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 12, 2, 58, 69, 12, 8, 178, True, 158, True, False, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.022, True, 20, 0.007, 64, 1, 20, categorical_crossentropy, 0.012, val_loss, adagrad, 4, False, 128, 0.067, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.067
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1735 - acc: 0.9537
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0713 - acc: 0.9797
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0502 - acc: 0.9852
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0827 - acc: 0.9788
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0313 - acc: 0.9908
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0661 - acc: 0.9835
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0217 - acc: 0.9938
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0606 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0172 - acc: 0.9950
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0573 - acc: 0.9861
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0144 - acc: 0.9959
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0550 - acc: 0.9867
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.92 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.461
	P, R  : 0.412, 0.524

==================================================================================================
	XP Ends: 21/9 (19 h:55)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:55)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.067
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2576 - acc: 0.9206
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1238 - acc: 0.9591
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0931 - acc: 0.9693
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0903 - acc: 0.9763
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0589 - acc: 0.9814
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0708 - acc: 0.9822
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0399 - acc: 0.9878
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0646 - acc: 0.9840
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0296 - acc: 0.9913
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0609 - acc: 0.9851
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0229 - acc: 0.9938
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0583 - acc: 0.9858
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.37 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.378
	P, R  : 0.279, 0.586

==================================================================================================
	XP Ends: 21/9 (19 h:59)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (19h:59)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.067
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2098 - acc: 0.9388
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0611 - acc: 0.9810
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0315 - acc: 0.9905
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0734 - acc: 0.9818
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0148 - acc: 0.9961
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0584 - acc: 0.9855
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0077 - acc: 0.9982
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0536 - acc: 0.9870
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0047 - acc: 0.9991
MWE identification: 4
Epoch 1/1
 - 21s - loss: 0.0511 - acc: 0.9878
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0032 - acc: 0.9994
MWE identification: 5
Epoch 1/1
 - 21s - loss: 0.0493 - acc: 0.9883
Should stop early?
Early stopping applied
POS tagging accuracy = 93.2
POS tagging accuracy (MWEs) = 93.2
	TRAINING TIME: 3.72 minutes 
==================================================================================================
	PARSING TIME: 0.67 minutes 
==================================================================================================
	Identification : 0.361
	P, R  : 0.433, 0.31

==================================================================================================
	XP Ends: 21/9 (20 h:4)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
23             ,1              ,170            ,77             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,117            ,True           ,105            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.013          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.009          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.011          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.011          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 23, 1, 170, 77, 5, 5, 117, True, 105, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.013, True, 20, 0.009, 256, 2, 20, categorical_crossentropy, 0.011, val_acc, adagrad, 4, False, 128, 0.011, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:4)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2833 - acc: 0.9315
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1046 - acc: 0.9734
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0842 - acc: 0.9773
MWE identification: 1
Epoch 1/1
 - 4s - loss: 0.1105 - acc: 0.9753
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0741 - acc: 0.9794
MWE identification: 2
Epoch 1/1
 - 4s - loss: 0.0637 - acc: 0.9843
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0637 - acc: 0.9818
MWE identification: 3
Epoch 1/1
 - 4s - loss: 0.0574 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0571 - acc: 0.9838
MWE identification: 4
Epoch 1/1
 - 4s - loss: 0.0544 - acc: 0.9869
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0522 - acc: 0.9853
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0525 - acc: 0.9875
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0481 - acc: 0.9866
MWE identification: 6
Epoch 1/1
 - 4s - loss: 0.0512 - acc: 0.9879
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.15 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.587
	P, R  : 0.816, 0.458

==================================================================================================
	XP Ends: 21/9 (20 h:8)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:8)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4005 - acc: 0.8884
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2055 - acc: 0.9361
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1754 - acc: 0.9438
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1402 - acc: 0.9688
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1589 - acc: 0.9490
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0691 - acc: 0.9828
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1418 - acc: 0.9543
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0617 - acc: 0.9849
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1310 - acc: 0.9578
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0577 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1226 - acc: 0.9604
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0551 - acc: 0.9866
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.1156 - acc: 0.9627
MWE identification: 6
Epoch 1/1
 - 3s - loss: 0.0533 - acc: 0.9872
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.77 minutes 
==================================================================================================
	PARSING TIME: 1.85 minutes 
==================================================================================================
	Identification : 0.605
	P, R  : 0.871, 0.463

==================================================================================================
	XP Ends: 21/9 (20 h:12)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:12)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3549 - acc: 0.9052
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1374 - acc: 0.9593
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1041 - acc: 0.9690
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0944 - acc: 0.9780
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0884 - acc: 0.9741
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0594 - acc: 0.9851
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0704 - acc: 0.9796
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0545 - acc: 0.9865
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0596 - acc: 0.9829
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0519 - acc: 0.9874
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0517 - acc: 0.9854
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0502 - acc: 0.9880
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0455 - acc: 0.9875
MWE identification: 6
Epoch 1/1
 - 6s - loss: 0.0489 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.6 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.426
	P, R  : 0.661, 0.314

==================================================================================================
	XP Ends: 21/9 (20 h:15)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,6              ,28             ,43             ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
21             ,42             ,True           ,48             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.005          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.019          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.031          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.061          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 6, 28, 43, 11, 21, 42, True, 48, True, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.005, False, 20, 0.019, 256, 1, 20, categorical_crossentropy, 0.031, val_loss, adagrad, 4, False, 96, 0.061, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:15)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1437 - acc: 0.9623
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0531 - acc: 0.9841
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0404 - acc: 0.9875
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0936 - acc: 0.9792
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0259 - acc: 0.9919
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0575 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0159 - acc: 0.9950
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0519 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0116 - acc: 0.9964
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0490 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0092 - acc: 0.9972
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0473 - acc: 0.9888
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.535
	P, R  : 0.626, 0.467

==================================================================================================
	XP Ends: 21/9 (20 h:19)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:19)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2488 - acc: 0.9233
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1224 - acc: 0.9588
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1001 - acc: 0.9657
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1153 - acc: 0.9748
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0681 - acc: 0.9777
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0642 - acc: 0.9842
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0466 - acc: 0.9852
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0558 - acc: 0.9865
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0349 - acc: 0.9895
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0523 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0274 - acc: 0.9920
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0504 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.75 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.547
	P, R  : 0.596, 0.505

==================================================================================================
	XP Ends: 21/9 (20 h:22)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:22)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1933 - acc: 0.9437
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0626 - acc: 0.9793
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0419 - acc: 0.9861
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0886 - acc: 0.9800
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0228 - acc: 0.9931
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0561 - acc: 0.9858
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0105 - acc: 0.9972
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0510 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0057 - acc: 0.9988
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0485 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0036 - acc: 0.9993
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0471 - acc: 0.9888
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.473
	P, R  : 0.641, 0.375

==================================================================================================
	XP Ends: 21/9 (20 h:26)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
13             ,6              ,49             ,52             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
15             ,83             ,True           ,75             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.005          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.033          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.009          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 13, 6, 49, 52, 7, 15, 83, True, 75, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.005, False, 20, 0.008, 256, 1, 20, categorical_crossentropy, 0.033, val_loss, adagrad, 4, False, 128, 0.009, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:26)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3404 - acc: 0.9175
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1174 - acc: 0.9710
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0933 - acc: 0.9754
MWE identification: 1
Epoch 1/1
 - 4s - loss: 0.1026 - acc: 0.9756
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0820 - acc: 0.9776
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0626 - acc: 0.9845
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0713 - acc: 0.9800
MWE identification: 3
Epoch 1/1
 - 4s - loss: 0.0570 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0648 - acc: 0.9817
MWE identification: 4
Epoch 1/1
 - 4s - loss: 0.0541 - acc: 0.9869
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0599 - acc: 0.9829
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0523 - acc: 0.9874
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.03 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.581
	P, R  : 0.781, 0.463

==================================================================================================
	XP Ends: 21/9 (20 h:29)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:29)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4607 - acc: 0.8733
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2251 - acc: 0.9318
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1904 - acc: 0.9398
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1373 - acc: 0.9678
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1723 - acc: 0.9451
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0704 - acc: 0.9824
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1555 - acc: 0.9502
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0632 - acc: 0.9845
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1450 - acc: 0.9534
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0593 - acc: 0.9853
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1369 - acc: 0.9559
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0567 - acc: 0.9861
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.72 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.624
	P, R  : 0.901, 0.477

==================================================================================================
	XP Ends: 21/9 (20 h:33)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:33)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4136 - acc: 0.8914
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1581 - acc: 0.9540
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1192 - acc: 0.9650
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0947 - acc: 0.9779
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1022 - acc: 0.9704
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0599 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0834 - acc: 0.9757
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0551 - acc: 0.9863
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0724 - acc: 0.9792
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0525 - acc: 0.9872
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0643 - acc: 0.9819
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0507 - acc: 0.9878
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.47 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.444
	P, R  : 0.652, 0.337

==================================================================================================
	XP Ends: 21/9 (20 h:37)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
13             ,2              ,32             ,56             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
35             ,151            ,True           ,42             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.035          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.041          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.011          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.012          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 13, 2, 32, 56, 5, 35, 151, True, 42, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.035, True, 20, 0.041, 128, 1, 20, categorical_crossentropy, 0.011, val_loss, adagrad, 4, False, 64, 0.012, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:37)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2641 - acc: 0.9359
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1000 - acc: 0.9743
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0802 - acc: 0.9781
MWE identification: 1
Epoch 1/1
 - 8s - loss: 7.1898 - acc: 0.5503
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1339 - acc: 0.9679
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0839 - acc: 0.9832
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0839 - acc: 0.9782
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0516 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0692 - acc: 0.9812
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0478 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0608 - acc: 0.9833
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0464 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 1.05 minutes 
==================================================================================================
	Identification : 0.594
	P, R  : 0.738, 0.497

==================================================================================================
	XP Ends: 21/9 (20 h:41)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:41)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3791 - acc: 0.8933
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1986 - acc: 0.9376
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1691 - acc: 0.9453
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0825 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1557 - acc: 0.9509
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1298 - acc: 0.9580
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1185 - acc: 0.9616
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1098 - acc: 0.9645
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.1028 - acc: 0.9670
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 2.32 minutes 
==================================================================================================
	PARSING TIME: 2.83 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (20 h:46)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:46)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3356 - acc: 0.9096
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1296 - acc: 0.9618
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0976 - acc: 0.9701
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.3911 - acc: 0.9622
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1575 - acc: 0.9574
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0607 - acc: 0.9866
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0991 - acc: 0.9726
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0483 - acc: 0.9885
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0761 - acc: 0.9784
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0467 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0646 - acc: 0.9815
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0459 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 3.17 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.468
	P, R  : 0.621, 0.376

==================================================================================================
	XP Ends: 21/9 (20 h:50)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,3              ,92             ,65             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
20             ,110            ,True           ,62             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.018          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.033          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.02           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.041          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 3, 92, 65, 6, 20, 110, True, 62, False, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.018, True, 20, 0.033, 128, 1, 20, categorical_crossentropy, 0.02, val_loss, adagrad, 4, False, 64, 0.041, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:50)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.033
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1469 - acc: 0.9617
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0592 - acc: 0.9828
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0480 - acc: 0.9853
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0857 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0289 - acc: 0.9911
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0189 - acc: 0.9941
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0143 - acc: 0.9955
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0116 - acc: 0.9965
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.53 minutes 
==================================================================================================
	PARSING TIME: 2.6 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.109

==================================================================================================
	XP Ends: 21/9 (20 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (20h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.033
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2497 - acc: 0.9230
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1323 - acc: 0.9559
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1131 - acc: 0.9616
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1095 - acc: 0.9776
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0930 - acc: 0.9694
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0615 - acc: 0.9857
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0660 - acc: 0.9790
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0514 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0514 - acc: 0.9843
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0489 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0417 - acc: 0.9874
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0478 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.568
	P, R  : 0.608, 0.533

==================================================================================================
	XP Ends: 21/9 (21 h:0)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:0)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.033
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1944 - acc: 0.9425
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0701 - acc: 0.9773
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0512 - acc: 0.9830
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0785 - acc: 0.9817
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0380 - acc: 0.9883
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0540 - acc: 0.9867
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0183 - acc: 0.9950
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0481 - acc: 0.9884
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0107 - acc: 0.9974
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0464 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0070 - acc: 0.9985
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0457 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 3.1 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.458
	P, R  : 0.58, 0.378

==================================================================================================
	XP Ends: 21/9 (21 h:4)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,1              ,42             ,185            ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
41             ,193            ,True           ,52             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.051          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.009          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 1, 42, 185, 9, 41, 193, True, 52, True, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.006, True, 20, 0.051, 256, 2, 20, categorical_crossentropy, 0.009, val_loss, adagrad, 4, False, 256, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:4)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1239 - acc: 0.9699
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1111 - acc: 0.9747
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.9833 - acc: 0.7782
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0686 - acc: 0.9857
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.3181 - acc: 0.9362
MWE identification: 3
Epoch 1/1
 - 4s - loss: 0.0588 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.2161 - acc: 0.9566
MWE identification: 4
Epoch 1/1
 - 4s - loss: 0.0482 - acc: 0.9888
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1600 - acc: 0.9648
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0466 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 95.1
POS tagging accuracy (MWEs) = 95.1
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.59
	P, R  : 0.708, 0.506

==================================================================================================
	XP Ends: 21/9 (21 h:7)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:7)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.2349 - acc: 0.9303
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.8021 - acc: 0.9295
POS tagging: 4
Epoch 1/1
 - 2s - loss: 1.1138 - acc: 0.7118
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0993 - acc: 0.9830
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.5743 - acc: 0.8559
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0689 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.3934 - acc: 0.9006
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0521 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.2999 - acc: 0.9183
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0493 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 91.4
POS tagging accuracy (MWEs) = 91.4
	TRAINING TIME: 1.6 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.584
	P, R  : 0.691, 0.506

==================================================================================================
	XP Ends: 21/9 (21 h:11)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:11)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1650 - acc: 0.9527
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0992 - acc: 0.9766
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.9299 - acc: 0.7714
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0748 - acc: 0.9856
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.3879 - acc: 0.9082
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0578 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.2644 - acc: 0.9360
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0479 - acc: 0.9888
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.2131 - acc: 0.9453
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0469 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 89.9
POS tagging accuracy (MWEs) = 89.9
	TRAINING TIME: 2.33 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.485
	P, R  : 0.512, 0.461

==================================================================================================
	XP Ends: 21/9 (21 h:14)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,2              ,67             ,125            ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,25             ,True           ,28             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.006          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.069          ,64             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.007          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.007          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 2, 67, 125, 13, 5, 25, True, 28, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.006, False, 20, 0.069, 64, 2, 20, categorical_crossentropy, 0.007, val_loss, adagrad, 4, False, 64, 0.007, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:14)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.069
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4404 - acc: 0.8938
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1397 - acc: 0.9666
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1044 - acc: 0.9733
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0864 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1149 - acc: 0.9724
MWE identification: 2
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0822 - acc: 0.9778
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0740 - acc: 0.9796
MWE identification: 4
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0685 - acc: 0.9809
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 3.07 minutes 
==================================================================================================
	PARSING TIME: 1.85 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (21 h:19)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:19)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.069
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5602 - acc: 0.8488
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2567 - acc: 0.9246
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.2079 - acc: 0.9354
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.4575 - acc: 0.9526
POS tagging: 4
Epoch 1/1
 - 6s - loss: 1.3042 - acc: 0.6348
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0635 - acc: 0.9851
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.7355 - acc: 0.7937
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0531 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.4581 - acc: 0.8778
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0500 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.3360 - acc: 0.9097
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0479 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 89.5
POS tagging accuracy (MWEs) = 89.5
	TRAINING TIME: 2.47 minutes 
==================================================================================================
	PARSING TIME: 1.77 minutes 
==================================================================================================
	Identification : 0.488
	P, R  : 0.459, 0.521

==================================================================================================
	XP Ends: 21/9 (21 h:24)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:24)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.069
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5174 - acc: 0.8655
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1913 - acc: 0.9468
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1372 - acc: 0.9598
MWE identification: 1
Epoch 1/1
 - 20s - loss: 12.0870 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1537 - acc: 0.9571
MWE identification: 2
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1021 - acc: 0.9702
MWE identification: 3
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0885 - acc: 0.9741
MWE identification: 4
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0794 - acc: 0.9771
MWE identification: 5
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.85 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (21 h:29)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,155            ,79             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
8              ,35             ,True           ,112            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.019          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.01           ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.094          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 155, 79, 8, 8, 35, True, 112, True, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.019, True, 20, 0.01, 128, 1, 20, categorical_crossentropy, 0.094, val_loss, adagrad, 4, False, 64, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:29)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1144 - acc: 0.9712
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0913 - acc: 0.9783
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0990 - acc: 0.9745
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0597 - acc: 0.9855
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0861 - acc: 0.9771
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0544 - acc: 0.9868
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0788 - acc: 0.9785
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0518 - acc: 0.9876
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0738 - acc: 0.9797
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0502 - acc: 0.9880
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.797, 0.463

==================================================================================================
	XP Ends: 21/9 (21 h:33)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:33)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.2225 - acc: 0.9322
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1200 - acc: 0.9722
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.2030 - acc: 0.9372
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0650 - acc: 0.9840
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1822 - acc: 0.9429
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0584 - acc: 0.9857
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1705 - acc: 0.9462
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0550 - acc: 0.9867
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1621 - acc: 0.9485
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0527 - acc: 0.9874
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.07 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.62
	P, R  : 0.877, 0.479

==================================================================================================
	XP Ends: 21/9 (21 h:37)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:37)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1522 - acc: 0.9554
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0817 - acc: 0.9801
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1303 - acc: 0.9632
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0560 - acc: 0.9858
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1072 - acc: 0.9692
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0517 - acc: 0.9873
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0952 - acc: 0.9724
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0495 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0867 - acc: 0.9749
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0480 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.07 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.447
	P, R  : 0.628, 0.347

==================================================================================================
	XP Ends: 21/9 (21 h:41)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
13             ,7              ,138            ,45             ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,49             ,True           ,67             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.012          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.083          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.092          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.052          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 13, 7, 138, 45, 11, 5, 49, True, 67, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.012, False, 20, 0.083, 128, 2, 20, categorical_crossentropy, 0.092, val_loss, adagrad, 4, False, 256, 0.052, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:41)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.052
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.083
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1407 - acc: 0.9629
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0548 - acc: 0.9836
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0364 - acc: 0.9890
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0852 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0334 - acc: 0.9900
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0212 - acc: 0.9936
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0162 - acc: 0.9951
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0131 - acc: 0.9960
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.22 minutes 
==================================================================================================
	PARSING TIME: 1.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (21 h:46)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:46)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.052
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.083
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2476 - acc: 0.9239
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1255 - acc: 0.9578
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0922 - acc: 0.9697
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0822 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0931 - acc: 0.9693
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0618 - acc: 0.9805
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0490 - acc: 0.9851
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0403 - acc: 0.9882
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0339 - acc: 0.9904
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.88 minutes 
==================================================================================================
	PARSING TIME: 2.77 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (21 h:51)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:51)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.052
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.083
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1914 - acc: 0.9439
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0652 - acc: 0.9786
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0367 - acc: 0.9886
MWE identification: 1
Epoch 1/1
 - 11s - loss: 10.7424 - acc: 0.3307
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0810 - acc: 0.9749
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0662 - acc: 0.9834
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0472 - acc: 0.9856
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0502 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0240 - acc: 0.9933
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0471 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0152 - acc: 0.9962
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0459 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 2.73 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.518
	P, R  : 0.559, 0.482

==================================================================================================
	XP Ends: 21/9 (21 h:54)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,4              ,59             ,64             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
43             ,78             ,True           ,139            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.027          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.007          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.009          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.024          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 4, 59, 64, 12, 43, 78, True, 139, True, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.027, True, 20, 0.007, 96, 2, 20, categorical_crossentropy, 0.009, val_loss, adagrad, 4, False, 256, 0.024, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:54)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.024
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2020 - acc: 0.9471
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0983 - acc: 0.9734
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0755 - acc: 0.9796
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0908 - acc: 0.9764
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0641 - acc: 0.9826
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0653 - acc: 0.9840
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0522 - acc: 0.9860
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0591 - acc: 0.9857
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0446 - acc: 0.9881
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0555 - acc: 0.9867
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0389 - acc: 0.9895
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0531 - acc: 0.9874
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.38 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.5
	P, R  : 0.492, 0.509

==================================================================================================
	XP Ends: 21/9 (21 h:58)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (21h:58)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.024
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2910 - acc: 0.9125
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1627 - acc: 0.9475
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1323 - acc: 0.9574
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1012 - acc: 0.9734
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1161 - acc: 0.9631
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0692 - acc: 0.9826
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0985 - acc: 0.9690
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0626 - acc: 0.9846
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0863 - acc: 0.9736
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0589 - acc: 0.9856
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0767 - acc: 0.9768
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0562 - acc: 0.9863
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.88 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.341
	P, R  : 0.238, 0.602

==================================================================================================
	XP Ends: 21/9 (22 h:2)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:2)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.024
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2495 - acc: 0.9281
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0982 - acc: 0.9711
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0624 - acc: 0.9829
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0781 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0465 - acc: 0.9877
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0569 - acc: 0.9863
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0325 - acc: 0.9917
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0520 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0250 - acc: 0.9940
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0496 - acc: 0.9883
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0202 - acc: 0.9953
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0482 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 3.0 minutes 
==================================================================================================
	PARSING TIME: 0.67 minutes 
==================================================================================================
	Identification : 0.374
	P, R  : 0.447, 0.322

==================================================================================================
	XP Ends: 21/9 (22 h:6)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
14             ,3              ,113            ,84             ,14             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
30             ,93             ,True           ,35             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.008          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.061          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.036          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.015          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 14, 3, 113, 84, 14, 30, 93, True, 35, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.008, True, 20, 0.061, 256, 2, 20, categorical_crossentropy, 0.036, val_loss, adagrad, 4, False, 128, 0.015, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:6)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2225 - acc: 0.9456
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0901 - acc: 0.9760
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0727 - acc: 0.9798
MWE identification: 1
Epoch 1/1
 - 4s - loss: 0.2337 - acc: 0.9689
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.3795 - acc: 0.9081
MWE identification: 2
Epoch 1/1
 - 4s - loss: 12.0863 - acc: 0.2501
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0966 - acc: 0.9751
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0776 - acc: 0.9792
MWE identification: 4
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0688 - acc: 0.9811
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0627 - acc: 0.9827
MWE identification: 6
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.15 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.018, 0.001

==================================================================================================
	XP Ends: 21/9 (22 h:10)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:10)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3363 - acc: 0.9032
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1823 - acc: 0.9417
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1558 - acc: 0.9494
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0740 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1638 - acc: 0.9499
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1260 - acc: 0.9590
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1131 - acc: 0.9633
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1036 - acc: 0.9665
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0961 - acc: 0.9695
MWE identification: 6
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 1.8 minutes 
==================================================================================================
	PARSING TIME: 2.78 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (22 h:15)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:15)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2889 - acc: 0.9203
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1134 - acc: 0.9659
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0857 - acc: 0.9737
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0828 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0923 - acc: 0.9742
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0566 - acc: 0.9833
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0451 - acc: 0.9873
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0374 - acc: 0.9897
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.48 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (22 h:19)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,7              ,182            ,166            ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
13             ,120            ,True           ,25             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.037          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.021          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.011          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.063          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 7, 182, 166, 5, 13, 120, True, 25, True, False, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.037, True, 20, 0.021, 64, 1, 20, categorical_crossentropy, 0.011, val_loss, adagrad, 4, False, 64, 0.063, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:19)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1457 - acc: 0.9618
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0531 - acc: 0.9842
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0436 - acc: 0.9864
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0746 - acc: 0.9819
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0267 - acc: 0.9917
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0545 - acc: 0.9865
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0159 - acc: 0.9950
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0497 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0116 - acc: 0.9963
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0473 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0092 - acc: 0.9971
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0460 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 3.08 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.563
	P, R  : 0.715, 0.464

==================================================================================================
	XP Ends: 21/9 (22 h:24)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:24)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2488 - acc: 0.9233
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1218 - acc: 0.9589
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1046 - acc: 0.9642
MWE identification: 1
Epoch 1/1
 - 9s - loss: 0.0818 - acc: 0.9794
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0678 - acc: 0.9778
MWE identification: 2
Epoch 1/1
 - 9s - loss: 0.0583 - acc: 0.9852
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0448 - acc: 0.9859
MWE identification: 3
Epoch 1/1
 - 9s - loss: 0.0522 - acc: 0.9873
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0330 - acc: 0.9900
MWE identification: 4
Epoch 1/1
 - 9s - loss: 0.0495 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0253 - acc: 0.9926
MWE identification: 5
Epoch 1/1
 - 9s - loss: 0.0481 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.42 minutes 
==================================================================================================
	PARSING TIME: 1.63 minutes 
==================================================================================================
	Identification : 0.524
	P, R  : 0.494, 0.559

==================================================================================================
	XP Ends: 21/9 (22 h:28)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:28)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1944 - acc: 0.9433
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0625 - acc: 0.9795
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0459 - acc: 0.9845
MWE identification: 1
Epoch 1/1
 - 19s - loss: 0.0686 - acc: 0.9824
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0230 - acc: 0.9928
MWE identification: 2
Epoch 1/1
 - 19s - loss: 0.0531 - acc: 0.9864
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0099 - acc: 0.9973
MWE identification: 3
Epoch 1/1
 - 19s - loss: 0.0488 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0053 - acc: 0.9989
MWE identification: 4
Epoch 1/1
 - 19s - loss: 0.0469 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0032 - acc: 0.9994
MWE identification: 5
Epoch 1/1
 - 19s - loss: 0.0459 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.75 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.45
	P, R  : 0.602, 0.359

==================================================================================================
	XP Ends: 21/9 (22 h:33)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
17             ,7              ,170            ,31             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
17             ,79             ,True           ,111            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.009          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.053          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.008          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.043          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 17, 7, 170, 31, 6, 17, 79, True, 111, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.009, True, 20, 0.053, 96, 2, 20, categorical_crossentropy, 0.008, val_loss, adagrad, 4, False, 96, 0.043, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:33)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1456 - acc: 0.9619
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0577 - acc: 0.9830
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0448 - acc: 0.9862
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0919 - acc: 0.9810
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0556 - acc: 0.9842
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0562 - acc: 0.9870
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0329 - acc: 0.9908
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0480 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0225 - acc: 0.9935
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0459 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0171 - acc: 0.9950
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0451 - acc: 0.9894
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.63 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.582
	P, R  : 0.774, 0.466

==================================================================================================
	XP Ends: 21/9 (22 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:37)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2492 - acc: 0.9230
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1308 - acc: 0.9562
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1080 - acc: 0.9634
MWE identification: 1
Epoch 1/1
 - 7s - loss: 12.0791 - acc: 0.2502
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0839 - acc: 0.9729
MWE identification: 2
Epoch 1/1
 - 7s - loss: 12.0885 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0569 - acc: 0.9819
MWE identification: 3
Epoch 1/1
 - 7s - loss: 12.0885 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0446 - acc: 0.9864
MWE identification: 4
Epoch 1/1
 - 7s - loss: 12.0885 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0366 - acc: 0.9892
MWE identification: 5
Epoch 1/1
 - 7s - loss: 12.0885 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0307 - acc: 0.9912
MWE identification: 6
Epoch 1/1
 - 7s - loss: 12.0885 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.28 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (22 h:42)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:43)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1939 - acc: 0.9433
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0688 - acc: 0.9776
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0468 - acc: 0.9849
MWE identification: 1
Epoch 1/1
 - 14s - loss: 12.0865 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0254 - acc: 0.9922
MWE identification: 2
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0127 - acc: 0.9966
MWE identification: 3
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0075 - acc: 0.9983
MWE identification: 4
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0050 - acc: 0.9990
MWE identification: 5
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.2 minutes 
==================================================================================================
	PARSING TIME: 1.27 minutes 
==================================================================================================
	Identification : 0.009
	P, R  : 0.005, 0.043

==================================================================================================
	XP Ends: 21/9 (22 h:47)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,1              ,61             ,27             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,34             ,True           ,132            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.078          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.013          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.062          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 1, 61, 27, 7, 7, 34, True, 132, False, False, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.006, True, 20, 0.078, 64, 1, 20, categorical_crossentropy, 0.013, val_loss, adagrad, 4, False, 256, 0.062, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.078
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1449 - acc: 0.9619
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0530 - acc: 0.9842
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0342 - acc: 0.9897
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0869 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0294 - acc: 0.9912
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0189 - acc: 0.9944
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0143 - acc: 0.9956
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0115 - acc: 0.9965
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.82 minutes 
==================================================================================================
	PARSING TIME: 1.87 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (22 h:52)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:52)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.078
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2488 - acc: 0.9234
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1219 - acc: 0.9591
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0875 - acc: 0.9710
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0857 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0814 - acc: 0.9734
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0546 - acc: 0.9830
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0424 - acc: 0.9873
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0342 - acc: 0.9900
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.18 minutes 
==================================================================================================
	PARSING TIME: 2.6 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (22 h:57)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (22h:57)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.078
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1933 - acc: 0.9436
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0622 - acc: 0.9795
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0330 - acc: 0.9896
MWE identification: 1
Epoch 1/1
 - 20s - loss: 12.0873 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0259 - acc: 0.9922
MWE identification: 2
Epoch 1/1
 - 19s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0128 - acc: 0.9966
MWE identification: 3
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0075 - acc: 0.9984
MWE identification: 4
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0050 - acc: 0.9991
MWE identification: 5
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.58 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (23 h:3)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,8              ,162            ,29             ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,111            ,True           ,154            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.006          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.01           ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.086          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.089          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 8, 162, 29, 11, 6, 111, True, 154, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.006, False, 20, 0.01, 96, 1, 20, categorical_crossentropy, 0.086, val_loss, adagrad, 4, False, 64, 0.089, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:3)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.089
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1628 - acc: 0.9590
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0541 - acc: 0.9839
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0464 - acc: 0.9858
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0798 - acc: 0.9797
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0245 - acc: 0.9924
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0636 - acc: 0.9839
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0151 - acc: 0.9954
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0586 - acc: 0.9853
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0112 - acc: 0.9964
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0555 - acc: 0.9863
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0090 - acc: 0.9971
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0533 - acc: 0.9869
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.73 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.564
	P, R  : 0.72, 0.464

==================================================================================================
	XP Ends: 21/9 (23 h:7)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:7)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.089
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2653 - acc: 0.9218
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1191 - acc: 0.9590
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1045 - acc: 0.9638
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0920 - acc: 0.9761
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0589 - acc: 0.9803
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0702 - acc: 0.9823
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0380 - acc: 0.9878
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0640 - acc: 0.9838
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0271 - acc: 0.9918
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0604 - acc: 0.9848
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0203 - acc: 0.9941
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0578 - acc: 0.9856
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.23 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.541
	P, R  : 0.537, 0.546

==================================================================================================
	XP Ends: 21/9 (23 h:11)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:11)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.089
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2021 - acc: 0.9427
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0599 - acc: 0.9803
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0457 - acc: 0.9849
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0749 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 7s - loss: 0.0180 - acc: 0.9944
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0609 - acc: 0.9842
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0079 - acc: 0.9981
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0564 - acc: 0.9855
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0044 - acc: 0.9992
MWE identification: 4
Epoch 1/1
 - 13s - loss: 0.0538 - acc: 0.9863
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0030 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0518 - acc: 0.9871
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.37 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.476
	P, R  : 0.638, 0.38

==================================================================================================
	XP Ends: 21/9 (23 h:15)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
20             ,3              ,61             ,43             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
11             ,188            ,True           ,27             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.014          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.069          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.007          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.087          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 20, 3, 61, 43, 6, 11, 188, True, 27, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.014, True, 20, 0.069, 96, 2, 20, categorical_crossentropy, 0.007, val_loss, adagrad, 4, False, 96, 0.087, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:15)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.087
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.069
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1892 - acc: 0.9527
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0715 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0530 - acc: 0.9845
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0861 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0335 - acc: 0.9904
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0206 - acc: 0.9941
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0159 - acc: 0.9954
MWE identification: 4
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0132 - acc: 0.9961
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.62 minutes 
==================================================================================================
	PARSING TIME: 1.87 minutes 
==================================================================================================
	Identification : 0.031
	P, R  : 0.02, 0.067

==================================================================================================
	XP Ends: 21/9 (23 h:20)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:20)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.087
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.069
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2713 - acc: 0.9190
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1232 - acc: 0.9594
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0976 - acc: 0.9674
MWE identification: 1
Epoch 1/1
 - 7s - loss: 1.2356 - acc: 0.9079
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0971 - acc: 0.9682
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0565 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0544 - acc: 0.9829
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0492 - acc: 0.9882
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0364 - acc: 0.9891
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0475 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0264 - acc: 0.9926
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0469 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 2.07 minutes 
==================================================================================================
	PARSING TIME: 1.63 minutes 
==================================================================================================
	Identification : 0.434
	P, R  : 0.342, 0.593

==================================================================================================
	XP Ends: 21/9 (23 h:24)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:24)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.087
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.069
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9385
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0587 - acc: 0.9817
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.0329 - acc: 0.9899
MWE identification: 1
Epoch 1/1
 - 14s - loss: 12.0866 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0161 - acc: 0.9956
MWE identification: 2
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0067 - acc: 0.9985
MWE identification: 3
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0040 - acc: 0.9993
MWE identification: 4
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0028 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 3.2 minutes 
==================================================================================================
	PARSING TIME: 1.22 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 21/9 (23 h:29)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,8              ,74             ,95             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
11             ,74             ,True           ,37             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.008          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.057          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.007          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 8, 74, 95, 7, 11, 74, True, 37, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.008, True, 20, 0.008, 128, 2, 20, categorical_crossentropy, 0.057, val_loss, adagrad, 4, False, 96, 0.007, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:29)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4404 - acc: 0.8938
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1397 - acc: 0.9666
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1062 - acc: 0.9730
MWE identification: 1
Epoch 1/1
 - 9s - loss: 0.0921 - acc: 0.9777
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0917 - acc: 0.9757
MWE identification: 2
Epoch 1/1
 - 9s - loss: 0.0614 - acc: 0.9850
POS tagging: 5
Epoch 1/1
 - 5s - loss: 0.0800 - acc: 0.9782
MWE identification: 3
Epoch 1/1
 - 9s - loss: 0.0560 - acc: 0.9863
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0732 - acc: 0.9797
MWE identification: 4
Epoch 1/1
 - 9s - loss: 0.0533 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0683 - acc: 0.9808
MWE identification: 5
Epoch 1/1
 - 9s - loss: 0.0516 - acc: 0.9876
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.47 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.588
	P, R  : 0.789, 0.469

==================================================================================================
	XP Ends: 21/9 (23 h:33)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:33)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5602 - acc: 0.8488
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2567 - acc: 0.9246
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.2103 - acc: 0.9349
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1169 - acc: 0.9714
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1903 - acc: 0.9404
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0681 - acc: 0.9831
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1715 - acc: 0.9457
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0614 - acc: 0.9849
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1605 - acc: 0.9490
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0577 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1523 - acc: 0.9512
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0552 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 1.83 minutes 
==================================================================================================
	Identification : 0.619
	P, R  : 0.883, 0.476

==================================================================================================
	XP Ends: 21/9 (23 h:37)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:37)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5174 - acc: 0.8655
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1913 - acc: 0.9468
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1398 - acc: 0.9591
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0825 - acc: 0.9797
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1177 - acc: 0.9662
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0575 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0971 - acc: 0.9715
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0532 - acc: 0.9867
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0857 - acc: 0.9751
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0509 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0775 - acc: 0.9777
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0493 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.92 minutes 
==================================================================================================
	PARSING TIME: 0.77 minutes 
==================================================================================================
	Identification : 0.453
	P, R  : 0.632, 0.353

==================================================================================================
	XP Ends: 21/9 (23 h:41)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,1              ,260            ,33             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
31             ,82             ,True           ,169            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.02           ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.091          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.038          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 1, 260, 33, 5, 31, 82, True, 169, True, False, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.006, True, 20, 0.02, 96, 2, 20, categorical_crossentropy, 0.091, val_acc, adagrad, 4, False, 128, 0.038, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:41)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1771 - acc: 0.9525
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0817 - acc: 0.9771
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0603 - acc: 0.9827
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0854 - acc: 0.9808
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0473 - acc: 0.9866
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0542 - acc: 0.9870
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0332 - acc: 0.9906
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0482 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0263 - acc: 0.9925
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0462 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0220 - acc: 0.9938
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0454 - acc: 0.9894
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0191 - acc: 0.9947
MWE identification: 6
Epoch 1/1
 - 10s - loss: 0.0450 - acc: 0.9894
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.82 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.504
	P, R  : 0.504, 0.504

==================================================================================================
	XP Ends: 21/9 (23 h:45)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:45)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2589 - acc: 0.9200
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1396 - acc: 0.9543
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1113 - acc: 0.9635
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0938 - acc: 0.9783
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0900 - acc: 0.9717
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0574 - acc: 0.9861
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0659 - acc: 0.9799
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0512 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0527 - acc: 0.9842
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0490 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0438 - acc: 0.9872
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0479 - acc: 0.9886
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0373 - acc: 0.9893
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0474 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.17 minutes 
==================================================================================================
	PARSING TIME: 1.62 minutes 
==================================================================================================
	Identification : 0.402
	P, R  : 0.297, 0.624

==================================================================================================
	XP Ends: 21/9 (23 h:49)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:49)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2135 - acc: 0.9367
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0761 - acc: 0.9771
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0439 - acc: 0.9871
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0814 - acc: 0.9823
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0310 - acc: 0.9915
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0513 - acc: 0.9880
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0166 - acc: 0.9958
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0471 - acc: 0.9890
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0109 - acc: 0.9975
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0462 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0079 - acc: 0.9984
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0456 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.8
POS tagging accuracy (MWEs) = 92.8
	TRAINING TIME: 3.23 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.408
	P, R  : 0.422, 0.394

==================================================================================================
	XP Ends: 21/9 (23 h:54)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,1              ,78             ,138            ,14             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
26             ,157            ,True           ,54             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.013          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.017          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.1            ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.029          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 1, 78, 138, 14, 26, 157, True, 54, True, False, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.013, True, 20, 0.017, 256, 2, 20, categorical_crossentropy, 0.1, val_loss, adagrad, 4, False, 256, 0.029, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:54)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1927 - acc: 0.9491
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0916 - acc: 0.9749
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0680 - acc: 0.9814
MWE identification: 1
Epoch 1/1
 - 5s - loss: 1.7038 - acc: 0.8799
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0609 - acc: 0.9834
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0645 - acc: 0.9853
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0479 - acc: 0.9869
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0527 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0399 - acc: 0.9891
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0496 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0343 - acc: 0.9907
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0480 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 1.95 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.493
	P, R  : 0.47, 0.519

==================================================================================================
	XP Ends: 21/9 (23 h:57)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 21/9 (23h:57)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2789 - acc: 0.9157
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1536 - acc: 0.9504
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1217 - acc: 0.9606
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1298 - acc: 0.9727
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1117 - acc: 0.9645
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0715 - acc: 0.9840
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0907 - acc: 0.9718
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0548 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0773 - acc: 0.9767
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0515 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0674 - acc: 0.9799
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0497 - acc: 0.9883
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 1.58 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.412
	P, R  : 0.324, 0.566

==================================================================================================
	XP Ends: 22/9 (0 h:0)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:0)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2354 - acc: 0.9316
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0893 - acc: 0.9736
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0537 - acc: 0.9852
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.1103 - acc: 0.9795
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0468 - acc: 0.9873
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0572 - acc: 0.9874
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0291 - acc: 0.9925
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0481 - acc: 0.9889
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0212 - acc: 0.9949
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0467 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0166 - acc: 0.9961
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0461 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 2.37 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.407
	P, R  : 0.48, 0.353

==================================================================================================
	XP Ends: 22/9 (0 h:4)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
14             ,5              ,276            ,48             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
15             ,65             ,True           ,79             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.036          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.074          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.009          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 14, 5, 276, 48, 9, 15, 65, True, 79, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.036, True, 20, 0.074, 256, 1, 20, categorical_crossentropy, 0.009, val_acc, adagrad, 4, False, 256, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:4)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1239 - acc: 0.9699
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0817 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1624 - acc: 0.9648
MWE identification: 2
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1095 - acc: 0.9723
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0980 - acc: 0.9748
MWE identification: 4
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0906 - acc: 0.9763
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 1.87 minutes 
==================================================================================================
	PARSING TIME: 1.87 minutes 
==================================================================================================
	Identification : 0.007
	P, R  : 0.004, 0.021

==================================================================================================
	XP Ends: 22/9 (0 h:8)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:8)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.2349 - acc: 0.9303
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0748 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.3538 - acc: 0.9118
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.2297 - acc: 0.9321
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.2082 - acc: 0.9369
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1950 - acc: 0.9399
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 1.62 minutes 
==================================================================================================
	PARSING TIME: 2.77 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (0 h:13)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:13)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1650 - acc: 0.9527
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0813 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.2953 - acc: 0.9313
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1623 - acc: 0.9536
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1391 - acc: 0.9599
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1252 - acc: 0.9642
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (0 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,4              ,242            ,37             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,49             ,True           ,43             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.026          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.007          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.045          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.057          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 4, 242, 37, 9, 7, 49, True, 43, True, False, False, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.026, True, 20, 0.007, 96, 2, 20, categorical_crossentropy, 0.045, val_loss, adagrad, 4, False, 128, 0.057, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.057
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1701 - acc: 0.9542
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0732 - acc: 0.9791
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0519 - acc: 0.9847
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0843 - acc: 0.9786
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0331 - acc: 0.9903
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0663 - acc: 0.9835
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0233 - acc: 0.9932
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0606 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0186 - acc: 0.9946
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0572 - acc: 0.9861
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0155 - acc: 0.9955
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0549 - acc: 0.9868
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.473
	P, R  : 0.435, 0.518

==================================================================================================
	XP Ends: 22/9 (0 h:21)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:21)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.057
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2541 - acc: 0.9214
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1263 - acc: 0.9580
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0962 - acc: 0.9681
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0924 - acc: 0.9755
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0629 - acc: 0.9800
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0701 - acc: 0.9825
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0438 - acc: 0.9866
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0639 - acc: 0.9842
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0331 - acc: 0.9903
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0602 - acc: 0.9852
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0260 - acc: 0.9927
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0576 - acc: 0.9859
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 1.98 minutes 
==================================================================================================
	PARSING TIME: 1.88 minutes 
==================================================================================================
	Identification : 0.365
	P, R  : 0.261, 0.608

==================================================================================================
	XP Ends: 22/9 (0 h:25)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:25)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.057
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2088 - acc: 0.9388
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0653 - acc: 0.9800
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0348 - acc: 0.9895
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0755 - acc: 0.9813
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0171 - acc: 0.9954
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0582 - acc: 0.9856
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0092 - acc: 0.9977
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0535 - acc: 0.9870
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0058 - acc: 0.9988
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0510 - acc: 0.9878
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0040 - acc: 0.9992
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0493 - acc: 0.9883
Should stop early?
Early stopping applied
POS tagging accuracy = 93.2
POS tagging accuracy (MWEs) = 93.2
	TRAINING TIME: 3.15 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.383
	P, R  : 0.454, 0.331

==================================================================================================
	XP Ends: 22/9 (0 h:29)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
20             ,3              ,245            ,79             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
16             ,59             ,True           ,89             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.021          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.033          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.087          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 20, 3, 245, 79, 7, 16, 59, True, 89, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.021, True, 20, 0.033, 96, 1, 20, categorical_crossentropy, 0.087, val_loss, adagrad, 4, False, 128, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:29)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.033
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2170 - acc: 0.9436
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1058 - acc: 0.9715
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0843 - acc: 0.9772
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0860 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0669 - acc: 0.9819
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0529 - acc: 0.9857
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0450 - acc: 0.9879
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0393 - acc: 0.9895
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 2.4 minutes 
==================================================================================================
	Identification : 0.01
	P, R  : 0.005, 0.155

==================================================================================================
	XP Ends: 22/9 (0 h:34)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:34)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.033
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3076 - acc: 0.9090
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1731 - acc: 0.9445
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1455 - acc: 0.9530
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1267 - acc: 0.9769
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1571 - acc: 0.9518
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.1632 - acc: 0.9802
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1215 - acc: 0.9627
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0499 - acc: 0.9883
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1021 - acc: 0.9683
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0482 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0900 - acc: 0.9727
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0473 - acc: 0.9887
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0806 - acc: 0.9758
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0471 - acc: 0.9888
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.22 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.423
	P, R  : 0.331, 0.586

==================================================================================================
	XP Ends: 22/9 (0 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.033
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2675 - acc: 0.9237
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1091 - acc: 0.9680
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0734 - acc: 0.9789
MWE identification: 1
Epoch 1/1
 - 15s - loss: 8.0594 - acc: 0.4998
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0574 - acc: 0.9851
MWE identification: 2
Epoch 1/1
 - 14s - loss: 8.0590 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0341 - acc: 0.9911
MWE identification: 3
Epoch 1/1
 - 15s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0257 - acc: 0.9937
MWE identification: 4
Epoch 1/1
 - 15s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0206 - acc: 0.9952
MWE identification: 5
Epoch 1/1
 - 15s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 3.17 minutes 
==================================================================================================
	PARSING TIME: 1.58 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.133

==================================================================================================
	XP Ends: 22/9 (0 h:43)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,1              ,238            ,65             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
40             ,48             ,True           ,167            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.051          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.006          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.041          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 1, 238, 65, 9, 40, 48, True, 167, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.006, True, 20, 0.051, 64, 1, 20, categorical_crossentropy, 0.006, val_loss, adagrad, 4, False, 256, 0.041, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:43)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1469 - acc: 0.9617
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0592 - acc: 0.9828
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0412 - acc: 0.9878
MWE identification: 1
Epoch 1/1
 - 14s - loss: 12.0869 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0343 - acc: 0.9899
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0245 - acc: 0.9927
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0194 - acc: 0.9943
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0160 - acc: 0.9953
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.77 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (0 h:48)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:48)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2497 - acc: 0.9230
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1323 - acc: 0.9557
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1011 - acc: 0.9665
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.4662 - acc: 0.9546
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.2004 - acc: 0.9404
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0645 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1151 - acc: 0.9633
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0508 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0908 - acc: 0.9709
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0482 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0759 - acc: 0.9761
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0473 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.17 minutes 
==================================================================================================
	PARSING TIME: 1.63 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.735, 0.497

==================================================================================================
	XP Ends: 22/9 (0 h:52)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:52)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1944 - acc: 0.9425
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0701 - acc: 0.9773
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0421 - acc: 0.9869
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.1144 - acc: 0.9797
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0703 - acc: 0.9782
MWE identification: 2
Epoch 1/1
 - 20s - loss: 0.0524 - acc: 0.9871
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0357 - acc: 0.9900
MWE identification: 3
Epoch 1/1
 - 20s - loss: 0.0474 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0223 - acc: 0.9941
MWE identification: 4
Epoch 1/1
 - 21s - loss: 0.0462 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0155 - acc: 0.9963
MWE identification: 5
Epoch 1/1
 - 20s - loss: 0.0455 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 3.53 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.468
	P, R  : 0.55, 0.408

==================================================================================================
	XP Ends: 22/9 (0 h:57)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
14             ,1              ,100            ,120            ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,58             ,True           ,103            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.01           ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.007          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.035          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.027          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 14, 1, 100, 120, 5, 9, 58, True, 103, True, False, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.01, True, 20, 0.007, 128, 2, 20, categorical_crossentropy, 0.035, val_loss, adagrad, 4, False, 256, 0.027, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (0h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.027
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1645 - acc: 0.9579
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0693 - acc: 0.9803
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0523 - acc: 0.9849
MWE identification: 1
Epoch 1/1
 - 9s - loss: 0.0887 - acc: 0.9782
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0446 - acc: 0.9871
MWE identification: 2
Epoch 1/1
 - 9s - loss: 0.0643 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0359 - acc: 0.9897
MWE identification: 3
Epoch 1/1
 - 9s - loss: 0.0589 - acc: 0.9857
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0301 - acc: 0.9914
MWE identification: 4
Epoch 1/1
 - 9s - loss: 0.0559 - acc: 0.9865
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0260 - acc: 0.9926
MWE identification: 5
Epoch 1/1
 - 9s - loss: 0.0541 - acc: 0.9871
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.28 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.579
	P, R  : 0.738, 0.476

==================================================================================================
	XP Ends: 22/9 (1 h:1)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:1)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.027
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2743 - acc: 0.9174
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1506 - acc: 0.9506
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1225 - acc: 0.9594
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1043 - acc: 0.9738
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1083 - acc: 0.9644
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0694 - acc: 0.9827
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0926 - acc: 0.9705
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0630 - acc: 0.9845
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0815 - acc: 0.9740
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0595 - acc: 0.9855
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0727 - acc: 0.9771
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0569 - acc: 0.9861
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.78 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.597
	P, R  : 0.763, 0.49

==================================================================================================
	XP Ends: 22/9 (1 h:4)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:4)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.027
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2227 - acc: 0.9360
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0843 - acc: 0.9735
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0568 - acc: 0.9828
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0779 - acc: 0.9804
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0449 - acc: 0.9870
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0596 - acc: 0.9848
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0318 - acc: 0.9912
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0553 - acc: 0.9860
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0240 - acc: 0.9939
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0528 - acc: 0.9869
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0190 - acc: 0.9955
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0511 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.77 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.447
	P, R  : 0.597, 0.357

==================================================================================================
	XP Ends: 22/9 (1 h:8)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
9              ,2              ,188            ,27             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
20             ,25             ,True           ,45             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.021          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.08           ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.028          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 9, 2, 188, 27, 7, 20, 25, True, 45, True, False, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.021, False, 20, 0.08, 256, 1, 20, categorical_crossentropy, 0.028, val_loss, adagrad, 4, False, 64, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:8)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1144 - acc: 0.9712
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0817 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1262 - acc: 0.9696
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0916 - acc: 0.9756
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0825 - acc: 0.9777
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0766 - acc: 0.9790
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0721 - acc: 0.9800
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.42 minutes 
==================================================================================================
	PARSING TIME: 2.27 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.16

==================================================================================================
	XP Ends: 22/9 (1 h:13)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:13)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.2225 - acc: 0.9322
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.7288 - acc: 0.9146
POS tagging: 4
Epoch 1/1
 - 6s - loss: 1.8823 - acc: 0.4314
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.1136 - acc: 0.9789
POS tagging: 5
Epoch 1/1
 - 6s - loss: 1.3715 - acc: 0.5843
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0867 - acc: 0.9830
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.9834 - acc: 0.7060
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0601 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.6248 - acc: 0.8225
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0526 - acc: 0.9872
Should stop early?
Early stopping applied
POS tagging accuracy = 73.9
POS tagging accuracy (MWEs) = 73.9
	TRAINING TIME: 1.87 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.553
	P, R  : 0.748, 0.439

==================================================================================================
	XP Ends: 22/9 (1 h:17)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:17)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1522 - acc: 0.9554
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0818 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.2183 - acc: 0.9423
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1321 - acc: 0.9615
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1138 - acc: 0.9670
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1024 - acc: 0.9703
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0940 - acc: 0.9729
MWE identification: 6
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 2.88 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (1 h:22)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
17             ,2              ,25             ,144            ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
16             ,135            ,True           ,65             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.007          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.074          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.042          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.038          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 17, 2, 25, 144, 6, 16, 135, True, 65, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.007, False, 20, 0.074, 128, 1, 20, categorical_crossentropy, 0.042, val_acc, adagrad, 4, False, 128, 0.038, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:22)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1496 - acc: 0.9609
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0605 - acc: 0.9825
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0455 - acc: 0.9861
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0852 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0362 - acc: 0.9891
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0231 - acc: 0.9931
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0177 - acc: 0.9946
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0144 - acc: 0.9957
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.32 minutes 
==================================================================================================
	PARSING TIME: 2.07 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (1 h:26)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:26)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2518 - acc: 0.9225
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1352 - acc: 0.9552
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1099 - acc: 0.9630
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0809 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0991 - acc: 0.9676
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0675 - acc: 0.9785
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0544 - acc: 0.9831
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0456 - acc: 0.9862
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.88 minutes 
==================================================================================================
	PARSING TIME: 2.87 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (1 h:31)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:31)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1991 - acc: 0.9417
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0724 - acc: 0.9768
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0482 - acc: 0.9846
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0858 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0349 - acc: 0.9892
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0173 - acc: 0.9952
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0109 - acc: 0.9974
MWE identification: 4
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0076 - acc: 0.9983
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.83 minutes 
==================================================================================================
	PARSING TIME: 1.22 minutes 
==================================================================================================
	Identification : 0.023
	P, R  : 0.04, 0.016

==================================================================================================
	XP Ends: 22/9 (1 h:36)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,1              ,224            ,81             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,28             ,True           ,140            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.01           ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.018          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.076          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 1, 224, 81, 6, 7, 28, True, 140, True, False, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.01, True, 20, 0.008, 256, 1, 20, categorical_crossentropy, 0.018, val_loss, adagrad, 4, False, 96, 0.076, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:36)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1770 - acc: 0.9535
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0703 - acc: 0.9799
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0521 - acc: 0.9845
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0907 - acc: 0.9769
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0301 - acc: 0.9911
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0678 - acc: 0.9831
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0202 - acc: 0.9942
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0619 - acc: 0.9846
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0160 - acc: 0.9953
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0584 - acc: 0.9857
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0134 - acc: 0.9961
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0559 - acc: 0.9864
Should stop early?
Early stopping applied
POS tagging accuracy = 95.5
POS tagging accuracy (MWEs) = 95.5
	TRAINING TIME: 2.12 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.468
	P, R  : 0.43, 0.513

==================================================================================================
	XP Ends: 22/9 (1 h:39)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:39)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2623 - acc: 0.9199
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1231 - acc: 0.9595
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0966 - acc: 0.9681
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1046 - acc: 0.9725
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0562 - acc: 0.9821
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0736 - acc: 0.9816
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0368 - acc: 0.9888
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0668 - acc: 0.9835
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0265 - acc: 0.9925
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0628 - acc: 0.9846
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0203 - acc: 0.9944
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0599 - acc: 0.9854
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 1.73 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.404
	P, R  : 0.302, 0.611

==================================================================================================
	XP Ends: 22/9 (1 h:43)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:43)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2122 - acc: 0.9387
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0597 - acc: 0.9815
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0336 - acc: 0.9898
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0803 - acc: 0.9799
POS tagging: 4
Epoch 1/1
 - 5s - loss: 0.0140 - acc: 0.9962
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0601 - acc: 0.9852
POS tagging: 5
Epoch 1/1
 - 5s - loss: 0.0067 - acc: 0.9984
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0551 - acc: 0.9866
POS tagging: 6
Epoch 1/1
 - 5s - loss: 0.0041 - acc: 0.9992
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0522 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 5s - loss: 0.0029 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0503 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 93.3
POS tagging accuracy (MWEs) = 93.3
	TRAINING TIME: 2.62 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.396
	P, R  : 0.418, 0.376

==================================================================================================
	XP Ends: 22/9 (1 h:47)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
11             ,5              ,78             ,39             ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
47             ,32             ,True           ,166            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.037          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.021          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.01           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.04           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 11, 5, 78, 39, 11, 47, 32, True, 166, True, False, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.037, False, 20, 0.021, 128, 1, 20, categorical_crossentropy, 0.01, val_loss, adagrad, 4, False, 96, 0.04, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1753 - acc: 0.9530
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0810 - acc: 0.9773
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0610 - acc: 0.9824
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.2026 - acc: 0.9735
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0453 - acc: 0.9870
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0564 - acc: 0.9869
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0314 - acc: 0.9911
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0493 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0249 - acc: 0.9929
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0469 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0207 - acc: 0.9941
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0458 - acc: 0.9893
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.42 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0.499
	P, R  : 0.506, 0.493

==================================================================================================
	XP Ends: 22/9 (1 h:51)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:51)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2581 - acc: 0.9199
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1378 - acc: 0.9549
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1115 - acc: 0.9630
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0968 - acc: 0.9780
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0855 - acc: 0.9731
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0611 - acc: 0.9855
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0610 - acc: 0.9812
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0516 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0479 - acc: 0.9853
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0490 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0393 - acc: 0.9885
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0478 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 1.6 minutes 
==================================================================================================
	Identification : 0.378
	P, R  : 0.273, 0.613

==================================================================================================
	XP Ends: 22/9 (1 h:54)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:54)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2122 - acc: 0.9373
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0741 - acc: 0.9778
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0440 - acc: 0.9868
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0950 - acc: 0.9817
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0279 - acc: 0.9921
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0523 - acc: 0.9879
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0149 - acc: 0.9961
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0475 - acc: 0.9890
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0096 - acc: 0.9979
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0465 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0069 - acc: 0.9986
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0459 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 3.03 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.393
	P, R  : 0.406, 0.38

==================================================================================================
	XP Ends: 22/9 (1 h:59)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
17             ,1              ,116            ,36             ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
22             ,36             ,True           ,157            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.056          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.053          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.04           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 17, 1, 116, 36, 13, 22, 36, True, 157, False, False, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.006, True, 20, 0.056, 256, 2, 20, categorical_crossentropy, 0.053, val_loss, adagrad, 4, False, 256, 0.04, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (1h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.056
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1753 - acc: 0.9530
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0810 - acc: 0.9773
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0563 - acc: 0.9844
MWE identification: 1
Epoch 1/1
 - 5s - loss: 3.6441 - acc: 0.7620
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1177 - acc: 0.9698
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.1086 - acc: 0.9829
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0680 - acc: 0.9823
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0517 - acc: 0.9882
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0477 - acc: 0.9872
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0460 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0379 - acc: 0.9898
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0450 - acc: 0.9894
Should stop early?
Early stopping applied
POS tagging accuracy = 94.9
POS tagging accuracy (MWEs) = 94.9
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.47
	P, R  : 0.426, 0.524

==================================================================================================
	XP Ends: 22/9 (2 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.056
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2581 - acc: 0.9199
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1378 - acc: 0.9549
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1034 - acc: 0.9664
MWE identification: 1
Epoch 1/1
 - 3s - loss: 5.4597 - acc: 0.6517
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1665 - acc: 0.9497
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.1030 - acc: 0.9814
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1131 - acc: 0.9662
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0666 - acc: 0.9862
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0876 - acc: 0.9736
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0514 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0707 - acc: 0.9791
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0492 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 1.6 minutes 
==================================================================================================
	PARSING TIME: 1.83 minutes 
==================================================================================================
	Identification : 0.448
	P, R  : 0.379, 0.548

==================================================================================================
	XP Ends: 22/9 (2 h:6)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:6)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.056
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2122 - acc: 0.9373
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0741 - acc: 0.9778
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0390 - acc: 0.9892
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0810 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0322 - acc: 0.9914
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0174 - acc: 0.9956
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0121 - acc: 0.9973
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0091 - acc: 0.9981
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0071 - acc: 0.9986
MWE identification: 6
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (2 h:10)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,5              ,87             ,147            ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
13             ,29             ,True           ,32             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.014          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.016          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.091          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.076          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 5, 87, 147, 9, 13, 29, True, 32, True, False, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.014, False, 20, 0.016, 64, 1, 20, categorical_crossentropy, 0.091, val_acc, adagrad, 4, False, 64, 0.076, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:10)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1770 - acc: 0.9534
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0703 - acc: 0.9799
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0564 - acc: 0.9831
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0766 - acc: 0.9807
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0317 - acc: 0.9906
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0571 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0203 - acc: 0.9942
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0515 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0159 - acc: 0.9953
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0486 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0132 - acc: 0.9962
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0469 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 3.12 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0.466
	P, R  : 0.457, 0.475

==================================================================================================
	XP Ends: 22/9 (2 h:14)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:14)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2623 - acc: 0.9199
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1231 - acc: 0.9595
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1032 - acc: 0.9658
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0824 - acc: 0.9786
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0589 - acc: 0.9812
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0609 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0373 - acc: 0.9884
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0544 - acc: 0.9868
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0264 - acc: 0.9925
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0512 - acc: 0.9877
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0200 - acc: 0.9946
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0493 - acc: 0.9883
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0156 - acc: 0.9959
MWE identification: 6
Epoch 1/1
 - 11s - loss: 0.0482 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.78 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.375
	P, R  : 0.271, 0.611

==================================================================================================
	XP Ends: 22/9 (2 h:19)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:19)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2122 - acc: 0.9388
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0597 - acc: 0.9816
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0378 - acc: 0.9881
MWE identification: 1
Epoch 1/1
 - 21s - loss: 0.0684 - acc: 0.9829
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0155 - acc: 0.9956
MWE identification: 2
Epoch 1/1
 - 21s - loss: 0.0519 - acc: 0.9873
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0068 - acc: 0.9983
MWE identification: 3
Epoch 1/1
 - 21s - loss: 0.0479 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0040 - acc: 0.9992
MWE identification: 4
Epoch 1/1
 - 21s - loss: 0.0463 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0027 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 21s - loss: 0.0456 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.2
POS tagging accuracy (MWEs) = 93.2
	TRAINING TIME: 3.92 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.403
	P, R  : 0.444, 0.369

==================================================================================================
	XP Ends: 22/9 (2 h:24)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,1              ,88             ,59             ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
29             ,26             ,True           ,30             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.019          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.008          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.012          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.034          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 1, 88, 59, 10, 29, 26, True, 30, True, True, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.019, True, 20, 0.008, 256, 1, 20, categorical_crossentropy, 0.012, val_acc, adagrad, 4, False, 96, 0.034, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1838 - acc: 0.9513
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0862 - acc: 0.9762
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0660 - acc: 0.9814
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1000 - acc: 0.9755
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0442 - acc: 0.9874
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0654 - acc: 0.9838
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0327 - acc: 0.9907
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0590 - acc: 0.9856
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0267 - acc: 0.9925
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0553 - acc: 0.9867
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0227 - acc: 0.9936
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0529 - acc: 0.9874
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0199 - acc: 0.9944
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0511 - acc: 0.9879
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.25 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.496
	P, R  : 0.526, 0.47

==================================================================================================
	XP Ends: 22/9 (2 h:28)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:28)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2669 - acc: 0.9181
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1454 - acc: 0.9526
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1192 - acc: 0.9606
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1146 - acc: 0.9705
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0852 - acc: 0.9732
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0710 - acc: 0.9824
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0654 - acc: 0.9799
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0635 - acc: 0.9845
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0536 - acc: 0.9839
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0594 - acc: 0.9856
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0453 - acc: 0.9866
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0566 - acc: 0.9864
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0392 - acc: 0.9888
MWE identification: 6
Epoch 1/1
 - 3s - loss: 0.0547 - acc: 0.9871
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 1.87 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.357
	P, R  : 0.252, 0.611

==================================================================================================
	XP Ends: 22/9 (2 h:31)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:31)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2198 - acc: 0.9354
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0805 - acc: 0.9761
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.0495 - acc: 0.9854
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0835 - acc: 0.9800
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0262 - acc: 0.9928
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0575 - acc: 0.9862
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0156 - acc: 0.9960
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0522 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 5s - loss: 0.0108 - acc: 0.9976
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0498 - acc: 0.9883
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0081 - acc: 0.9983
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0483 - acc: 0.9887
Should stop early?
POS tagging: 8
Epoch 1/1
 - 5s - loss: 0.0064 - acc: 0.9987
MWE identification: 6
Epoch 1/1
 - 6s - loss: 0.0473 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 2.75 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.33
	P, R  : 0.444, 0.263

==================================================================================================
	XP Ends: 22/9 (2 h:35)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,4              ,34             ,159            ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,197            ,True           ,56             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.007          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.044          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.032          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.031          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 4, 34, 159, 6, 7, 197, True, 56, True, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.007, False, 20, 0.044, 96, 1, 20, categorical_crossentropy, 0.032, val_loss, adagrad, 4, False, 128, 0.031, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:35)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1598 - acc: 0.9591
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0661 - acc: 0.9810
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0510 - acc: 0.9850
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0860 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0378 - acc: 0.9888
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0272 - acc: 0.9918
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0217 - acc: 0.9936
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0181 - acc: 0.9947
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (2 h:40)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:40)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2649 - acc: 0.9196
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1445 - acc: 0.9521
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1197 - acc: 0.9599
MWE identification: 1
Epoch 1/1
 - 8s - loss: 8.0594 - acc: 0.4994
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1103 - acc: 0.9650
MWE identification: 2
Epoch 1/1
 - 8s - loss: 8.0602 - acc: 0.4998
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0818 - acc: 0.9737
MWE identification: 3
Epoch 1/1
 - 8s - loss: 8.0595 - acc: 0.4998
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0674 - acc: 0.9789
MWE identification: 4
Epoch 1/1
 - 8s - loss: 8.0594 - acc: 0.4998
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0579 - acc: 0.9821
MWE identification: 5
Epoch 1/1
 - 8s - loss: 8.0594 - acc: 0.4998
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.07 minutes 
==================================================================================================
	PARSING TIME: 3.6 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.145

==================================================================================================
	XP Ends: 22/9 (2 h:46)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:46)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2130 - acc: 0.9385
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0800 - acc: 0.9748
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0557 - acc: 0.9824
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.1205 - acc: 0.9791
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0719 - acc: 0.9791
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0558 - acc: 0.9868
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0387 - acc: 0.9892
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0478 - acc: 0.9885
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0245 - acc: 0.9935
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0464 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0177 - acc: 0.9957
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0457 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 3.05 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.461
	P, R  : 0.597, 0.375

==================================================================================================
	XP Ends: 22/9 (2 h:50)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,4              ,51             ,100            ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
20             ,31             ,True           ,97             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.046          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.015          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.064          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.039          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 4, 51, 100, 8, 20, 31, True, 97, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.046, True, 20, 0.015, 128, 1, 20, categorical_crossentropy, 0.064, val_loss, adagrad, 4, False, 64, 0.039, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:50)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1483 - acc: 0.9612
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0599 - acc: 0.9826
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0486 - acc: 0.9851
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0847 - acc: 0.9804
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0317 - acc: 0.9904
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0572 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0213 - acc: 0.9935
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0519 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0163 - acc: 0.9951
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0491 - acc: 0.9883
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0132 - acc: 0.9961
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0477 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.734, 0.475

==================================================================================================
	XP Ends: 22/9 (2 h:54)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:54)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2511 - acc: 0.9228
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1343 - acc: 0.9551
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1149 - acc: 0.9610
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0954 - acc: 0.9776
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0814 - acc: 0.9735
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0629 - acc: 0.9847
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0603 - acc: 0.9809
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0550 - acc: 0.9867
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0484 - acc: 0.9852
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0520 - acc: 0.9875
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0402 - acc: 0.9879
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0501 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.608
	P, R  : 0.707, 0.533

==================================================================================================
	XP Ends: 22/9 (2 h:58)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (2h:58)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1969 - acc: 0.9424
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0721 - acc: 0.9768
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0531 - acc: 0.9826
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0750 - acc: 0.9814
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0292 - acc: 0.9912
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0551 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0156 - acc: 0.9959
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0506 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0097 - acc: 0.9977
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0483 - acc: 0.9883
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0066 - acc: 0.9987
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0469 - acc: 0.9888
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.03 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.459
	P, R  : 0.57, 0.384

==================================================================================================
	XP Ends: 22/9 (3 h:2)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,6              ,137            ,57             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
12             ,41             ,True           ,90             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.007          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.014          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.065          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.05           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 6, 137, 57, 5, 12, 41, True, 90, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.007, True, 20, 0.014, 256, 1, 20, categorical_crossentropy, 0.065, val_loss, adagrad, 4, False, 128, 0.05, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.05
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1407 - acc: 0.9626
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0551 - acc: 0.9835
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0405 - acc: 0.9876
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0950 - acc: 0.9784
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0280 - acc: 0.9916
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0603 - acc: 0.9852
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0186 - acc: 0.9944
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0547 - acc: 0.9868
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0140 - acc: 0.9956
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0515 - acc: 0.9877
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0113 - acc: 0.9966
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0496 - acc: 0.9882
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.07 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.575
	P, R  : 0.689, 0.493

==================================================================================================
	XP Ends: 22/9 (3 h:6)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:6)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.05
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2481 - acc: 0.9237
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1265 - acc: 0.9577
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1005 - acc: 0.9660
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1312 - acc: 0.9732
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0735 - acc: 0.9761
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0670 - acc: 0.9836
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0534 - acc: 0.9832
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0580 - acc: 0.9858
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0419 - acc: 0.9873
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0544 - acc: 0.9868
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0341 - acc: 0.9898
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0522 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.67 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.571
	P, R  : 0.654, 0.506

==================================================================================================
	XP Ends: 22/9 (3 h:9)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:9)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.05
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1916 - acc: 0.9439
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0654 - acc: 0.9784
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0419 - acc: 0.9862
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0866 - acc: 0.9798
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0246 - acc: 0.9925
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0572 - acc: 0.9855
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0128 - acc: 0.9966
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0522 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0075 - acc: 0.9983
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0496 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0050 - acc: 0.9990
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0480 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.48 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.459
	P, R  : 0.589, 0.376

==================================================================================================
	XP Ends: 22/9 (3 h:13)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,2              ,73             ,69             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
18             ,55             ,True           ,40             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.007          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.005          ,64             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.007          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.019          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 2, 73, 69, 6, 18, 55, True, 40, False, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.007, True, 20, 0.005, 64, 2, 20, categorical_crossentropy, 0.007, val_loss, adagrad, 4, False, 96, 0.019, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:13)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1924 - acc: 0.9517
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0803 - acc: 0.9779
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0649 - acc: 0.9814
MWE identification: 1
Epoch 1/1
 - 16s - loss: 0.0851 - acc: 0.9782
POS tagging: 4
Epoch 1/1
 - 5s - loss: 0.0499 - acc: 0.9857
MWE identification: 2
Epoch 1/1
 - 16s - loss: 0.0661 - acc: 0.9835
POS tagging: 5
Epoch 1/1
 - 5s - loss: 0.0401 - acc: 0.9887
MWE identification: 3
Epoch 1/1
 - 16s - loss: 0.0611 - acc: 0.9851
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0339 - acc: 0.9905
MWE identification: 4
Epoch 1/1
 - 16s - loss: 0.0582 - acc: 0.9858
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0295 - acc: 0.9917
MWE identification: 5
Epoch 1/1
 - 16s - loss: 0.0562 - acc: 0.9863
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 3.07 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.57
	P, R  : 0.771, 0.452

==================================================================================================
	XP Ends: 22/9 (3 h:17)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:17)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3045 - acc: 0.9104
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1688 - acc: 0.9456
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1440 - acc: 0.9525
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0987 - acc: 0.9743
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1186 - acc: 0.9612
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0724 - acc: 0.9818
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1017 - acc: 0.9672
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0662 - acc: 0.9834
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0904 - acc: 0.9712
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0629 - acc: 0.9844
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0818 - acc: 0.9742
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0605 - acc: 0.9850
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.3 minutes 
==================================================================================================
	PARSING TIME: 1.77 minutes 
==================================================================================================
	Identification : 0.61
	P, R  : 0.886, 0.465

==================================================================================================
	XP Ends: 22/9 (3 h:22)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:22)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2562 - acc: 0.9281
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1007 - acc: 0.9691
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0754 - acc: 0.9763
MWE identification: 1
Epoch 1/1
 - 22s - loss: 0.0772 - acc: 0.9805
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0521 - acc: 0.9845
MWE identification: 2
Epoch 1/1
 - 22s - loss: 0.0619 - acc: 0.9842
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0373 - acc: 0.9895
MWE identification: 3
Epoch 1/1
 - 22s - loss: 0.0575 - acc: 0.9854
POS tagging: 6
Epoch 1/1
 - 5s - loss: 0.0286 - acc: 0.9923
MWE identification: 4
Epoch 1/1
 - 22s - loss: 0.0550 - acc: 0.9861
POS tagging: 7
Epoch 1/1
 - 5s - loss: 0.0229 - acc: 0.9941
MWE identification: 5
Epoch 1/1
 - 22s - loss: 0.0532 - acc: 0.9867
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.87 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.448
	P, R  : 0.627, 0.349

==================================================================================================
	XP Ends: 22/9 (3 h:26)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,8              ,32             ,39             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,97             ,True           ,46             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.019          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.005          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.075          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 8, 32, 39, 6, 9, 97, True, 46, False, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.019, True, 20, 0.005, 128, 1, 20, categorical_crossentropy, 0.075, val_loss, adagrad, 4, False, 64, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:26)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1144 - acc: 0.9712
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0999 - acc: 0.9740
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0942 - acc: 0.9754
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0674 - acc: 0.9833
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0831 - acc: 0.9776
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0612 - acc: 0.9848
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0766 - acc: 0.9789
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0581 - acc: 0.9857
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0718 - acc: 0.9799
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0561 - acc: 0.9862
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 1.15 minutes 
==================================================================================================
	Identification : 0.579
	P, R  : 0.754, 0.47

==================================================================================================
	XP Ends: 22/9 (3 h:30)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:30)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.2225 - acc: 0.9322
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.1246 - acc: 0.9667
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1947 - acc: 0.9391
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0761 - acc: 0.9811
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1771 - acc: 0.9441
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0684 - acc: 0.9829
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1666 - acc: 0.9471
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0644 - acc: 0.9837
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1588 - acc: 0.9493
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0616 - acc: 0.9846
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.15 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.609
	P, R  : 0.91, 0.458

==================================================================================================
	XP Ends: 22/9 (3 h:35)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:35)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1522 - acc: 0.9554
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0868 - acc: 0.9777
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1223 - acc: 0.9647
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0624 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1032 - acc: 0.9700
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0579 - acc: 0.9852
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0922 - acc: 0.9730
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0554 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0841 - acc: 0.9757
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0536 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.07 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.445
	P, R  : 0.642, 0.341

==================================================================================================
	XP Ends: 22/9 (3 h:39)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,1              ,238            ,83             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
27             ,30             ,True           ,136            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.029          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.009          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 1, 238, 83, 5, 27, 30, True, 136, True, False, True, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.006, True, 20, 0.006, 96, 1, 20, categorical_crossentropy, 0.029, val_loss, adagrad, 4, False, 256, 0.009, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:39)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3637 - acc: 0.9093
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1528 - acc: 0.9601
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1276 - acc: 0.9664
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0979 - acc: 0.9740
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1184 - acc: 0.9688
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0680 - acc: 0.9833
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1048 - acc: 0.9723
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0611 - acc: 0.9853
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0958 - acc: 0.9749
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0572 - acc: 0.9863
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0888 - acc: 0.9766
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0547 - acc: 0.9870
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.493
	P, R  : 0.452, 0.543

==================================================================================================
	XP Ends: 22/9 (3 h:42)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:42)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4674 - acc: 0.8716
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2339 - acc: 0.9297
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.2023 - acc: 0.9374
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1148 - acc: 0.9688
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1917 - acc: 0.9401
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0736 - acc: 0.9817
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1748 - acc: 0.9448
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0661 - acc: 0.9838
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1633 - acc: 0.9482
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0620 - acc: 0.9849
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1542 - acc: 0.9512
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0591 - acc: 0.9856
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 1.9 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.29
	P, R  : 0.187, 0.644

==================================================================================================
	XP Ends: 22/9 (3 h:46)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:46)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4335 - acc: 0.8837
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1797 - acc: 0.9479
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1378 - acc: 0.9608
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0841 - acc: 0.9788
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1187 - acc: 0.9668
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0587 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0974 - acc: 0.9734
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0535 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0841 - acc: 0.9777
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0508 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0740 - acc: 0.9807
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0492 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.1
POS tagging accuracy (MWEs) = 93.1
	TRAINING TIME: 3.05 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.407
	P, R  : 0.504, 0.341

==================================================================================================
	XP Ends: 22/9 (3 h:50)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,8              ,169            ,30             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
46             ,25             ,True           ,114            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.042          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.08           ,64             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.058          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.039          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 8, 169, 30, 7, 46, 25, True, 114, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.042, False, 20, 0.08, 64, 2, 20, categorical_crossentropy, 0.058, val_loss, adagrad, 4, False, 128, 0.039, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:50)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1483 - acc: 0.9611
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0599 - acc: 0.9825
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0450 - acc: 0.9864
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0869 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0358 - acc: 0.9891
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0226 - acc: 0.9931
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0173 - acc: 0.9947
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0141 - acc: 0.9959
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.87 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (3 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (3h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2511 - acc: 0.9228
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1344 - acc: 0.9550
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1089 - acc: 0.9633
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0844 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0974 - acc: 0.9684
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0663 - acc: 0.9791
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0533 - acc: 0.9835
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0444 - acc: 0.9868
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.27 minutes 
==================================================================================================
	PARSING TIME: 2.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (4 h:1)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:1)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1969 - acc: 0.9424
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0721 - acc: 0.9768
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0482 - acc: 0.9845
MWE identification: 1
Epoch 1/1
 - 21s - loss: 12.0873 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0348 - acc: 0.9894
MWE identification: 2
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0170 - acc: 0.9954
MWE identification: 3
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0106 - acc: 0.9974
MWE identification: 4
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0073 - acc: 0.9985
MWE identification: 5
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.68 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (4 h:6)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,4              ,118            ,60             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
30             ,198            ,True           ,119            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.012          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.032          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.016          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.015          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 4, 118, 60, 12, 30, 198, True, 119, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.012, False, 20, 0.032, 256, 1, 20, categorical_crossentropy, 0.016, val_loss, adagrad, 4, False, 96, 0.015, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:6)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2516 - acc: 0.9362
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1188 - acc: 0.9681
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0963 - acc: 0.9739
MWE identification: 1
Epoch 1/1
 - 4s - loss: 12.0817 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0786 - acc: 0.9793
MWE identification: 2
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0639 - acc: 0.9830
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0554 - acc: 0.9854
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0492 - acc: 0.9870
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0446 - acc: 0.9882
MWE identification: 6
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.4
POS tagging accuracy (MWEs) = 95.4
	TRAINING TIME: 2.23 minutes 
==================================================================================================
	PARSING TIME: 2.58 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.122

==================================================================================================
	XP Ends: 22/9 (4 h:11)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:11)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3460 - acc: 0.9005
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1913 - acc: 0.9393
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1632 - acc: 0.9476
MWE identification: 1
Epoch 1/1
 - 3s - loss: 8.0604 - acc: 0.4986
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1512 - acc: 0.9532
MWE identification: 2
Epoch 1/1
 - 3s - loss: 8.0597 - acc: 0.4998
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1222 - acc: 0.9615
MWE identification: 3
Epoch 1/1
 - 3s - loss: 8.0595 - acc: 0.4998
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1091 - acc: 0.9660
MWE identification: 4
Epoch 1/1
 - 3s - loss: 8.0595 - acc: 0.4998
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0992 - acc: 0.9694
MWE identification: 5
Epoch 1/1
 - 3s - loss: 8.0595 - acc: 0.4998
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.75 minutes 
==================================================================================================
	PARSING TIME: 3.72 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.145

==================================================================================================
	XP Ends: 22/9 (4 h:17)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:17)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3097 - acc: 0.9137
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1295 - acc: 0.9621
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.0919 - acc: 0.9737
MWE identification: 1
Epoch 1/1
 - 6s - loss: 8.0578 - acc: 0.4995
POS tagging: 4
Epoch 1/1
 - 5s - loss: 0.0767 - acc: 0.9797
MWE identification: 2
Epoch 1/1
 - 6s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 5s - loss: 0.0492 - acc: 0.9870
MWE identification: 3
Epoch 1/1
 - 6s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 5s - loss: 0.0378 - acc: 0.9905
MWE identification: 4
Epoch 1/1
 - 6s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 5s - loss: 0.0310 - acc: 0.9926
MWE identification: 5
Epoch 1/1
 - 6s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 2.58 minutes 
==================================================================================================
	PARSING TIME: 1.6 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.133

==================================================================================================
	XP Ends: 22/9 (4 h:21)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,1              ,33             ,173            ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
8              ,56             ,True           ,157            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.006          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.03           ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.005          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.066          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 1, 33, 173, 6, 8, 56, True, 157, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.006, False, 20, 0.03, 256, 1, 20, categorical_crossentropy, 0.005, val_loss, adagrad, 4, False, 96, 0.066, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:21)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1467 - acc: 0.9617
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0527 - acc: 0.9843
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0406 - acc: 0.9875
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0932 - acc: 0.9796
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0296 - acc: 0.9911
MWE identification: 2
Epoch 1/1
 - 4s - loss: 0.0546 - acc: 0.9865
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0173 - acc: 0.9947
MWE identification: 3
Epoch 1/1
 - 4s - loss: 0.0489 - acc: 0.9882
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0123 - acc: 0.9961
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0465 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0096 - acc: 0.9970
MWE identification: 5
Epoch 1/1
 - 4s - loss: 0.0455 - acc: 0.9893
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.58
	P, R  : 0.729, 0.482

==================================================================================================
	XP Ends: 22/9 (4 h:25)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:25)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2485 - acc: 0.9237
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1204 - acc: 0.9596
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0981 - acc: 0.9664
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0756 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0617 - acc: 0.9798
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0414 - acc: 0.9870
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0305 - acc: 0.9910
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0235 - acc: 0.9932
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0186 - acc: 0.9950
MWE identification: 6
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.85 minutes 
==================================================================================================
	PARSING TIME: 3.03 minutes 
==================================================================================================
	Identification : 0.009
	P, R  : 0.005, 0.04

==================================================================================================
	XP Ends: 22/9 (4 h:30)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:30)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1949 - acc: 0.9437
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0616 - acc: 0.9798
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0410 - acc: 0.9865
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0923 - acc: 0.9800
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0255 - acc: 0.9922
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0564 - acc: 0.9861
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0112 - acc: 0.9970
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0493 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0059 - acc: 0.9988
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0472 - acc: 0.9888
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0036 - acc: 0.9994
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0462 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.443
	P, R  : 0.599, 0.351

==================================================================================================
	XP Ends: 22/9 (4 h:34)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,6              ,163            ,34             ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,72             ,True           ,50             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.04           ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.019          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.014          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.04           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 6, 163, 34, 11, 6, 72, True, 50, False, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.04, True, 20, 0.019, 128, 1, 20, categorical_crossentropy, 0.014, val_loss, adagrad, 4, False, 128, 0.04, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:34)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1473 - acc: 0.9614
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0593 - acc: 0.9827
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0445 - acc: 0.9865
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0830 - acc: 0.9810
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0350 - acc: 0.9894
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0568 - acc: 0.9864
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0238 - acc: 0.9931
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0507 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0180 - acc: 0.9947
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0482 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0145 - acc: 0.9957
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0469 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.3 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.741, 0.473

==================================================================================================
	XP Ends: 22/9 (4 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:37)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2503 - acc: 0.9226
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1332 - acc: 0.9555
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1076 - acc: 0.9638
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1406 - acc: 0.9751
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0871 - acc: 0.9715
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0634 - acc: 0.9848
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0653 - acc: 0.9794
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0540 - acc: 0.9871
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0526 - acc: 0.9837
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0511 - acc: 0.9879
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0439 - acc: 0.9866
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0493 - acc: 0.9883
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.85 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.601
	P, R  : 0.709, 0.521

==================================================================================================
	XP Ends: 22/9 (4 h:41)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:41)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.019
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1955 - acc: 0.9426
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0707 - acc: 0.9773
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0467 - acc: 0.9851
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0798 - acc: 0.9816
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0329 - acc: 0.9901
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0542 - acc: 0.9864
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0177 - acc: 0.9953
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0496 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0110 - acc: 0.9974
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0476 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0075 - acc: 0.9984
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0464 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.83 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.421
	P, R  : 0.54, 0.345

==================================================================================================
	XP Ends: 22/9 (4 h:45)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,1              ,50             ,153            ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
33             ,28             ,True           ,114            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.015          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.082          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.081          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.007          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 1, 50, 153, 11, 33, 28, True, 114, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.015, False, 20, 0.082, 64, 1, 20, categorical_crossentropy, 0.081, val_loss, adagrad, 4, False, 96, 0.007, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:45)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.082
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4404 - acc: 0.8938
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1397 - acc: 0.9666
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1062 - acc: 0.9730
MWE identification: 1
Epoch 1/1
 - 16s - loss: 12.0865 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 5s - loss: 0.1373 - acc: 0.9688
MWE identification: 2
Epoch 1/1
 - 16s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 5s - loss: 0.0891 - acc: 0.9766
MWE identification: 3
Epoch 1/1
 - 16s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 5s - loss: 0.0792 - acc: 0.9788
MWE identification: 4
Epoch 1/1
 - 16s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 5s - loss: 0.0730 - acc: 0.9800
MWE identification: 5
Epoch 1/1
 - 16s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 3.1 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (4 h:50)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:50)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.082
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5602 - acc: 0.8488
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2567 - acc: 0.9246
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.2103 - acc: 0.9349
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0938 - acc: 0.2495
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.2311 - acc: 0.9320
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1808 - acc: 0.9431
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1668 - acc: 0.9471
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1572 - acc: 0.9496
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.33 minutes 
==================================================================================================
	PARSING TIME: 3.18 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (4 h:56)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (4h:56)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.082
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5174 - acc: 0.8655
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1913 - acc: 0.9468
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1398 - acc: 0.9591
MWE identification: 1
Epoch 1/1
 - 21s - loss: 12.0869 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1725 - acc: 0.9528
MWE identification: 2
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1096 - acc: 0.9681
MWE identification: 3
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0948 - acc: 0.9724
MWE identification: 4
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0850 - acc: 0.9754
MWE identification: 5
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.72 minutes 
==================================================================================================
	PARSING TIME: 1.17 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (5 h:1)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,9              ,215            ,39             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,105            ,True           ,40             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.043          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.015          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.018          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.017          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 9, 215, 39, 5, 9, 105, True, 40, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.043, False, 20, 0.015, 128, 1, 20, categorical_crossentropy, 0.018, val_loss, adagrad, 4, False, 64, 0.017, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:1)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2036 - acc: 0.9496
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0842 - acc: 0.9772
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0689 - acc: 0.9804
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0936 - acc: 0.9797
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0581 - acc: 0.9836
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0581 - acc: 0.9861
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0466 - acc: 0.9869
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0523 - acc: 0.9875
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0398 - acc: 0.9890
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0498 - acc: 0.9883
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0350 - acc: 0.9903
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0483 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 1.13 minutes 
==================================================================================================
	Identification : 0.572
	P, R  : 0.724, 0.473

==================================================================================================
	XP Ends: 22/9 (5 h:5)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:5)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3185 - acc: 0.9073
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1743 - acc: 0.9439
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1496 - acc: 0.9506
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1097 - acc: 0.9766
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1311 - acc: 0.9575
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0640 - acc: 0.9848
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1112 - acc: 0.9640
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0550 - acc: 0.9869
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0986 - acc: 0.9681
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0520 - acc: 0.9878
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0893 - acc: 0.9714
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0502 - acc: 0.9882
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.07 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.581
	P, R  : 0.666, 0.515

==================================================================================================
	XP Ends: 22/9 (5 h:9)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:9)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2697 - acc: 0.9250
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1061 - acc: 0.9677
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0804 - acc: 0.9748
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0799 - acc: 0.9816
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0640 - acc: 0.9811
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0553 - acc: 0.9864
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0453 - acc: 0.9870
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0503 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0349 - acc: 0.9904
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0482 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0282 - acc: 0.9928
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0469 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.08 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.451
	P, R  : 0.623, 0.353

==================================================================================================
	XP Ends: 22/9 (5 h:13)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
21             ,1              ,42             ,158            ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,56             ,True           ,32             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.017          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.051          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.085          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 21, 1, 42, 158, 8, 6, 56, True, 32, False, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.017, False, 20, 0.051, 64, 1, 20, categorical_crossentropy, 0.085, val_loss, adagrad, 4, False, 64, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:13)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1875 - acc: 0.9528
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0787 - acc: 0.9784
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0644 - acc: 0.9814
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0873 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0503 - acc: 0.9858
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0372 - acc: 0.9894
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0308 - acc: 0.9912
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0265 - acc: 0.9925
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 3.1 minutes 
==================================================================================================
	PARSING TIME: 2.38 minutes 
==================================================================================================
	Identification : 0.012
	P, R  : 0.006, 0.178

==================================================================================================
	XP Ends: 22/9 (5 h:19)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:19)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2987 - acc: 0.9120
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1653 - acc: 0.9465
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1420 - acc: 0.9529
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0847 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1223 - acc: 0.9605
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0972 - acc: 0.9685
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0852 - acc: 0.9729
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0763 - acc: 0.9760
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 2.85 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (5 h:25)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:25)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2483 - acc: 0.9298
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0979 - acc: 0.9700
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0740 - acc: 0.9765
MWE identification: 1
Epoch 1/1
 - 21s - loss: 12.0873 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0510 - acc: 0.9848
MWE identification: 2
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0336 - acc: 0.9903
MWE identification: 3
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0251 - acc: 0.9932
MWE identification: 4
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0198 - acc: 0.9951
MWE identification: 5
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.83 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.014
	P, R  : 0.007, 0.255

==================================================================================================
	XP Ends: 22/9 (5 h:31)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,1              ,219            ,57             ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
16             ,132            ,True           ,46             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.041          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.007          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.099          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.017          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 1, 219, 57, 10, 16, 132, True, 46, True, False, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.041, True, 20, 0.007, 96, 1, 20, categorical_crossentropy, 0.099, val_acc, adagrad, 4, False, 64, 0.017, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:31)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2340 - acc: 0.9398
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1125 - acc: 0.9697
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0911 - acc: 0.9752
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0905 - acc: 0.9768
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0696 - acc: 0.9813
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0643 - acc: 0.9842
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0564 - acc: 0.9848
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0581 - acc: 0.9860
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0483 - acc: 0.9870
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0546 - acc: 0.9869
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0425 - acc: 0.9885
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0523 - acc: 0.9876
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0383 - acc: 0.9897
MWE identification: 6
Epoch 1/1
 - 10s - loss: 0.0507 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 3.03 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.502
	P, R  : 0.523, 0.482

==================================================================================================
	XP Ends: 22/9 (5 h:35)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:35)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3275 - acc: 0.9043
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1836 - acc: 0.9416
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1567 - acc: 0.9492
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1017 - acc: 0.9729
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1274 - acc: 0.9594
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0694 - acc: 0.9826
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1078 - acc: 0.9662
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0624 - acc: 0.9848
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0952 - acc: 0.9706
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0586 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0856 - acc: 0.9741
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0559 - acc: 0.9866
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0781 - acc: 0.9768
MWE identification: 6
Epoch 1/1
 - 7s - loss: 0.0541 - acc: 0.9871
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.43 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.336
	P, R  : 0.237, 0.577

==================================================================================================
	XP Ends: 22/9 (5 h:40)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:40)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2894 - acc: 0.9188
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1188 - acc: 0.9651
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0833 - acc: 0.9756
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0794 - acc: 0.9806
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0522 - acc: 0.9856
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0562 - acc: 0.9866
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0363 - acc: 0.9904
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0515 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0281 - acc: 0.9930
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0493 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0230 - acc: 0.9944
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0479 - acc: 0.9888
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 3.38 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.347
	P, R  : 0.441, 0.286

==================================================================================================
	XP Ends: 22/9 (5 h:44)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,9              ,47             ,172            ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
42             ,49             ,True           ,89             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.009          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.026          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.028          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.005          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 9, 47, 172, 11, 42, 49, True, 89, False, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.009, True, 20, 0.026, 96, 2, 20, categorical_crossentropy, 0.028, val_loss, adagrad, 4, False, 128, 0.005, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6418 - acc: 0.8429
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1948 - acc: 0.9543
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1367 - acc: 0.9671
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0805 - acc: 0.9817
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1625 - acc: 0.9648
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0525 - acc: 0.9874
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1242 - acc: 0.9712
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0477 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1064 - acc: 0.9738
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0459 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0966 - acc: 0.9751
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0452 - acc: 0.9893
Should stop early?
Early stopping applied
POS tagging accuracy = 95.9
POS tagging accuracy (MWEs) = 95.9
	TRAINING TIME: 2.53 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.568
	P, R  : 0.698, 0.479

==================================================================================================
	XP Ends: 22/9 (5 h:48)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:48)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.7461 - acc: 0.8006
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.3238 - acc: 0.9094
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.2523 - acc: 0.9261
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.1051 - acc: 0.9777
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.2818 - acc: 0.9222
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0561 - acc: 0.9867
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.2339 - acc: 0.9313
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0501 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.2098 - acc: 0.9360
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0484 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1957 - acc: 0.9393
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0475 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.3
POS tagging accuracy (MWEs) = 93.3
	TRAINING TIME: 2.07 minutes 
==================================================================================================
	PARSING TIME: 1.63 minutes 
==================================================================================================
	Identification : 0.602
	P, R  : 0.626, 0.58

==================================================================================================
	XP Ends: 22/9 (5 h:52)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:52)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.026
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.7034 - acc: 0.8166
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2518 - acc: 0.9352
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1827 - acc: 0.9486
MWE identification: 1
Epoch 1/1
 - 16s - loss: 8.0585 - acc: 0.4998
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1738 - acc: 0.9521
MWE identification: 2
Epoch 1/1
 - 16s - loss: 8.0590 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1309 - acc: 0.9624
MWE identification: 3
Epoch 1/1
 - 15s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1168 - acc: 0.9663
MWE identification: 4
Epoch 1/1
 - 15s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1072 - acc: 0.9689
MWE identification: 5
Epoch 1/1
 - 14s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 1.62 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.133

==================================================================================================
	XP Ends: 22/9 (5 h:57)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,2              ,65             ,42             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
14             ,35             ,True           ,66             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.02           ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.009          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.074          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.039          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 2, 65, 42, 7, 14, 35, True, 66, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.02, False, 20, 0.009, 128, 2, 20, categorical_crossentropy, 0.074, val_acc, adagrad, 4, False, 64, 0.039, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (5h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1483 - acc: 0.9611
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0599 - acc: 0.9825
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0485 - acc: 0.9852
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0840 - acc: 0.9792
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0295 - acc: 0.9910
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0622 - acc: 0.9845
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0202 - acc: 0.9938
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0566 - acc: 0.9861
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0156 - acc: 0.9953
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0535 - acc: 0.9870
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0127 - acc: 0.9961
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0516 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.572
	P, R  : 0.729, 0.47

==================================================================================================
	XP Ends: 22/9 (6 h:1)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:1)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2511 - acc: 0.9228
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1343 - acc: 0.9550
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1149 - acc: 0.9610
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0973 - acc: 0.9758
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0778 - acc: 0.9747
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0671 - acc: 0.9833
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0584 - acc: 0.9816
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0607 - acc: 0.9850
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0470 - acc: 0.9856
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0573 - acc: 0.9860
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0391 - acc: 0.9881
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0548 - acc: 0.9866
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0333 - acc: 0.9901
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0532 - acc: 0.9872
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.27 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.576
	P, R  : 0.618, 0.539

==================================================================================================
	XP Ends: 22/9 (6 h:5)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:5)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.039
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.009
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1969 - acc: 0.9424
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0721 - acc: 0.9768
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0531 - acc: 0.9827
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0753 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0265 - acc: 0.9920
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0580 - acc: 0.9850
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0147 - acc: 0.9963
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0537 - acc: 0.9864
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0094 - acc: 0.9979
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0512 - acc: 0.9873
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0066 - acc: 0.9987
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0495 - acc: 0.9879
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.08 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.479
	P, R  : 0.602, 0.398

==================================================================================================
	XP Ends: 22/9 (6 h:9)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,3              ,77             ,130            ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
30             ,44             ,True           ,171            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.018          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.043          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.014          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.065          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 3, 77, 130, 9, 30, 44, True, 171, False, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.018, True, 20, 0.043, 128, 1, 20, categorical_crossentropy, 0.014, val_acc, adagrad, 4, False, 128, 0.065, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:9)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.065
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1463 - acc: 0.9619
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0527 - acc: 0.9844
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0384 - acc: 0.9881
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0852 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0244 - acc: 0.9926
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0158 - acc: 0.9952
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0118 - acc: 0.9963
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0095 - acc: 0.9971
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.42 minutes 
==================================================================================================
	PARSING TIME: 2.55 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.109

==================================================================================================
	XP Ends: 22/9 (6 h:15)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:15)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.065
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2483 - acc: 0.9234
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1207 - acc: 0.9592
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0940 - acc: 0.9681
MWE identification: 1
Epoch 1/1
 - 5s - loss: 8.2518 - acc: 0.4877
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0670 - acc: 0.9783
MWE identification: 2
Epoch 1/1
 - 5s - loss: 8.0594 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0445 - acc: 0.9863
MWE identification: 3
Epoch 1/1
 - 5s - loss: 8.0593 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0329 - acc: 0.9900
MWE identification: 4
Epoch 1/1
 - 5s - loss: 8.0593 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0256 - acc: 0.9926
MWE identification: 5
Epoch 1/1
 - 6s - loss: 8.0593 - acc: 0.5000
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0204 - acc: 0.9944
MWE identification: 6
Epoch 1/1
 - 5s - loss: 8.0593 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.05 minutes 
==================================================================================================
	PARSING TIME: 2.75 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (6 h:20)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:20)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.065
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.043
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1940 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0616 - acc: 0.9798
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0381 - acc: 0.9875
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0766 - acc: 0.9817
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0348 - acc: 0.9891
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0535 - acc: 0.9866
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0140 - acc: 0.9962
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0478 - acc: 0.9884
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0073 - acc: 0.9983
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0463 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0044 - acc: 0.9992
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0456 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.83 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.474
	P, R  : 0.585, 0.398

==================================================================================================
	XP Ends: 22/9 (6 h:24)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,8              ,43             ,40             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,198            ,True           ,25             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.014          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.012          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.015          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 8, 43, 40, 8, 5, 198, True, 25, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.014, False, 20, 0.006, 96, 1, 20, categorical_crossentropy, 0.012, val_loss, adagrad, 4, False, 96, 0.015, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2225 - acc: 0.9456
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0901 - acc: 0.9760
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0727 - acc: 0.9797
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0871 - acc: 0.9778
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0585 - acc: 0.9831
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0641 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0486 - acc: 0.9863
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0591 - acc: 0.9855
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0422 - acc: 0.9883
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0563 - acc: 0.9863
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0375 - acc: 0.9896
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0545 - acc: 0.9868
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.58 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.583
	P, R  : 0.796, 0.46

==================================================================================================
	XP Ends: 22/9 (6 h:28)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:28)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3363 - acc: 0.9032
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1823 - acc: 0.9417
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1560 - acc: 0.9491
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1081 - acc: 0.9727
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1331 - acc: 0.9566
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0714 - acc: 0.9820
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1167 - acc: 0.9621
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0648 - acc: 0.9839
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1058 - acc: 0.9657
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0612 - acc: 0.9848
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0973 - acc: 0.9687
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0586 - acc: 0.9855
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 2.07 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0.59
	P, R  : 0.881, 0.443

==================================================================================================
	XP Ends: 22/9 (6 h:32)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:32)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2889 - acc: 0.9203
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1134 - acc: 0.9659
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0858 - acc: 0.9734
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0796 - acc: 0.9801
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0640 - acc: 0.9810
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0601 - acc: 0.9846
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0484 - acc: 0.9860
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0558 - acc: 0.9858
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0389 - acc: 0.9893
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0534 - acc: 0.9866
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0324 - acc: 0.9915
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0517 - acc: 0.9872
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.22 minutes 
==================================================================================================
	PARSING TIME: 0.77 minutes 
==================================================================================================
	Identification : 0.443
	P, R  : 0.601, 0.351

==================================================================================================
	XP Ends: 22/9 (6 h:36)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,1              ,163            ,30             ,13             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
27             ,106            ,True           ,50             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.027          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.02           ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.057          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.023          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 1, 163, 30, 13, 27, 106, True, 50, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.027, True, 20, 0.02, 96, 1, 20, categorical_crossentropy, 0.057, val_loss, adagrad, 4, False, 96, 0.023, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:36)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1737 - acc: 0.9558
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0737 - acc: 0.9793
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0592 - acc: 0.9827
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0852 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0430 - acc: 0.9876
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0331 - acc: 0.9904
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0272 - acc: 0.9921
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0232 - acc: 0.9934
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.62 minutes 
==================================================================================================
	PARSING TIME: 2.55 minutes 
==================================================================================================
	Identification : 0.012
	P, R  : 0.006, 0.27

==================================================================================================
	XP Ends: 22/9 (6 h:42)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:42)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2856 - acc: 0.9146
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1578 - acc: 0.9485
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1340 - acc: 0.9553
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0959 - acc: 0.9789
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1195 - acc: 0.9610
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0601 - acc: 0.9858
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0973 - acc: 0.9687
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0520 - acc: 0.9876
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0835 - acc: 0.9732
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0497 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0738 - acc: 0.9771
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0484 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.07 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.56
	P, R  : 0.608, 0.519

==================================================================================================
	XP Ends: 22/9 (6 h:46)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:46)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2340 - acc: 0.9331
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0908 - acc: 0.9718
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0668 - acc: 0.9789
MWE identification: 1
Epoch 1/1
 - 14s - loss: 12.0865 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0422 - acc: 0.9874
MWE identification: 2
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0283 - acc: 0.9922
MWE identification: 3
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0207 - acc: 0.9947
MWE identification: 4
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0160 - acc: 0.9963
MWE identification: 5
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 1.42 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.063

==================================================================================================
	XP Ends: 22/9 (6 h:51)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
18             ,1              ,258            ,151            ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
31             ,56             ,True           ,153            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.08           ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.007          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.03           ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 18, 1, 258, 151, 11, 31, 56, True, 153, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.006, True, 20, 0.08, 96, 1, 20, categorical_crossentropy, 0.007, val_loss, adagrad, 4, False, 64, 0.03, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1609 - acc: 0.9588
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0669 - acc: 0.9808
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0545 - acc: 0.9838
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0860 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0415 - acc: 0.9877
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0270 - acc: 0.9919
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0211 - acc: 0.9938
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0174 - acc: 0.9949
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.73 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (6 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (6h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2671 - acc: 0.9190
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1457 - acc: 0.9519
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1253 - acc: 0.9578
MWE identification: 1
Epoch 1/1
 - 8s - loss: 2.5364 - acc: 0.8243
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.4006 - acc: 0.8823
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.1844 - acc: 0.9753
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1944 - acc: 0.9407
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0555 - acc: 0.9866
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1549 - acc: 0.9519
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0501 - acc: 0.9879
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1343 - acc: 0.9578
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0481 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 92.5
POS tagging accuracy (MWEs) = 92.5
	TRAINING TIME: 2.3 minutes 
==================================================================================================
	PARSING TIME: 1.63 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.804, 0.461

==================================================================================================
	XP Ends: 22/9 (7 h:0)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:0)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2154 - acc: 0.9377
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0809 - acc: 0.9746
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0603 - acc: 0.9807
MWE identification: 1
Epoch 1/1
 - 14s - loss: 12.0860 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0507 - acc: 0.9850
MWE identification: 2
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0234 - acc: 0.9933
MWE identification: 3
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0155 - acc: 0.9960
MWE identification: 4
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0113 - acc: 0.9974
MWE identification: 5
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.32 minutes 
==================================================================================================
	PARSING TIME: 1.27 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (7 h:5)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,6              ,109            ,126            ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
10             ,82             ,True           ,63             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.012          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.031          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.056          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.013          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 6, 109, 126, 5, 10, 82, True, 63, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.012, True, 20, 0.031, 128, 2, 20, categorical_crossentropy, 0.056, val_loss, adagrad, 4, False, 96, 0.013, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:5)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2471 - acc: 0.9401
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0961 - acc: 0.9749
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0775 - acc: 0.9786
MWE identification: 1
Epoch 1/1
 - 8s - loss: 8.0584 - acc: 0.4996
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0744 - acc: 0.9805
MWE identification: 2
Epoch 1/1
 - 8s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0556 - acc: 0.9842
MWE identification: 3
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0485 - acc: 0.9864
MWE identification: 4
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0435 - acc: 0.9879
MWE identification: 5
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 2.37 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 22/9 (7 h:10)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:10)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3616 - acc: 0.8974
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1924 - acc: 0.9390
POS tagging: 3
Epoch 1/1
 - 5s - loss: 0.1645 - acc: 0.9467
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1049 - acc: 0.9775
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1848 - acc: 0.9447
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.9074 - acc: 0.9353
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1504 - acc: 0.9530
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0534 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1326 - acc: 0.9575
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0500 - acc: 0.9883
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1205 - acc: 0.9614
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0483 - acc: 0.9886
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.1115 - acc: 0.9644
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0478 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.13 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.576
	P, R  : 0.662, 0.51

==================================================================================================
	XP Ends: 22/9 (7 h:14)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:14)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3187 - acc: 0.9134
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1232 - acc: 0.9636
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0933 - acc: 0.9713
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0817 - acc: 0.9817
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1135 - acc: 0.9683
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0583 - acc: 0.9870
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0782 - acc: 0.9779
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0480 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0618 - acc: 0.9825
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0467 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0520 - acc: 0.9852
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0460 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.9 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.454
	P, R  : 0.618, 0.359

==================================================================================================
	XP Ends: 22/9 (7 h:18)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,7              ,215            ,75             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
10             ,68             ,True           ,31             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.016          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.076          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.012          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.064          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 7, 215, 75, 6, 10, 68, True, 31, False, False, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.016, True, 20, 0.076, 256, 2, 20, categorical_crossentropy, 0.012, val_loss, adagrad, 4, False, 64, 0.064, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:18)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1462 - acc: 0.9619
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0531 - acc: 0.9842
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0440 - acc: 0.9864
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0816 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0270 - acc: 0.9915
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0154 - acc: 0.9951
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0112 - acc: 0.9965
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0089 - acc: 0.9972
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0075 - acc: 0.9976
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.42 minutes 
==================================================================================================
	PARSING TIME: 1.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (7 h:23)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:23)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2485 - acc: 0.9233
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1210 - acc: 0.9592
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1042 - acc: 0.9643
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0784 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0734 - acc: 0.9757
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0443 - acc: 0.9861
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0323 - acc: 0.9903
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0249 - acc: 0.9929
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0197 - acc: 0.9947
MWE identification: 6
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.03 minutes 
==================================================================================================
	PARSING TIME: 2.73 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (7 h:28)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:28)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1942 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0618 - acc: 0.9797
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0457 - acc: 0.9844
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0830 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0230 - acc: 0.9927
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0092 - acc: 0.9975
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0047 - acc: 0.9990
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0028 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.68 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.117
	P, R  : 0.075, 0.261

==================================================================================================
	XP Ends: 22/9 (7 h:32)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
16             ,6              ,285            ,32             ,11             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
13             ,112            ,True           ,174            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.032          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.038          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.011          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.041          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 16, 6, 285, 32, 11, 13, 112, True, 174, True, False, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.032, True, 20, 0.038, 64, 1, 20, categorical_crossentropy, 0.011, val_acc, adagrad, 4, False, 256, 0.041, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:32)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1469 - acc: 0.9617
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0592 - acc: 0.9828
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0412 - acc: 0.9877
MWE identification: 1
Epoch 1/1
 - 15s - loss: 0.0986 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0498 - acc: 0.9854
MWE identification: 2
Epoch 1/1
 - 15s - loss: 0.0523 - acc: 0.9874
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0332 - acc: 0.9905
MWE identification: 3
Epoch 1/1
 - 15s - loss: 0.0472 - acc: 0.9887
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0247 - acc: 0.9928
MWE identification: 4
Epoch 1/1
 - 15s - loss: 0.0455 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0197 - acc: 0.9943
MWE identification: 5
Epoch 1/1
 - 15s - loss: 0.0449 - acc: 0.9894
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0163 - acc: 0.9953
MWE identification: 6
Epoch 1/1
 - 15s - loss: 0.0446 - acc: 0.9895
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 3.08 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.575
	P, R  : 0.744, 0.469

==================================================================================================
	XP Ends: 22/9 (7 h:36)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:36)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2497 - acc: 0.9230
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1323 - acc: 0.9559
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1011 - acc: 0.9666
MWE identification: 1
Epoch 1/1
 - 10s - loss: 8.0600 - acc: 0.4995
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0952 - acc: 0.9694
MWE identification: 2
Epoch 1/1
 - 10s - loss: 8.0596 - acc: 0.4998
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0704 - acc: 0.9779
MWE identification: 3
Epoch 1/1
 - 10s - loss: 8.0594 - acc: 0.4998
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0586 - acc: 0.9817
MWE identification: 4
Epoch 1/1
 - 10s - loss: 8.0594 - acc: 0.4998
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0500 - acc: 0.9848
MWE identification: 5
Epoch 1/1
 - 10s - loss: 8.0594 - acc: 0.4998
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.18 minutes 
==================================================================================================
	PARSING TIME: 3.63 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.108

==================================================================================================
	XP Ends: 22/9 (7 h:43)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:43)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.041
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1944 - acc: 0.9425
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0701 - acc: 0.9773
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0422 - acc: 0.9868
MWE identification: 1
Epoch 1/1
 - 20s - loss: 0.0707 - acc: 0.9825
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0539 - acc: 0.9838
MWE identification: 2
Epoch 1/1
 - 20s - loss: 0.0515 - acc: 0.9871
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0282 - acc: 0.9923
MWE identification: 3
Epoch 1/1
 - 19s - loss: 0.0473 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0180 - acc: 0.9955
MWE identification: 4
Epoch 1/1
 - 20s - loss: 0.0461 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0125 - acc: 0.9971
MWE identification: 5
Epoch 1/1
 - 20s - loss: 0.0455 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 3.48 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.477
	P, R  : 0.573, 0.408

==================================================================================================
	XP Ends: 22/9 (7 h:47)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,4              ,47             ,36             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
14             ,53             ,True           ,58             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.033          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.059          ,64             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.019          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.062          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 4, 47, 36, 9, 14, 53, True, 58, False, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.033, True, 20, 0.059, 64, 1, 20, categorical_crossentropy, 0.019, val_loss, adagrad, 4, False, 128, 0.062, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1449 - acc: 0.9619
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0531 - acc: 0.9841
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0384 - acc: 0.9881
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0869 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0255 - acc: 0.9920
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0159 - acc: 0.9951
MWE identification: 3
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0118 - acc: 0.9963
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0094 - acc: 0.9971
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.87 minutes 
==================================================================================================
	PARSING TIME: 1.83 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (7 h:52)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:52)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2488 - acc: 0.9234
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1219 - acc: 0.9591
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0958 - acc: 0.9675
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0856 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0688 - acc: 0.9772
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0460 - acc: 0.9855
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0345 - acc: 0.9898
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0272 - acc: 0.9920
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.25 minutes 
==================================================================================================
	PARSING TIME: 2.72 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.007

==================================================================================================
	XP Ends: 22/9 (7 h:57)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (7h:57)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1933 - acc: 0.9436
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0622 - acc: 0.9795
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0383 - acc: 0.9875
MWE identification: 1
Epoch 1/1
 - 20s - loss: 12.0873 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0211 - acc: 0.9934
MWE identification: 2
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0096 - acc: 0.9974
MWE identification: 3
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0051 - acc: 0.9990
MWE identification: 4
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0031 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 20s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.6 minutes 
==================================================================================================
	PARSING TIME: 1.5 minutes 
==================================================================================================
	Identification : 0.027
	P, R  : 0.014, 0.3

==================================================================================================
	XP Ends: 22/9 (8 h:3)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,3              ,128            ,55             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,141            ,True           ,70             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.038          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.07           ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.025          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.006          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 3, 128, 55, 5, 7, 141, True, 70, False, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.038, True, 20, 0.07, 256, 2, 20, categorical_crossentropy, 0.025, val_loss, adagrad, 4, False, 128, 0.006, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:3)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.07
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5214 - acc: 0.8736
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1603 - acc: 0.9620
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1190 - acc: 0.9706
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0817 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1332 - acc: 0.9690
MWE identification: 2
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0964 - acc: 0.9749
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0869 - acc: 0.9769
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0805 - acc: 0.9784
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0758 - acc: 0.9794
MWE identification: 6
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.15 minutes 
==================================================================================================
	PARSING TIME: 2.22 minutes 
==================================================================================================
	Identification : 0.01
	P, R  : 0.005, 0.14

==================================================================================================
	XP Ends: 22/9 (8 h:7)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:7)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.07
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6373 - acc: 0.8289
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2826 - acc: 0.9189
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.2284 - acc: 0.9313
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0758 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.3027 - acc: 0.9214
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.2081 - acc: 0.9367
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1900 - acc: 0.9413
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1785 - acc: 0.9442
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.1699 - acc: 0.9465
MWE identification: 6
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 1.82 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (8 h:12)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:12)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.07
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5871 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2140 - acc: 0.9421
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1584 - acc: 0.9541
MWE identification: 1
Epoch 1/1
 - 6s - loss: 12.0816 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.2231 - acc: 0.9433
MWE identification: 2
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1362 - acc: 0.9602
MWE identification: 3
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1180 - acc: 0.9659
MWE identification: 4
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1065 - acc: 0.9692
MWE identification: 5
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 3s - loss: 0.0979 - acc: 0.9718
MWE identification: 6
Epoch 1/1
 - 6s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 2.6 minutes 
==================================================================================================
	PARSING TIME: 1.23 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (8 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
18             ,1              ,49             ,72             ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,85             ,True           ,89             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.005          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.018          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.067          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.023          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 18, 1, 49, 72, 8, 6, 85, True, 89, False, True, False, False, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 256, 0.005, False, 20, 0.018, 128, 2, 20, categorical_crossentropy, 0.067, val_loss, adagrad, 4, False, 256, 0.023, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2044 - acc: 0.9466
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0997 - acc: 0.9730
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0772 - acc: 0.9792
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0862 - acc: 0.9801
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0741 - acc: 0.9800
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0554 - acc: 0.9871
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0586 - acc: 0.9844
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0487 - acc: 0.9886
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0490 - acc: 0.9868
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0468 - acc: 0.9891
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0424 - acc: 0.9885
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0458 - acc: 0.9893
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.23 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.507
	P, R  : 0.536, 0.481

==================================================================================================
	XP Ends: 22/9 (8 h:20)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:20)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2935 - acc: 0.9120
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1646 - acc: 0.9470
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1347 - acc: 0.9567
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1252 - acc: 0.9753
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1315 - acc: 0.9584
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0630 - acc: 0.9854
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1085 - acc: 0.9661
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0530 - acc: 0.9876
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0941 - acc: 0.9708
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0504 - acc: 0.9883
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0837 - acc: 0.9747
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0488 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 1.78 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.392
	P, R  : 0.292, 0.597

==================================================================================================
	XP Ends: 22/9 (8 h:24)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:24)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2534 - acc: 0.9271
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1007 - acc: 0.9703
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0642 - acc: 0.9823
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0941 - acc: 0.9818
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0598 - acc: 0.9839
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0519 - acc: 0.9880
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0395 - acc: 0.9898
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0472 - acc: 0.9890
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0295 - acc: 0.9928
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0463 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0238 - acc: 0.9944
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0458 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 92.7
POS tagging accuracy (MWEs) = 92.7
	TRAINING TIME: 2.8 minutes 
==================================================================================================
	PARSING TIME: 0.65 minutes 
==================================================================================================
	Identification : 0.422
	P, R  : 0.439, 0.406

==================================================================================================
	XP Ends: 22/9 (8 h:28)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
19             ,2              ,235            ,74             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
20             ,56             ,True           ,30             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.017          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.036          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.038          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.063          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 19, 2, 235, 74, 6, 20, 56, True, 30, False, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.017, False, 20, 0.036, 256, 1, 20, categorical_crossentropy, 0.038, val_acc, adagrad, 4, False, 256, 0.063, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:28)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1457 - acc: 0.9619
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0530 - acc: 0.9842
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0341 - acc: 0.9898
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0816 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0254 - acc: 0.9924
MWE identification: 2
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0179 - acc: 0.9946
MWE identification: 3
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0139 - acc: 0.9958
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0113 - acc: 0.9966
MWE identification: 5
Epoch 1/1
 - 4s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 1.97 minutes 
==================================================================================================
	PARSING TIME: 2.4 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.082

==================================================================================================
	XP Ends: 22/9 (8 h:32)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:32)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2488 - acc: 0.9233
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1218 - acc: 0.9588
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0869 - acc: 0.9712
MWE identification: 1
Epoch 1/1
 - 3s - loss: 12.0748 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0697 - acc: 0.9774
MWE identification: 2
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0508 - acc: 0.9842
MWE identification: 3
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0398 - acc: 0.9881
MWE identification: 4
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0321 - acc: 0.9907
MWE identification: 5
Epoch 1/1
 - 3s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.58 minutes 
==================================================================================================
	PARSING TIME: 3.18 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.045

==================================================================================================
	XP Ends: 22/9 (8 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1944 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0625 - acc: 0.9795
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0335 - acc: 0.9894
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0969 - acc: 0.9799
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0351 - acc: 0.9893
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0550 - acc: 0.9865
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0172 - acc: 0.9953
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0481 - acc: 0.9884
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0099 - acc: 0.9978
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0464 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0065 - acc: 0.9987
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0458 - acc: 0.9891
Should stop early?
POS tagging: 8
Epoch 1/1
 - 2s - loss: 0.0046 - acc: 0.9992
MWE identification: 6
Epoch 1/1
 - 6s - loss: 0.0455 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.44
	P, R  : 0.627, 0.339

==================================================================================================
	XP Ends: 22/9 (8 h:41)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
12             ,8              ,58             ,60             ,14             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
33             ,152            ,True           ,138            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.017          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.014          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.011          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.063          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 12, 8, 58, 60, 14, 33, 152, True, 138, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 96, 0.017, False, 20, 0.014, 256, 1, 20, categorical_crossentropy, 0.011, val_loss, adagrad, 4, False, 128, 0.063, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:41)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1714 - acc: 0.9539
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0716 - acc: 0.9795
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0505 - acc: 0.9851
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0961 - acc: 0.9782
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0332 - acc: 0.9902
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0607 - acc: 0.9851
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0225 - acc: 0.9934
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0542 - acc: 0.9870
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0177 - acc: 0.9948
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0507 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0145 - acc: 0.9957
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0486 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 95.3
POS tagging accuracy (MWEs) = 95.3
	TRAINING TIME: 2.12 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.475
	P, R  : 0.457, 0.494

==================================================================================================
	XP Ends: 22/9 (8 h:45)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:45)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2562 - acc: 0.9210
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1253 - acc: 0.9581
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0946 - acc: 0.9684
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1037 - acc: 0.9748
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0628 - acc: 0.9800
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0649 - acc: 0.9838
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0423 - acc: 0.9871
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0574 - acc: 0.9860
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0314 - acc: 0.9909
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0537 - acc: 0.9871
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0244 - acc: 0.9933
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0514 - acc: 0.9877
Should stop early?
Early stopping applied
POS tagging accuracy = 93.6
POS tagging accuracy (MWEs) = 93.6
	TRAINING TIME: 1.7 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.41
	P, R  : 0.321, 0.568

==================================================================================================
	XP Ends: 22/9 (8 h:48)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:48)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2081 - acc: 0.9392
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0611 - acc: 0.9813
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0322 - acc: 0.9904
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0815 - acc: 0.9809
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0167 - acc: 0.9955
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0535 - acc: 0.9870
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0083 - acc: 0.9980
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0490 - acc: 0.9884
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0050 - acc: 0.9989
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0472 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0034 - acc: 0.9993
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0462 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.4
POS tagging accuracy (MWEs) = 93.4
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.377
	P, R  : 0.439, 0.331

==================================================================================================
	XP Ends: 22/9 (8 h:52)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
20             ,3              ,113            ,119            ,8              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
16             ,54             ,True           ,61             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.043          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.021          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.011          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.031          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 20, 3, 113, 119, 8, 16, 54, True, 61, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.043, False, 20, 0.021, 128, 1, 20, categorical_crossentropy, 0.011, val_loss, adagrad, 4, False, 128, 0.031, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:52)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1598 - acc: 0.9591
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0662 - acc: 0.9810
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0511 - acc: 0.9850
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0852 - acc: 0.9812
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0443 - acc: 0.9870
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0584 - acc: 0.9865
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0317 - acc: 0.9908
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0500 - acc: 0.9880
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0249 - acc: 0.9928
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0476 - acc: 0.9888
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0206 - acc: 0.9940
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0464 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.35 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.578
	P, R  : 0.708, 0.488

==================================================================================================
	XP Ends: 22/9 (8 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2649 - acc: 0.9196
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1445 - acc: 0.9521
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1197 - acc: 0.9599
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.7618 - acc: 0.9380
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1053 - acc: 0.9654
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0642 - acc: 0.9850
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0829 - acc: 0.9738
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0535 - acc: 0.9873
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0691 - acc: 0.9784
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0507 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0594 - acc: 0.9819
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0491 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.727, 0.501

==================================================================================================
	XP Ends: 22/9 (8 h:59)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (8h:59)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2130 - acc: 0.9385
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0800 - acc: 0.9748
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0557 - acc: 0.9824
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0883 - acc: 0.9810
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0460 - acc: 0.9863
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0549 - acc: 0.9864
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0271 - acc: 0.9925
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0492 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0181 - acc: 0.9955
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0473 - acc: 0.9887
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0133 - acc: 0.9970
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0463 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 2.85 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.441
	P, R  : 0.599, 0.349

==================================================================================================
	XP Ends: 22/9 (9 h:3)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,1              ,266            ,139            ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
7              ,35             ,True           ,188            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.046          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.011          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.034          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.011          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 1, 266, 139, 5, 7, 35, True, 188, True, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.046, True, 20, 0.011, 128, 1, 20, categorical_crossentropy, 0.034, val_loss, adagrad, 4, False, 128, 0.011, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:3)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2833 - acc: 0.9315
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1046 - acc: 0.9734
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0842 - acc: 0.9773
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0968 - acc: 0.9787
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0767 - acc: 0.9788
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0593 - acc: 0.9857
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0655 - acc: 0.9815
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0541 - acc: 0.9870
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0586 - acc: 0.9834
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0515 - acc: 0.9877
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0536 - acc: 0.9847
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0499 - acc: 0.9882
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.37 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.799, 0.463

==================================================================================================
	XP Ends: 22/9 (9 h:7)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:7)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4005 - acc: 0.8884
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2055 - acc: 0.9361
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1754 - acc: 0.9438
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1240 - acc: 0.9735
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1628 - acc: 0.9480
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0651 - acc: 0.9839
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1446 - acc: 0.9534
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0582 - acc: 0.9859
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1330 - acc: 0.9571
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0548 - acc: 0.9869
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.1242 - acc: 0.9598
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0524 - acc: 0.9875
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 1.85 minutes 
==================================================================================================
	PARSING TIME: 1.87 minutes 
==================================================================================================
	Identification : 0.61
	P, R  : 0.818, 0.486

==================================================================================================
	XP Ends: 22/9 (9 h:11)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:11)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3549 - acc: 0.9052
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1374 - acc: 0.9593
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1041 - acc: 0.9690
MWE identification: 1
Epoch 1/1
 - 12s - loss: 0.0802 - acc: 0.9808
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0914 - acc: 0.9733
MWE identification: 2
Epoch 1/1
 - 12s - loss: 0.0559 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0722 - acc: 0.9792
MWE identification: 3
Epoch 1/1
 - 12s - loss: 0.0515 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0610 - acc: 0.9826
MWE identification: 4
Epoch 1/1
 - 12s - loss: 0.0493 - acc: 0.9882
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0530 - acc: 0.9851
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0478 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.87 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.427
	P, R  : 0.642, 0.32

==================================================================================================
	XP Ends: 22/9 (9 h:15)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,7              ,236            ,42             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
28             ,60             ,True           ,88             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.007          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.066          ,64             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.01           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.013          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 7, 236, 42, 5, 28, 60, True, 88, True, True, False, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.007, True, 20, 0.066, 64, 2, 20, categorical_crossentropy, 0.01, val_loss, adagrad, 4, False, 96, 0.013, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:15)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2753 - acc: 0.9307
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1270 - acc: 0.9661
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1033 - acc: 0.9721
MWE identification: 1
Epoch 1/1
 - 15s - loss: 12.0869 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0967 - acc: 0.9745
MWE identification: 2
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0744 - acc: 0.9802
MWE identification: 3
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0649 - acc: 0.9829
MWE identification: 4
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0581 - acc: 0.9848
MWE identification: 5
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.5
POS tagging accuracy (MWEs) = 95.5
	TRAINING TIME: 2.98 minutes 
==================================================================================================
	PARSING TIME: 1.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (9 h:20)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:20)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3720 - acc: 0.8947
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2021 - acc: 0.9368
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1729 - acc: 0.9447
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0861 - acc: 0.2499
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1741 - acc: 0.9460
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1372 - acc: 0.9568
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1233 - acc: 0.9612
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1129 - acc: 0.9652
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.33 minutes 
==================================================================================================
	PARSING TIME: 2.75 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (9 h:26)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:26)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3367 - acc: 0.9073
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1408 - acc: 0.9587
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1015 - acc: 0.9707
MWE identification: 1
Epoch 1/1
 - 21s - loss: 12.0873 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0872 - acc: 0.9761
MWE identification: 2
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0574 - acc: 0.9846
MWE identification: 3
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0457 - acc: 0.9883
MWE identification: 4
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0381 - acc: 0.9907
MWE identification: 5
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.2
POS tagging accuracy (MWEs) = 93.2
	TRAINING TIME: 3.78 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.009
	P, R  : 0.005, 0.041

==================================================================================================
	XP Ends: 22/9 (9 h:31)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
10             ,1              ,75             ,142            ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,124            ,True           ,42             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.012          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.014          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.026          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.017          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 10, 1, 75, 142, 6, 6, 124, True, 42, True, False, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.012, True, 20, 0.014, 128, 2, 20, categorical_crossentropy, 0.026, val_loss, adagrad, 4, False, 128, 0.017, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:31)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2036 - acc: 0.9496
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0842 - acc: 0.9772
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0680 - acc: 0.9808
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0970 - acc: 0.9792
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0614 - acc: 0.9827
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0586 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0498 - acc: 0.9859
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0529 - acc: 0.9874
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0428 - acc: 0.9881
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0504 - acc: 0.9881
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0378 - acc: 0.9895
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0489 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.32 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.575
	P, R  : 0.749, 0.467

==================================================================================================
	XP Ends: 22/9 (9 h:35)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:35)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3185 - acc: 0.9073
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1743 - acc: 0.9439
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1484 - acc: 0.9513
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1165 - acc: 0.9755
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.1361 - acc: 0.9559
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0628 - acc: 0.9848
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.1164 - acc: 0.9623
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0554 - acc: 0.9866
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.1039 - acc: 0.9663
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0523 - acc: 0.9876
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0946 - acc: 0.9697
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0504 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 1.88 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.608
	P, R  : 0.774, 0.501

==================================================================================================
	XP Ends: 22/9 (9 h:39)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:39)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2697 - acc: 0.9250
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1061 - acc: 0.9677
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0793 - acc: 0.9756
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0784 - acc: 0.9816
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0679 - acc: 0.9800
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0554 - acc: 0.9863
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0495 - acc: 0.9858
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0504 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0388 - acc: 0.9892
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0483 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0317 - acc: 0.9917
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0470 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.85 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.454
	P, R  : 0.618, 0.359

==================================================================================================
	XP Ends: 22/9 (9 h:43)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,3              ,27             ,175            ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
23             ,37             ,True           ,69             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.012          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.013          ,256            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.018          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.031          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 3, 27, 175, 12, 23, 37, True, 69, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.012, False, 20, 0.013, 256, 1, 20, categorical_crossentropy, 0.018, val_loss, adagrad, 4, False, 128, 0.031, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:43)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1598 - acc: 0.9591
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0662 - acc: 0.9811
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0511 - acc: 0.9850
MWE identification: 1
Epoch 1/1
 - 4s - loss: 0.0997 - acc: 0.9777
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0398 - acc: 0.9883
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0613 - acc: 0.9850
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0292 - acc: 0.9914
MWE identification: 3
Epoch 1/1
 - 4s - loss: 0.0551 - acc: 0.9869
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0233 - acc: 0.9933
MWE identification: 4
Epoch 1/1
 - 4s - loss: 0.0520 - acc: 0.9878
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0195 - acc: 0.9944
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0502 - acc: 0.9882
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.02 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.572
	P, R  : 0.754, 0.461

==================================================================================================
	XP Ends: 22/9 (9 h:46)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:46)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2649 - acc: 0.9196
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1445 - acc: 0.9521
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.1197 - acc: 0.9599
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1281 - acc: 0.9728
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0972 - acc: 0.9682
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0687 - acc: 0.9835
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0776 - acc: 0.9753
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0586 - acc: 0.9859
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0654 - acc: 0.9795
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0549 - acc: 0.9870
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0566 - acc: 0.9827
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0526 - acc: 0.9876
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.68 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.717, 0.495

==================================================================================================
	XP Ends: 22/9 (9 h:50)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:50)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2130 - acc: 0.9385
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0800 - acc: 0.9748
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0557 - acc: 0.9824
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0986 - acc: 0.9791
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0390 - acc: 0.9885
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0577 - acc: 0.9856
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0238 - acc: 0.9934
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0520 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0162 - acc: 0.9960
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0495 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0121 - acc: 0.9973
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0480 - acc: 0.9885
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.47 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.438
	P, R  : 0.639, 0.333

==================================================================================================
	XP Ends: 22/9 (9 h:53)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,2              ,149            ,49             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
5              ,43             ,True           ,56             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.005          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.02           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.021          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 2, 149, 49, 7, 5, 43, True, 56, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.005, True, 20, 0.006, 128, 2, 20, categorical_crossentropy, 0.02, val_loss, adagrad, 4, False, 96, 0.021, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:53)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2118 - acc: 0.9450
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1034 - acc: 0.9720
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0825 - acc: 0.9775
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0954 - acc: 0.9753
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0618 - acc: 0.9831
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0688 - acc: 0.9829
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0491 - acc: 0.9866
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0621 - acc: 0.9849
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0415 - acc: 0.9887
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0583 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0362 - acc: 0.9902
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0558 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 95.2
POS tagging accuracy (MWEs) = 95.2
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.489
	P, R  : 0.468, 0.512

==================================================================================================
	XP Ends: 22/9 (9 h:57)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (9h:57)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3016 - acc: 0.9107
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1701 - acc: 0.9454
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1433 - acc: 0.9533
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.1083 - acc: 0.9711
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1139 - acc: 0.9638
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0731 - acc: 0.9816
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0947 - acc: 0.9703
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0657 - acc: 0.9838
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0821 - acc: 0.9749
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0616 - acc: 0.9850
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0729 - acc: 0.9782
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0587 - acc: 0.9857
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.95 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.306
	P, R  : 0.204, 0.613

==================================================================================================
	XP Ends: 22/9 (10 h:1)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:1)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2622 - acc: 0.9252
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1060 - acc: 0.9688
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0709 - acc: 0.9794
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0800 - acc: 0.9801
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0425 - acc: 0.9885
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0584 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0287 - acc: 0.9925
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0534 - acc: 0.9872
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0217 - acc: 0.9946
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0509 - acc: 0.9879
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0174 - acc: 0.9959
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0492 - acc: 0.9884
Should stop early?
Early stopping applied
POS tagging accuracy = 92.9
POS tagging accuracy (MWEs) = 92.9
	TRAINING TIME: 2.97 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.341
	P, R  : 0.445, 0.276

==================================================================================================
	XP Ends: 22/9 (10 h:5)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
8              ,3              ,48             ,32             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
23             ,50             ,True           ,154            ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.025          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.062          ,96             ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.051          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.088          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 8, 3, 48, 32, 6, 23, 50, True, 154, False, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.025, False, 20, 0.062, 96, 2, 20, categorical_crossentropy, 0.051, val_loss, adagrad, 4, False, 256, 0.088, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:5)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.088
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1615 - acc: 0.9593
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0538 - acc: 0.9839
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0338 - acc: 0.9898
MWE identification: 1
Epoch 1/1
 - 10s - loss: 6.0220 - acc: 0.6181
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0517 - acc: 0.9846
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0580 - acc: 0.9856
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0290 - acc: 0.9915
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0493 - acc: 0.9879
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0198 - acc: 0.9942
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0463 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0148 - acc: 0.9957
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0452 - acc: 0.9893
Should stop early?
Early stopping applied
POS tagging accuracy = 96.0
POS tagging accuracy (MWEs) = 96.0
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.726, 0.479

==================================================================================================
	XP Ends: 22/9 (10 h:9)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:9)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.088
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2665 - acc: 0.9216
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1197 - acc: 0.9592
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0824 - acc: 0.9723
MWE identification: 1
Epoch 1/1
 - 7s - loss: 12.0832 - acc: 0.2501
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0685 - acc: 0.9778
MWE identification: 2
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0455 - acc: 0.9862
MWE identification: 3
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0341 - acc: 0.9900
MWE identification: 4
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0264 - acc: 0.9928
MWE identification: 5
Epoch 1/1
 - 7s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.88 minutes 
==================================================================================================
	PARSING TIME: 2.95 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (10 h:14)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:14)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.088
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.062
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2026 - acc: 0.9423
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0599 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0304 - acc: 0.9904
MWE identification: 1
Epoch 1/1
 - 14s - loss: 8.6001 - acc: 0.4663
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0251 - acc: 0.9925
MWE identification: 2
Epoch 1/1
 - 14s - loss: 8.0590 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0107 - acc: 0.9973
MWE identification: 3
Epoch 1/1
 - 14s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0061 - acc: 0.9988
MWE identification: 4
Epoch 1/1
 - 14s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0039 - acc: 0.9993
MWE identification: 5
Epoch 1/1
 - 14s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.0 minutes 
==================================================================================================
	PARSING TIME: 1.18 minutes 
==================================================================================================
	Identification : 0.001
	P, R  : 0.001, 0.002

==================================================================================================
	XP Ends: 22/9 (10 h:18)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
15             ,7              ,31             ,98             ,10             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
21             ,45             ,True           ,85             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.006          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.051          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.062          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.071          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 15, 7, 31, 98, 10, 21, 45, True, 85, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.006, True, 20, 0.051, 128, 2, 20, categorical_crossentropy, 0.062, val_loss, adagrad, 4, False, 96, 0.071, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:18)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1490 - acc: 0.9614
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0527 - acc: 0.9842
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0404 - acc: 0.9873
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0852 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0239 - acc: 0.9924
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0147 - acc: 0.9953
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0108 - acc: 0.9966
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0086 - acc: 0.9973
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0.05
	P, R  : 0.36, 0.027

==================================================================================================
	XP Ends: 22/9 (10 h:23)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:23)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2511 - acc: 0.9234
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1197 - acc: 0.9594
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0974 - acc: 0.9666
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0822 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0641 - acc: 0.9789
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0408 - acc: 0.9873
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0296 - acc: 0.9912
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0227 - acc: 0.9935
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0177 - acc: 0.9951
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 2.75 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (10 h:28)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:28)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.051
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1957 - acc: 0.9437
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0609 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0411 - acc: 0.9863
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0823 - acc: 0.9813
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0358 - acc: 0.9887
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0521 - acc: 0.9869
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0135 - acc: 0.9964
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0477 - acc: 0.9885
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0067 - acc: 0.9985
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0462 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0040 - acc: 0.9993
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0456 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 2.93 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.489
	P, R  : 0.588, 0.418

==================================================================================================
	XP Ends: 22/9 (10 h:32)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
19             ,2              ,270            ,83             ,7              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
42             ,58             ,True           ,30             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.021          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.022          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.026          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.005          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 19, 2, 270, 83, 7, 42, 58, True, 30, True, True, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 128, 0.021, False, 20, 0.022, 128, 2, 20, categorical_crossentropy, 0.026, val_loss, adagrad, 4, False, 256, 0.005, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:32)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.6382 - acc: 0.8425
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2345 - acc: 0.9404
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.1856 - acc: 0.9528
MWE identification: 1
Epoch 1/1
 - 8s - loss: 8.0603 - acc: 0.4997
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.1858 - acc: 0.9553
MWE identification: 2
Epoch 1/1
 - 8s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1520 - acc: 0.9606
MWE identification: 3
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1399 - acc: 0.9637
MWE identification: 4
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1313 - acc: 0.9657
MWE identification: 5
Epoch 1/1
 - 8s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 94.9
POS tagging accuracy (MWEs) = 94.9
	TRAINING TIME: 2.2 minutes 
==================================================================================================
	PARSING TIME: 2.4 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 22/9 (10 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:37)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.7487 - acc: 0.8008
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.3301 - acc: 0.9075
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.2696 - acc: 0.9216
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.1135 - acc: 0.9758
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.3172 - acc: 0.9172
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0593 - acc: 0.9861
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.2662 - acc: 0.9254
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0509 - acc: 0.9881
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.2374 - acc: 0.9306
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0488 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.2214 - acc: 0.9339
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0478 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 1.77 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.464
	P, R  : 0.372, 0.618

==================================================================================================
	XP Ends: 22/9 (10 h:41)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:41)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.005
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.7073 - acc: 0.8129
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2805 - acc: 0.9242
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.2161 - acc: 0.9394
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0791 - acc: 0.9816
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.2645 - acc: 0.9317
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0494 - acc: 0.9883
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.1942 - acc: 0.9478
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0462 - acc: 0.9891
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.1626 - acc: 0.9551
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0457 - acc: 0.9892
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.1461 - acc: 0.9597
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0454 - acc: 0.9892
Should stop early?
Early stopping applied
POS tagging accuracy = 91.5
POS tagging accuracy (MWEs) = 91.5
	TRAINING TIME: 2.73 minutes 
==================================================================================================
	PARSING TIME: 0.78 minutes 
==================================================================================================
	Identification : 0.449
	P, R  : 0.469, 0.431

==================================================================================================
	XP Ends: 22/9 (10 h:44)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,1              ,262            ,37             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
48             ,55             ,True           ,183            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.046          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.007          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.01           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
128            ,0.081          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 1, 262, 37, 6, 48, 55, True, 183, True, True, False, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.046, True, 20, 0.007, 256, 2, 20, categorical_crossentropy, 0.01, val_loss, adagrad, 4, False, 128, 0.081, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.081
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1582 - acc: 0.9595
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0525 - acc: 0.9844
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0380 - acc: 0.9883
MWE identification: 1
Epoch 1/1
 - 4s - loss: 0.0888 - acc: 0.9771
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0231 - acc: 0.9928
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0680 - acc: 0.9828
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0149 - acc: 0.9955
MWE identification: 3
Epoch 1/1
 - 4s - loss: 0.0631 - acc: 0.9842
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0112 - acc: 0.9965
MWE identification: 4
Epoch 1/1
 - 4s - loss: 0.0600 - acc: 0.9851
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0090 - acc: 0.9971
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0579 - acc: 0.9858
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.02 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.562
	P, R  : 0.687, 0.475

==================================================================================================
	XP Ends: 22/9 (10 h:48)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:48)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.081
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2638 - acc: 0.9217
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1197 - acc: 0.9597
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0927 - acc: 0.9685
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1031 - acc: 0.9731
POS tagging: 4
Epoch 1/1
 - 3s - loss: 0.0595 - acc: 0.9806
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0751 - acc: 0.9808
POS tagging: 5
Epoch 1/1
 - 3s - loss: 0.0408 - acc: 0.9873
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0687 - acc: 0.9826
POS tagging: 6
Epoch 1/1
 - 3s - loss: 0.0298 - acc: 0.9913
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0649 - acc: 0.9837
POS tagging: 7
Epoch 1/1
 - 3s - loss: 0.0230 - acc: 0.9935
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0624 - acc: 0.9843
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.67 minutes 
==================================================================================================
	PARSING TIME: 1.67 minutes 
==================================================================================================
	Identification : 0.56
	P, R  : 0.632, 0.503

==================================================================================================
	XP Ends: 22/9 (10 h:51)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:52)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.081
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1987 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0604 - acc: 0.9799
POS tagging: 3
Epoch 1/1
 - 3s - loss: 0.0371 - acc: 0.9878
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0823 - acc: 0.9789
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0175 - acc: 0.9950
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0637 - acc: 0.9836
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0089 - acc: 0.9979
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0593 - acc: 0.9847
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0051 - acc: 0.9991
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0567 - acc: 0.9854
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0034 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0548 - acc: 0.9861
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.5 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.477
	P, R  : 0.642, 0.38

==================================================================================================
	XP Ends: 22/9 (10 h:55)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
22             ,3              ,139            ,41             ,14             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
33             ,142            ,True           ,29             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.01           ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.012          ,128            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.011          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.008          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 22, 3, 139, 41, 14, 33, 142, True, 29, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.01, True, 20, 0.012, 128, 2, 20, categorical_crossentropy, 0.011, val_acc, adagrad, 4, False, 64, 0.008, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:55)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3836 - acc: 0.9070
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1269 - acc: 0.9692
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0972 - acc: 0.9746
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0955 - acc: 0.9789
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0866 - acc: 0.9767
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0579 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0746 - acc: 0.9794
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0530 - acc: 0.9873
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0678 - acc: 0.9811
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0505 - acc: 0.9880
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0629 - acc: 0.9822
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0490 - acc: 0.9884
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.0589 - acc: 0.9831
MWE identification: 6
Epoch 1/1
 - 8s - loss: 0.0479 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.75 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.591
	P, R  : 0.797, 0.469

==================================================================================================
	XP Ends: 22/9 (10 h:59)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (10h:59)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5031 - acc: 0.8631
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2385 - acc: 0.9287
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1967 - acc: 0.9380
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1244 - acc: 0.9738
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1820 - acc: 0.9428
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0639 - acc: 0.9843
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1626 - acc: 0.9483
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0569 - acc: 0.9863
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1509 - acc: 0.9517
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0536 - acc: 0.9873
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1424 - acc: 0.9541
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0514 - acc: 0.9877
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.1354 - acc: 0.9564
MWE identification: 6
Epoch 1/1
 - 6s - loss: 0.0502 - acc: 0.9881
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.28 minutes 
==================================================================================================
	PARSING TIME: 1.73 minutes 
==================================================================================================
	Identification : 0.625
	P, R  : 0.846, 0.495

==================================================================================================
	XP Ends: 22/9 (11 h:3)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:3)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4625 - acc: 0.8796
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1727 - acc: 0.9504
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1254 - acc: 0.9629
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0845 - acc: 0.9807
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1112 - acc: 0.9681
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0549 - acc: 0.9862
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0889 - acc: 0.9742
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0505 - acc: 0.9877
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0770 - acc: 0.9779
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0485 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0686 - acc: 0.9805
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0472 - acc: 0.9888
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 3.1 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.45
	P, R  : 0.645, 0.345

==================================================================================================
	XP Ends: 22/9 (11 h:8)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,3              ,211            ,70             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
49             ,115            ,True           ,61             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.043          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.006          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.019          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
256            ,0.054          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 3, 211, 70, 5, 49, 115, True, 61, True, False, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.043, True, 20, 0.006, 96, 1, 20, categorical_crossentropy, 0.019, val_loss, adagrad, 4, False, 256, 0.054, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:8)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1399 - acc: 0.9629
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0538 - acc: 0.9838
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0354 - acc: 0.9893
MWE identification: 1
Epoch 1/1
 - 10s - loss: 0.0828 - acc: 0.9788
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0263 - acc: 0.9919
MWE identification: 2
Epoch 1/1
 - 10s - loss: 0.0651 - acc: 0.9836
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0191 - acc: 0.9942
MWE identification: 3
Epoch 1/1
 - 10s - loss: 0.0605 - acc: 0.9848
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0148 - acc: 0.9955
MWE identification: 4
Epoch 1/1
 - 10s - loss: 0.0576 - acc: 0.9857
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0122 - acc: 0.9963
MWE identification: 5
Epoch 1/1
 - 10s - loss: 0.0556 - acc: 0.9862
Should stop early?
Early stopping applied
POS tagging accuracy = 96.2
POS tagging accuracy (MWEs) = 96.2
	TRAINING TIME: 2.43 minutes 
==================================================================================================
	PARSING TIME: 1.13 minutes 
==================================================================================================
	Identification : 0.554
	P, R  : 0.651, 0.482

==================================================================================================
	XP Ends: 22/9 (11 h:11)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:11)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2481 - acc: 0.9235
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1246 - acc: 0.9583
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0910 - acc: 0.9698
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.0951 - acc: 0.9752
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0717 - acc: 0.9767
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0716 - acc: 0.9820
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0554 - acc: 0.9828
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0659 - acc: 0.9835
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0448 - acc: 0.9865
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0624 - acc: 0.9843
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0370 - acc: 0.9891
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0600 - acc: 0.9850
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 1.92 minutes 
==================================================================================================
	PARSING TIME: 1.7 minutes 
==================================================================================================
	Identification : 0.569
	P, R  : 0.686, 0.486

==================================================================================================
	XP Ends: 22/9 (11 h:15)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:15)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.006
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1905 - acc: 0.9440
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0638 - acc: 0.9791
POS tagging: 3
Epoch 1/1
 - 2s - loss: 0.0352 - acc: 0.9889
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0764 - acc: 0.9805
POS tagging: 4
Epoch 1/1
 - 2s - loss: 0.0221 - acc: 0.9936
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0617 - acc: 0.9841
POS tagging: 5
Epoch 1/1
 - 2s - loss: 0.0131 - acc: 0.9967
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0578 - acc: 0.9851
POS tagging: 6
Epoch 1/1
 - 2s - loss: 0.0084 - acc: 0.9982
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0554 - acc: 0.9859
POS tagging: 7
Epoch 1/1
 - 2s - loss: 0.0058 - acc: 0.9989
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0536 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 2.97 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.473
	P, R  : 0.606, 0.388

==================================================================================================
	XP Ends: 22/9 (11 h:19)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
20             ,1              ,69             ,35             ,6              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
11             ,66             ,True           ,39             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
False          ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.007          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.03           ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.015          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.007          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 20, 1, 69, 35, 6, 11, 66, True, 39, False, False, True, True, 3, True, False, False, False, False, True, False, 1, 1, 32, False, relu, 64, 0.007, True, 20, 0.03, 96, 1, 20, categorical_crossentropy, 0.015, val_loss, adagrad, 4, False, 64, 0.007, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:19)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 14799 * POS : 153
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 14799

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4570 - acc: 0.8873
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1791 - acc: 0.9539
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1392 - acc: 0.9632
MWE identification: 1
Epoch 1/1
 - 10s - loss: 12.0854 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1239 - acc: 0.9679
MWE identification: 2
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1050 - acc: 0.9720
MWE identification: 3
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0960 - acc: 0.9744
MWE identification: 4
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0893 - acc: 0.9764
MWE identification: 5
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 95.5
POS tagging accuracy (MWEs) = 95.5
	TRAINING TIME: 2.75 minutes 
==================================================================================================
	PARSING TIME: 2.37 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 22/9 (11 h:25)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:25)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 12104 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 12104

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5647 - acc: 0.8478
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2650 - acc: 0.9222
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.2172 - acc: 0.9332
MWE identification: 1
Epoch 1/1
 - 7s - loss: 1.2885 - acc: 0.9055
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.2623 - acc: 0.9270
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0600 - acc: 0.9863
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.2155 - acc: 0.9360
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0501 - acc: 0.9883
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1874 - acc: 0.9415
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0483 - acc: 0.9886
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1730 - acc: 0.9452
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0475 - acc: 0.9887
Should stop early?
Early stopping applied
POS tagging accuracy = 93.5
POS tagging accuracy (MWEs) = 93.5
	TRAINING TIME: 2.22 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.445
	P, R  : 0.363, 0.575

==================================================================================================
	XP Ends: 22/9 (11 h:29)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:29)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 29785 * POS : 110
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 29785

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5276 - acc: 0.8603
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2150 - acc: 0.9393
POS tagging: 3
Epoch 1/1
 - 7s - loss: 0.1548 - acc: 0.9551
MWE identification: 1
Epoch 1/1
 - 14s - loss: 8.0591 - acc: 0.4998
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1427 - acc: 0.9615
MWE identification: 2
Epoch 1/1
 - 14s - loss: 8.0591 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 7s - loss: 0.1033 - acc: 0.9714
MWE identification: 3
Epoch 1/1
 - 14s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 7s - loss: 0.0886 - acc: 0.9761
MWE identification: 4
Epoch 1/1
 - 14s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0781 - acc: 0.9795
MWE identification: 5
Epoch 1/1
 - 14s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 93.0
POS tagging accuracy (MWEs) = 93.0
	TRAINING TIME: 3.38 minutes 
==================================================================================================
	PARSING TIME: 1.58 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.003, 0.133

==================================================================================================
	XP Ends: 22/9 (11 h:34)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,1              ,43             ,70             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
9              ,31             ,True           ,156            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,96             ,0.027          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.024          ,256            ,2              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.096          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.072          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 1, 43, 70, 5, 9, 31, True, 156, True, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 96, 0.027, True, 20, 0.024, 256, 2, 20, categorical_crossentropy, 0.096, val_loss, adagrad, 4, False, 64, 0.072, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:34)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.072
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.024
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1514 - acc: 0.9608
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0529 - acc: 0.9842
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0438 - acc: 0.9864
MWE identification: 1
Epoch 1/1
 - 4s - loss: 0.0997 - acc: 0.9788
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0261 - acc: 0.9920
MWE identification: 2
Epoch 1/1
 - 4s - loss: 0.0569 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0153 - acc: 0.9952
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0511 - acc: 0.9876
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0111 - acc: 0.9964
MWE identification: 4
Epoch 1/1
 - 4s - loss: 0.0481 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0088 - acc: 0.9972
MWE identification: 5
Epoch 1/1
 - 4s - loss: 0.0467 - acc: 0.9890
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.25 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.751, 0.469

==================================================================================================
	XP Ends: 22/9 (11 h:38)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:38)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.072
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.024
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2515 - acc: 0.9234
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1192 - acc: 0.9598
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1035 - acc: 0.9646
MWE identification: 1
Epoch 1/1
 - 3s - loss: 0.1333 - acc: 0.9736
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0643 - acc: 0.9791
MWE identification: 2
Epoch 1/1
 - 3s - loss: 0.0616 - acc: 0.9846
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0416 - acc: 0.9869
MWE identification: 3
Epoch 1/1
 - 3s - loss: 0.0539 - acc: 0.9869
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0299 - acc: 0.9910
MWE identification: 4
Epoch 1/1
 - 3s - loss: 0.0506 - acc: 0.9878
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0227 - acc: 0.9934
MWE identification: 5
Epoch 1/1
 - 3s - loss: 0.0489 - acc: 0.9883
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 1.88 minutes 
==================================================================================================
	PARSING TIME: 1.75 minutes 
==================================================================================================
	Identification : 0.54
	P, R  : 0.574, 0.51

==================================================================================================
	XP Ends: 22/9 (11 h:42)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:42)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.072
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.024
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1966 - acc: 0.9434
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0612 - acc: 0.9801
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0460 - acc: 0.9845
MWE identification: 1
Epoch 1/1
 - 6s - loss: 0.0917 - acc: 0.9799
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0220 - acc: 0.9933
MWE identification: 2
Epoch 1/1
 - 6s - loss: 0.0558 - acc: 0.9859
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0093 - acc: 0.9975
MWE identification: 3
Epoch 1/1
 - 6s - loss: 0.0507 - acc: 0.9876
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0050 - acc: 0.9990
MWE identification: 4
Epoch 1/1
 - 6s - loss: 0.0481 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0031 - acc: 0.9995
MWE identification: 5
Epoch 1/1
 - 6s - loss: 0.0467 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.68 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.446
	P, R  : 0.616, 0.349

==================================================================================================
	XP Ends: 22/9 (11 h:46)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
5              ,2              ,36             ,60             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
6              ,67             ,True           ,138            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,64             ,0.032          ,False          ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.029          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.038          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.046          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 5, 2, 36, 60, 5, 6, 67, True, 138, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 64, 0.032, False, 20, 0.029, 128, 1, 20, categorical_crossentropy, 0.038, val_loss, adagrad, 4, False, 64, 0.046, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.046
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1429 - acc: 0.9623
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0563 - acc: 0.9834
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0461 - acc: 0.9858
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0861 - acc: 0.9810
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0334 - acc: 0.9898
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0573 - acc: 0.9866
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0207 - acc: 0.9938
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0490 - acc: 0.9883
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0149 - acc: 0.9954
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0466 - acc: 0.9890
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0118 - acc: 0.9965
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0456 - acc: 0.9893
Should stop early?
Early stopping applied
POS tagging accuracy = 96.1
POS tagging accuracy (MWEs) = 96.1
	TRAINING TIME: 2.53 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.582
	P, R  : 0.723, 0.487

==================================================================================================
	XP Ends: 22/9 (11 h:49)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:49)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.046
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2487 - acc: 0.9232
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1294 - acc: 0.9566
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1104 - acc: 0.9623
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.0906 - acc: 0.9789
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0837 - acc: 0.9726
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0614 - acc: 0.9856
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0590 - acc: 0.9814
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0513 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0454 - acc: 0.9860
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0489 - acc: 0.9884
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0365 - acc: 0.9890
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0477 - acc: 0.9886
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.08 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.585
	P, R  : 0.619, 0.555

==================================================================================================
	XP Ends: 22/9 (11 h:54)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:54)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.046
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.1927 - acc: 0.9435
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0674 - acc: 0.9780
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0494 - acc: 0.9837
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0811 - acc: 0.9816
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.0317 - acc: 0.9902
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0547 - acc: 0.9865
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0151 - acc: 0.9959
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0485 - acc: 0.9884
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0085 - acc: 0.9981
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0467 - acc: 0.9889
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0054 - acc: 0.9989
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0459 - acc: 0.9891
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.08 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.431
	P, R  : 0.581, 0.343

==================================================================================================
	XP Ends: 22/9 (11 h:58)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
6              ,3              ,226            ,90             ,5              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
18             ,36             ,True           ,25             ,False          ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,False          ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,128            ,0.034          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.014          ,96             ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.007          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.013          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 6, 3, 226, 90, 5, 18, 36, True, 25, False, True, False, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 128, 0.034, True, 20, 0.014, 96, 1, 20, categorical_crossentropy, 0.007, val_loss, adagrad, 4, False, 96, 0.013, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (11h:58)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2471 - acc: 0.9401
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.0961 - acc: 0.9749
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0775 - acc: 0.9786
MWE identification: 1
Epoch 1/1
 - 10s - loss: 8.0574 - acc: 0.4998
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0638 - acc: 0.9821
MWE identification: 2
Epoch 1/1
 - 10s - loss: 8.0590 - acc: 0.5000
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0529 - acc: 0.9850
MWE identification: 3
Epoch 1/1
 - 10s - loss: 8.0590 - acc: 0.5000
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0465 - acc: 0.9871
MWE identification: 4
Epoch 1/1
 - 10s - loss: 8.0590 - acc: 0.5000
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0417 - acc: 0.9885
MWE identification: 5
Epoch 1/1
 - 10s - loss: 8.0590 - acc: 0.5000
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 2.37 minutes 
==================================================================================================
	Identification : 0.008
	P, R  : 0.004, 0.182

==================================================================================================
	XP Ends: 22/9 (12 h:3)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (12h:3)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3616 - acc: 0.8974
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1924 - acc: 0.9390
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1645 - acc: 0.9467
MWE identification: 1
Epoch 1/1
 - 7s - loss: 0.1124 - acc: 0.9760
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1530 - acc: 0.9507
MWE identification: 2
Epoch 1/1
 - 7s - loss: 0.0614 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1332 - acc: 0.9573
MWE identification: 3
Epoch 1/1
 - 7s - loss: 0.0549 - acc: 0.9868
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1207 - acc: 0.9610
MWE identification: 4
Epoch 1/1
 - 7s - loss: 0.0519 - acc: 0.9877
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1114 - acc: 0.9643
MWE identification: 5
Epoch 1/1
 - 7s - loss: 0.0500 - acc: 0.9882
Should stop early?
Early stopping applied
POS tagging accuracy = 94.2
POS tagging accuracy (MWEs) = 94.2
	TRAINING TIME: 2.07 minutes 
==================================================================================================
	PARSING TIME: 1.77 minutes 
==================================================================================================
	Identification : 0.59
	P, R  : 0.677, 0.523

==================================================================================================
	XP Ends: 22/9 (12 h:7)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (12h:7)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3187 - acc: 0.9134
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1232 - acc: 0.9636
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0933 - acc: 0.9713
MWE identification: 1
Epoch 1/1
 - 14s - loss: 0.0783 - acc: 0.9818
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0826 - acc: 0.9758
MWE identification: 2
Epoch 1/1
 - 14s - loss: 0.0545 - acc: 0.9864
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0623 - acc: 0.9819
MWE identification: 3
Epoch 1/1
 - 14s - loss: 0.0502 - acc: 0.9878
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0510 - acc: 0.9856
MWE identification: 4
Epoch 1/1
 - 14s - loss: 0.0482 - acc: 0.9885
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0431 - acc: 0.9880
MWE identification: 5
Epoch 1/1
 - 14s - loss: 0.0470 - acc: 0.9889
Should stop early?
Early stopping applied
POS tagging accuracy = 93.7
POS tagging accuracy (MWEs) = 93.7
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 0.82 minutes 
==================================================================================================
	Identification : 0.448
	P, R  : 0.632, 0.347

==================================================================================================
	XP Ends: 22/9 (12 h:11)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
7              ,7              ,34             ,98             ,9              ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
49             ,72             ,True           ,96             ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,False          ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.031          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.088          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.007          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
64             ,0.008          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 7, 7, 34, 98, 9, 49, 72, True, 96, True, True, True, False, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.031, True, 20, 0.088, 128, 1, 20, categorical_crossentropy, 0.007, val_loss, adagrad, 4, False, 64, 0.008, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (12h:11)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.088
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3836 - acc: 0.9070
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1269 - acc: 0.9692
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.0972 - acc: 0.9746
MWE identification: 1
Epoch 1/1
 - 8s - loss: 12.0848 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1293 - acc: 0.9707
MWE identification: 2
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0814 - acc: 0.9783
MWE identification: 3
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0719 - acc: 0.9804
MWE identification: 4
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0659 - acc: 0.9816
MWE identification: 5
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.55 minutes 
==================================================================================================
	PARSING TIME: 1.8 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (12 h:16)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (12h:16)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.088
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.5031 - acc: 0.8631
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2385 - acc: 0.9287
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1967 - acc: 0.9380
MWE identification: 1
Epoch 1/1
 - 5s - loss: 12.0722 - acc: 0.2507
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.2695 - acc: 0.9247
MWE identification: 2
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.1866 - acc: 0.9419
MWE identification: 3
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.1696 - acc: 0.9469
MWE identification: 4
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.1585 - acc: 0.9498
MWE identification: 5
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
POS tagging: 8
Epoch 1/1
 - 6s - loss: 0.1502 - acc: 0.9525
MWE identification: 6
Epoch 1/1
 - 5s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 94.0
POS tagging accuracy (MWEs) = 94.0
	TRAINING TIME: 2.27 minutes 
==================================================================================================
	PARSING TIME: 2.8 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (12 h:21)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (12h:21)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.008
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.088
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4625 - acc: 0.8796
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1727 - acc: 0.9504
POS tagging: 3
Epoch 1/1
 - 6s - loss: 0.1254 - acc: 0.9629
MWE identification: 1
Epoch 1/1
 - 11s - loss: 12.0856 - acc: 0.2500
POS tagging: 4
Epoch 1/1
 - 6s - loss: 0.1489 - acc: 0.9585
MWE identification: 2
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 5
Epoch 1/1
 - 6s - loss: 0.0976 - acc: 0.9716
MWE identification: 3
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 6
Epoch 1/1
 - 6s - loss: 0.0836 - acc: 0.9757
MWE identification: 4
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging: 7
Epoch 1/1
 - 6s - loss: 0.0741 - acc: 0.9786
MWE identification: 5
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
Should stop early?
Early stopping applied
POS tagging accuracy = 93.9
POS tagging accuracy (MWEs) = 93.9
	TRAINING TIME: 3.08 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 22/9 (12 h:26)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, affixeDim, capitalDim, depParsingDenseUnits, idenDenseUnits, symbolDim, sytacticLabelDim, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,depParsingDense,idenDenseUnits ,symbolDim      ,
__________________________________________________________________________________________________
11             ,6              ,56             ,76             ,12             ,
__________________________________________________________________________________________________
sytacticLabelDi,taggingDenseUni,testOnToken    ,tokenDim       ,useB1          ,
__________________________________________________________________________________________________
39             ,179            ,True           ,104            ,True           ,
__________________________________________________________________________________________________
useBx          ,useCapitalizati,useSymbols     ,windowSize     ,average        ,
__________________________________________________________________________________________________
True           ,True           ,True           ,3              ,True           ,
__________________________________________________________________________________________________
compactVocab   ,dynamicVocab   ,keras          ,lemma          ,manual         ,
__________________________________________________________________________________________________
False          ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
pretrained     ,useB-1         ,useB1          ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
False          ,1              ,1              ,32             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,256            ,0.018          ,True           ,20             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.007          ,128            ,1              ,20             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.041          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
96             ,0.011          ,0.2            ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, 11, 6, 56, 76, 12, 39, 179, True, 104, True, True, True, True, 3, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 256, 0.018, True, 20, 0.007, 128, 1, 20, categorical_crossentropy, 0.041, val_acc, adagrad, 4, False, 96, 0.011, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (12h:26)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
== BG,17813,5364,0.301128389379,10,2.12416107383,0,0,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9313 * POS : 153
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 9313

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 356484
POS Tagging data = 273594
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.2833 - acc: 0.9315
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1046 - acc: 0.9734
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.0838 - acc: 0.9772
MWE identification: 1
Epoch 1/1
 - 8s - loss: 0.0912 - acc: 0.9777
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0709 - acc: 0.9800
MWE identification: 2
Epoch 1/1
 - 8s - loss: 0.0630 - acc: 0.9845
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0609 - acc: 0.9825
MWE identification: 3
Epoch 1/1
 - 8s - loss: 0.0577 - acc: 0.9859
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0545 - acc: 0.9846
MWE identification: 4
Epoch 1/1
 - 8s - loss: 0.0549 - acc: 0.9867
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0496 - acc: 0.9861
MWE identification: 5
Epoch 1/1
 - 8s - loss: 0.0532 - acc: 0.9871
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.0457 - acc: 0.9874
MWE identification: 6
Epoch 1/1
 - 8s - loss: 0.0518 - acc: 0.9876
Should stop early?
Early stopping applied
POS tagging accuracy = 96.3
POS tagging accuracy (MWEs) = 96.3
	TRAINING TIME: 2.6 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.59
	P, R  : 0.832, 0.457

==================================================================================================
	XP Ends: 22/9 (12 h:30)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 22/9 (12h:30)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
== PT,22017,4405,0.200072671118,1,2.21203178207,23,20,11,3,5,3,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9195 * POS : 170
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 9195

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 241368
POS Tagging data = 272587
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.4005 - acc: 0.8884
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.2055 - acc: 0.9361
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1748 - acc: 0.9438
MWE identification: 1
Epoch 1/1
 - 5s - loss: 0.1158 - acc: 0.9719
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.1546 - acc: 0.9501
MWE identification: 2
Epoch 1/1
 - 5s - loss: 0.0704 - acc: 0.9826
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.1380 - acc: 0.9553
MWE identification: 3
Epoch 1/1
 - 5s - loss: 0.0636 - acc: 0.9843
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.1274 - acc: 0.9588
MWE identification: 4
Epoch 1/1
 - 5s - loss: 0.0598 - acc: 0.9853
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.1191 - acc: 0.9613
MWE identification: 5
Epoch 1/1
 - 5s - loss: 0.0571 - acc: 0.9860
Should stop early?
POS tagging: 8
Epoch 1/1
 - 4s - loss: 0.1123 - acc: 0.9638
MWE identification: 6
Epoch 1/1
 - 5s - loss: 0.0553 - acc: 0.9866
Should stop early?
Early stopping applied
POS tagging accuracy = 94.1
POS tagging accuracy (MWEs) = 94.1
	TRAINING TIME: 2.12 minutes 
==================================================================================================
	PARSING TIME: 1.88 minutes 
==================================================================================================
	Identification : 0.598
	P, R  : 0.869, 0.456

==================================================================================================
	XP Ends: 22/9 (12 h:34)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 22/9 (12h:34)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== TR,16715,6111,0.365599760694,3,2.05989199804,3,3,0,0,0,0,0

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 17289 * POS : 110
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 17289

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.007
__________________________________________________________________________________________________
Iden data = 480496
POS Tagging data = 274871
POS tagging: 1
Epoch 1/1
 - 2s - loss: 0.3549 - acc: 0.9052
POS tagging: 2
Epoch 1/1
 - 2s - loss: 0.1374 - acc: 0.9593
POS tagging: 3
Epoch 1/1
 - 4s - loss: 0.1035 - acc: 0.9690
MWE identification: 1
Epoch 1/1
 - 11s - loss: 0.0814 - acc: 0.9798
POS tagging: 4
Epoch 1/1
 - 4s - loss: 0.0828 - acc: 0.9755
MWE identification: 2
Epoch 1/1
 - 11s - loss: 0.0592 - acc: 0.9849
POS tagging: 5
Epoch 1/1
 - 4s - loss: 0.0660 - acc: 0.9809
MWE identification: 3
Epoch 1/1
 - 11s - loss: 0.0548 - acc: 0.9862
POS tagging: 6
Epoch 1/1
 - 4s - loss: 0.0556 - acc: 0.9842
MWE identification: 4
Epoch 1/1
 - 11s - loss: 0.0524 - acc: 0.9870
POS tagging: 7
Epoch 1/1
 - 4s - loss: 0.0482 - acc: 0.9865
MWE identification: 5
Epoch 1/1
 - 11s - loss: 0.0507 - acc: 0.9876
Should stop early?
Early stopping applied
POS tagging accuracy = 93.8
POS tagging accuracy (MWEs) = 93.8
	TRAINING TIME: 2.97 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.428
	P, R  : 0.636, 0.322

==================================================================================================
	XP Ends: 22/9 (12 h:38)
==================================================================================================
